{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83228cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Improved Temporal Graph Neural Network for Anti-Money Laundering Detection\n",
    "==========================================================================\n",
    "Optimized for F2 Score with structured code organization\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (precision_recall_curve, roc_auc_score, f1_score, \n",
    "                           precision_score, recall_score, fbeta_score, \n",
    "                           confusion_matrix, average_precision_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74ecce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent.parent))  # Adjust as needed\n",
    "from config import DATAPATH, SAMPLE_DATAPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ddba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f457192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration class for hyperparameters and settings\"\"\"\n",
    "    # Model architecture\n",
    "    HIDDEN_DIM = 256\n",
    "    NODE_DIM = 15\n",
    "    EDGE_DIM = 9\n",
    "    DROPOUT_RATE = 0.3\n",
    "    \n",
    "    # Training parameters\n",
    "    LEARNING_RATE = 0.0005  # Reduced for better convergence\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    EPOCHS = 75\n",
    "    PATIENCE = 10\n",
    "    \n",
    "    # F2 score optimization\n",
    "    BETA = 2  # For F2 score (emphasizes recall)\n",
    "    CLASS_WEIGHT_MULTIPLIER = 10  # Strong emphasis on minority class\n",
    "\n",
    "    # Criterion parameters\n",
    "    FOCAL_LOSS_ALPHA = 0.25\n",
    "    FOCAL_LOSS_GAMMA = 2.0\n",
    "    \n",
    "    # Data processing\n",
    "    TIME_WINDOW = '7D'\n",
    "    VALIDATION_SPLIT = 0.17\n",
    "    TEST_SPLIT = 0.13\n",
    "    \n",
    "    # Threshold optimization\n",
    "    THRESHOLD_SEARCH_RANGE = np.arange(0.05, 0.95, 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0671bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for addressing class imbalance - better than BCE for F2 optimization\"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08365f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGraphDataProcessor:\n",
    "    \"\"\"Enhanced data processor with better feature engineering for F2 optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, time_window='7D'):\n",
    "        self.time_window = time_window\n",
    "        self.scalers = {}\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_and_preprocess(self, df):\n",
    "        \"\"\"Load SAML-D dataset and perform initial preprocessing\"\"\"\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        \n",
    "        # Combine date and time into datetime\n",
    "        df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "        df = df.sort_values('datetime').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Loaded {len(df)} transactions\")\n",
    "        print(f\"Suspicious transactions: {df['Is_laundering'].sum()} ({df['Is_laundering'].mean()*100:.3f}%)\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def engineer_features(self, df):\n",
    "        \"\"\"Enhanced feature engineering for better detection\"\"\"\n",
    "        print(\"Engineering enhanced features...\")\n",
    "        \n",
    "        # Time-based features (more granular)\n",
    "        df['hour'] = df['datetime'].dt.hour.astype('int8')\n",
    "        df['month'] = df['datetime'].dt.month.astype('int8')\n",
    "        df['day_of_week'] = df['datetime'].dt.dayofweek.astype('int8')\n",
    "        df['day_of_month'] = df['datetime'].dt.day.astype('int8')\n",
    "        df['is_weekend'] = (df['day_of_week'] >= 5).astype('int8')\n",
    "        df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 5)).astype('int8')  # Night transactions\n",
    "        \n",
    "        # Amount-based features\n",
    "        df['log_amount'] = np.log1p(df['Amount']).astype('float32')\n",
    "        \n",
    "        # Calculate amount percentiles for anomaly detection\n",
    "        # amount_percentiles = df['Amount'].quantile([0.95, 0.99]).values\n",
    "        # df['high_amount'] = (df['Amount'] > amount_percentiles[0]).astype('int8')\n",
    "        # df['very_high_amount'] = (df['Amount'] > amount_percentiles[1]).astype('int8')\n",
    "        \n",
    "        # Geographic risk features\n",
    "        df['cross_border'] = (df['Payment_type'] == 'Cross-border').astype('int8')\n",
    "        risky_countries = {'Mexico', 'Turkey', 'Morocco', 'UAE'}\n",
    "        df['high_risk_sender'] = df['Sender_bank_location'].isin(risky_countries).astype('int8')\n",
    "        df['high_risk_receiver'] = df['Receiver_bank_location'].isin(risky_countries).astype('int8')\n",
    "        # df['both_high_risk'] = (df['high_risk_sender'] & df['high_risk_receiver']).astype('int8')\n",
    "        \n",
    "        # Currency features\n",
    "        df['currency_mismatch'] = (df['Payment_currency'] != df['Received_currency']).astype('int8')\n",
    "        \n",
    "        # Convert target\n",
    "        df['Is_laundering'] = df['Is_laundering'].astype('int8')\n",
    "        \n",
    "        # Clean up\n",
    "        columns_to_drop = ['Date', 'Time', 'Amount', 'Sender_bank_location', \n",
    "                          'Receiver_bank_location', 'Payment_currency', 'Received_currency', \n",
    "                          'Laundering_type']\n",
    "        df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_temporal_snapshots(self, df, account_features):\n",
    "        \"\"\"Create temporal graph snapshots with enhanced features\"\"\"\n",
    "        print(\"Creating temporal graph snapshots...\")\n",
    "        \n",
    "        # Global account mapping\n",
    "        all_accounts = list(set(df['Sender_account'].unique()) | set(df['Receiver_account'].unique()))\n",
    "        global_account_to_idx = {acc: idx for idx, acc in enumerate(all_accounts)}\n",
    "        global_num_nodes = len(all_accounts)\n",
    "        \n",
    "        # Time windows\n",
    "        start_date = df['datetime'].min().normalize().date()\n",
    "        end_date = df['datetime'].max().normalize().date()\n",
    "        \n",
    "        snapshots = []\n",
    "        print(f\"Processing time range: {start_date} to {end_date}\")\n",
    "\n",
    "        for window_start in pd.date_range(start=start_date, end=end_date, freq=self.time_window, inclusive='left'):\n",
    "            window_end = window_start + pd.Timedelta(days=7)\n",
    "            window_start_str = pd.to_datetime(window_start).strftime('%Y-%m-%d')\n",
    "            window_end_str = pd.to_datetime(window_end).strftime('%Y-%m-%d')\n",
    "            print(f\"Processing window: {window_start_str} to {window_end_str}\")\n",
    "            \n",
    "            # Get transactions in current window\n",
    "            window_mask = (df['datetime'] >= window_start_str) & (df['datetime'] < window_end_str)\n",
    "            window_trnx_data = df[window_mask].copy()\n",
    "            \n",
    "            # Account features for this window\n",
    "            window_accounts_features = account_features[account_features['window_start'] == window_start_str]\n",
    "            \n",
    "            if len(window_trnx_data) > 0:\n",
    "                graph_data = self._create_graph_snapshot(\n",
    "                    window_trnx_data, window_accounts_features,\n",
    "                    window_start_str, global_account_to_idx, global_num_nodes\n",
    "                )\n",
    "                if graph_data is not None:\n",
    "                    snapshots.append(graph_data)\n",
    "\n",
    "        print(f\"Created {len(snapshots)} temporal snapshots\")\n",
    "        return snapshots, global_num_nodes\n",
    "\n",
    "    def _create_graph_snapshot(self, window_trnx_data, window_accounts_features, \n",
    "                              timestamp, global_account_to_idx, global_num_nodes):\n",
    "        \"\"\"Create enhanced graph snapshot\"\"\"\n",
    "        if len(window_trnx_data) == 0:\n",
    "            return None\n",
    "\n",
    "        # Enhanced edge features\n",
    "        edge_feature_columns = [\n",
    "            'Payment_type_encoded', 'log_amount', 'month', 'day_of_week', 'hour', \n",
    "            'currency_mismatch', 'cross_border', 'high_risk_sender', 'high_risk_receiver',\n",
    "        ]\n",
    "        \n",
    "        # Filter available columns\n",
    "        edge_feature_columns = [col for col in edge_feature_columns if col in window_trnx_data.columns]\n",
    "\n",
    "        # Node features\n",
    "        node_feature_columns = ['sent_txns_count', 'fan_out', 'recv_txns_count', 'fan_in', \n",
    "                               'max_sent_txn_count', 'max_recv_txn_count', 'sent_recv_ratio', \n",
    "                               'fanout_fanin_ratio', 'log_med_sent_amt', 'log_std_sent_amt', \n",
    "                               'log_med_recv_amt', 'log_std_recv_amt', 'log_max_sent_txn_amt', \n",
    "                               'log_max_recv_txn_amt', 'log_total_txns_amt']\n",
    "\n",
    "        # Create mappings and features\n",
    "        sender_mapped = window_trnx_data['Sender_account'].map(global_account_to_idx)\n",
    "        receiver_mapped = window_trnx_data['Receiver_account'].map(global_account_to_idx)\n",
    "        edge_index = np.column_stack((sender_mapped, receiver_mapped))\n",
    "        edge_features = window_trnx_data[edge_feature_columns].values\n",
    "        transaction_labels = window_trnx_data['Is_laundering'].values\n",
    "\n",
    "        # Node features\n",
    "        node_features = np.zeros((global_num_nodes, len(node_feature_columns)))\n",
    "        try:\n",
    "            window_accounts_features['global_idx'] = window_accounts_features['account'].map(global_account_to_idx)\n",
    "            node_features[window_accounts_features['global_idx'].values] = window_accounts_features[node_feature_columns].values\n",
    "        except: \n",
    "            raise ValueError(\"Error in mapping account features to global indices.\")\n",
    "\n",
    "        # Convert to tensors\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "        edge_features = torch.tensor(edge_features, dtype=torch.float)\n",
    "        transaction_labels = torch.tensor(transaction_labels, dtype=torch.float)\n",
    "\n",
    "        return Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_features,\n",
    "            y=transaction_labels,\n",
    "            timestamp=timestamp,\n",
    "            num_nodes=global_num_nodes\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fbfa562",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalEdgeClassifier(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, dropout_rate):\n",
    "        super(TemporalEdgeClassifier, self).__init__()\n",
    "        \n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(node_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Change 2: Multi-head attention in GNN layers\n",
    "        self.gnn1 = GATConv(hidden_dim, hidden_dim, heads=4, concat=False)\n",
    "        self.gnn2 = GATConv(hidden_dim, hidden_dim, heads=2, concat=False)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        # Change 3: Larger classifier with residual connection\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        \n",
    "        h = self.node_encoder(x)\n",
    "        \n",
    "        # Apply GNN layers\n",
    "        h = F.relu(self.gnn1(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.gnn2(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        \n",
    "        # Edge features\n",
    "        h_i = h[edge_index[0]]\n",
    "        h_j = h[edge_index[1]]\n",
    "        edge_input = torch.cat([h_i + h_j, edge_attr], dim=-1)\n",
    "        \n",
    "        # Prediction\n",
    "        out = self.classifier(edge_input)\n",
    "        \n",
    "        return out, h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59dd2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"Enhanced trainer class optimized for F2 score\"\"\"\n",
    "    \n",
    "    def __init__(self, config=Config()):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "    \n",
    "    def find_optimal_threshold(self, probs, labels):\n",
    "        \"\"\"Find optimal threshold for F2 score\"\"\"\n",
    "        best_f2 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in self.config.THRESHOLD_SEARCH_RANGE:\n",
    "            preds = (probs >= threshold).astype(int)\n",
    "            f2 = fbeta_score(labels, preds, beta=self.config.BETA, average='binary', zero_division=0)\n",
    "            if f2 > best_f2:\n",
    "                best_f2 = f2\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        return best_threshold, best_f2\n",
    "    \n",
    "    def compute_class_weights(self, snapshots):\n",
    "        \"\"\"Compute class weights for focal loss\"\"\"\n",
    "        all_labels = []\n",
    "        for snap in snapshots:\n",
    "            all_labels.extend(snap.y.cpu().numpy())\n",
    "        \n",
    "        all_labels = np.array(all_labels)\n",
    "        pos_weight = len(all_labels) / (2 * np.sum(all_labels))\n",
    "        return torch.tensor(pos_weight, dtype=torch.float).to(self.device)\n",
    "    \n",
    "    def train_model(self, snapshots, global_num_nodes):\n",
    "        \"\"\"Enhanced training with F2 optimization\"\"\"\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(len(snapshots) * (1 - self.config.VALIDATION_SPLIT - self.config.TEST_SPLIT))\n",
    "        val_size = int(len(snapshots) * self.config.VALIDATION_SPLIT)\n",
    "        \n",
    "        train_snaps = snapshots[:train_size]\n",
    "        val_snaps = snapshots[train_size:train_size + val_size]\n",
    "        test_snaps = snapshots[train_size + val_size:]\n",
    "        \n",
    "        print(f\"Data split - Train: {len(train_snaps)}, Val: {len(val_snaps)}, Test: {len(test_snaps)}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = TemporalEdgeClassifier(\n",
    "            self.config.NODE_DIM, \n",
    "            self.config.EDGE_DIM, \n",
    "            self.config.HIDDEN_DIM,\n",
    "            self.config.DROPOUT_RATE\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Compute class weights for focal loss\n",
    "        pos_weight = self.compute_class_weights(train_snaps)\n",
    "        criterion = FocalLoss(alpha=self.config.FOCAL_LOSS_ALPHA, gamma=self.config.FOCAL_LOSS_GAMMA)\n",
    "        \n",
    "        # Optimizer with different learning rates for different components\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': model.node_encoder.parameters(), 'lr': self.config.LEARNING_RATE * 0.5},\n",
    "            {'params': model.gnn1.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.gnn2.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            # {'params': model.gnn3.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.classifier.parameters(), 'lr': self.config.LEARNING_RATE * 1.5}\n",
    "        ], weight_decay=self.config.WEIGHT_DECAY)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.7, patience=5, verbose=True\n",
    "        )\n",
    "        \n",
    "        # Training loop\n",
    "        best_f2_score = 0\n",
    "        patience_counter = 0\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "        f2_history = []\n",
    "        \n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            \n",
    "            for snap in train_snaps:\n",
    "                snap = snap.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                out, _ = model(snap)\n",
    "                loss = criterion(out.squeeze(), snap.y)\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_snaps)\n",
    "            train_loss_history.append(avg_train_loss)\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_probs_list, val_labels_list = [], []\n",
    "            val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for snap in val_snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, _ = model(snap)\n",
    "                    loss = criterion(out.squeeze(), snap.y)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    preds = torch.sigmoid(out).squeeze()\n",
    "                    val_probs_list.append(preds.cpu())\n",
    "                    val_labels_list.append(snap.y.cpu())\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_snaps)\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "            \n",
    "            # Scale\n",
    "            avg_train_loss *= 1000\n",
    "            avg_val_loss *= 1000\n",
    "            \n",
    "            # Calculate F2 score with optimal threshold\n",
    "            val_probs = torch.cat(val_probs_list).numpy()\n",
    "            val_labels = torch.cat(val_labels_list).numpy()\n",
    "            \n",
    "            optimal_threshold, f2_score = self.find_optimal_threshold(val_probs, val_labels)\n",
    "            f2_history.append(f2_score)\n",
    "            recall = recall_score(val_labels, (val_probs >= optimal_threshold).astype(int), zero_division=0)\n",
    "            \n",
    "            scheduler.step(f2_score)\n",
    "            \n",
    "            # Early stopping based on F2 score\n",
    "            if f2_score > best_f2_score:\n",
    "                best_f2_score = f2_score\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                # torch.save(model.state_dict(), './outputs/best_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}: Train Loss(x1e3): {avg_train_loss:.4f}, Val Loss(x1e3): {avg_val_loss:.4f}, \"\n",
    "                        f\"F2: {f2_score:.4f}, Threshold: {optimal_threshold:.3f}, Recall: {recall:.4f}\")\n",
    "            \n",
    "            if patience_counter >= self.config.PATIENCE:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # Load best model and evaluate\n",
    "        # model.load_state_dict(torch.load('./outputs/best_model.pth'))\n",
    "        \n",
    "        # Final evaluation\n",
    "        results = self._evaluate_model(model, train_snaps, val_snaps, test_snaps, global_num_nodes)\n",
    "        results.update({\n",
    "            'train_loss_history': train_loss_history,\n",
    "            'val_loss_history': val_loss_history,\n",
    "            'f2_history': f2_history,\n",
    "            'model': model\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_model(self, model, train_snaps, val_snaps, test_snaps, global_num_nodes):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        model.eval()\n",
    "        results = {}\n",
    "        \n",
    "        for split_name, snaps in [('val', val_snaps), ('test', test_snaps)]:\n",
    "            probs_list, labels_list = [], []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for snap in snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, _ = model(snap)\n",
    "                    preds = torch.sigmoid(out).squeeze().cpu().numpy()\n",
    "                    probs_list.extend(preds)\n",
    "                    labels_list.extend(snap.y.cpu().numpy())\n",
    "            \n",
    "            probs = np.array(probs_list)\n",
    "            labels = np.array(labels_list)\n",
    "            \n",
    "            # Find optimal threshold\n",
    "            optimal_threshold, best_f2 = self.find_optimal_threshold(probs, labels)\n",
    "            binary_preds = (probs >= optimal_threshold).astype(int)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            precision = precision_score(labels, binary_preds, zero_division=0)\n",
    "            recall = recall_score(labels, binary_preds, zero_division=0)\n",
    "            f1 = f1_score(labels, binary_preds, zero_division=0)\n",
    "            roc_auc = roc_auc_score(labels, probs)\n",
    "            pr_auc = average_precision_score(labels, probs)\n",
    "            \n",
    "            results[f'{split_name}_probs'] = probs\n",
    "            results[f'{split_name}_labels'] = labels\n",
    "            results[f'{split_name}_threshold'] = optimal_threshold\n",
    "            results[f'{split_name}_precision'] = precision\n",
    "            results[f'{split_name}_recall'] = recall\n",
    "            results[f'{split_name}_f1'] = f1\n",
    "            results[f'{split_name}_f2'] = best_f2\n",
    "            results[f'{split_name}_roc_auc'] = roc_auc\n",
    "            results[f'{split_name}_pr_auc'] = pr_auc\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2124555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset\n",
    "df = pd.read_csv(DATAPATH)\n",
    "\n",
    "# Filter by data range\n",
    "# df = df[df['Date'] < '2023-08-18']\n",
    "# df = df.head(300000).copy()\n",
    "\n",
    "# run feature engg.ipynb to get the account_stats_7D.csv\n",
    "account_stats = pd.read_csv('../account_stats_7D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9178de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Loaded 9504852 transactions\n",
      "Suspicious transactions: 9873 (0.104%)\n",
      "Engineering enhanced features...\n"
     ]
    }
   ],
   "source": [
    "graph_processor = TemporalGraphDataProcessor()\n",
    "df = graph_processor.load_and_preprocess(df)\n",
    "df = graph_processor.engineer_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8bfb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For each categorical column\n",
    "# categorical_cols = ['Payment_currency', 'Received_currency', 'Sender_bank_location', \n",
    "#                    'Receiver_bank_location', 'Payment_type']\n",
    "categorical_cols = ['Payment_type']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "# Drop original object columns\n",
    "df = df.drop(categorical_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43c740f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process accont_stats\n",
    "columns = ['med_sent_amt', 'std_sent_amt', 'med_recv_amt', 'std_recv_amt', \n",
    "           'max_sent_txn_amt', 'max_recv_txn_amt', 'total_txns_amt']\n",
    "\n",
    "for col in columns:\n",
    "    account_stats['log_' + col] = np.log1p(account_stats[col]).astype('float32')\n",
    "\n",
    "account_stats = account_stats.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "094d1677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data types to optimize memory\n",
    "account_stats = account_stats.astype({\n",
    "    'sent_txns_count': 'int32',\n",
    "    'recv_txns_count': 'int32',\n",
    "    'fan_out': 'int32',\n",
    "    'fan_in': 'int32',\n",
    "    'max_sent_txn_count': 'int32',\n",
    "    'max_recv_txn_count': 'int32',\n",
    "    'sent_recv_ratio': 'float32',\n",
    "    'fanout_fanin_ratio': 'float32'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79bf8e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporal graph snapshots...\n",
      "Processing time range: 2022-10-07 to 2023-08-23\n",
      "Processing window: 2022-10-07 to 2022-10-14\n",
      "Processing window: 2022-10-14 to 2022-10-21\n",
      "Processing window: 2022-10-21 to 2022-10-28\n",
      "Processing window: 2022-10-28 to 2022-11-04\n",
      "Processing window: 2022-11-04 to 2022-11-11\n",
      "Processing window: 2022-11-11 to 2022-11-18\n",
      "Processing window: 2022-11-18 to 2022-11-25\n",
      "Processing window: 2022-11-25 to 2022-12-02\n",
      "Processing window: 2022-12-02 to 2022-12-09\n",
      "Processing window: 2022-12-09 to 2022-12-16\n",
      "Processing window: 2022-12-16 to 2022-12-23\n",
      "Processing window: 2022-12-23 to 2022-12-30\n",
      "Processing window: 2022-12-30 to 2023-01-06\n",
      "Processing window: 2023-01-06 to 2023-01-13\n",
      "Processing window: 2023-01-13 to 2023-01-20\n",
      "Processing window: 2023-01-20 to 2023-01-27\n",
      "Processing window: 2023-01-27 to 2023-02-03\n",
      "Processing window: 2023-02-03 to 2023-02-10\n",
      "Processing window: 2023-02-10 to 2023-02-17\n",
      "Processing window: 2023-02-17 to 2023-02-24\n",
      "Processing window: 2023-02-24 to 2023-03-03\n",
      "Processing window: 2023-03-03 to 2023-03-10\n",
      "Processing window: 2023-03-10 to 2023-03-17\n",
      "Processing window: 2023-03-17 to 2023-03-24\n",
      "Processing window: 2023-03-24 to 2023-03-31\n",
      "Processing window: 2023-03-31 to 2023-04-07\n",
      "Processing window: 2023-04-07 to 2023-04-14\n",
      "Processing window: 2023-04-14 to 2023-04-21\n",
      "Processing window: 2023-04-21 to 2023-04-28\n",
      "Processing window: 2023-04-28 to 2023-05-05\n",
      "Processing window: 2023-05-05 to 2023-05-12\n",
      "Processing window: 2023-05-12 to 2023-05-19\n",
      "Processing window: 2023-05-19 to 2023-05-26\n",
      "Processing window: 2023-05-26 to 2023-06-02\n",
      "Processing window: 2023-06-02 to 2023-06-09\n",
      "Processing window: 2023-06-09 to 2023-06-16\n",
      "Processing window: 2023-06-16 to 2023-06-23\n",
      "Processing window: 2023-06-23 to 2023-06-30\n",
      "Processing window: 2023-06-30 to 2023-07-07\n",
      "Processing window: 2023-07-07 to 2023-07-14\n",
      "Processing window: 2023-07-14 to 2023-07-21\n",
      "Processing window: 2023-07-21 to 2023-07-28\n",
      "Processing window: 2023-07-28 to 2023-08-04\n",
      "Processing window: 2023-08-04 to 2023-08-11\n",
      "Processing window: 2023-08-11 to 2023-08-18\n",
      "Processing window: 2023-08-18 to 2023-08-25\n",
      "Created 46 temporal snapshots\n"
     ]
    }
   ],
   "source": [
    "snapshots, global_num_nodes = graph_processor.create_temporal_snapshots(df, account_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89fc6783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Data split - Train: 32, Val: 7, Test: 7\n",
      "Epoch 1: Train Loss(x1e3): 4.1069, Val Loss(x1e3): 0.7794, F2: 0.0106, Threshold: 0.050, Recall: 0.3786\n",
      "Epoch 2: Train Loss(x1e3): 0.7505, Val Loss(x1e3): 0.6873, F2: 0.0116, Threshold: 0.100, Recall: 0.0809\n",
      "Epoch 3: Train Loss(x1e3): 0.6961, Val Loss(x1e3): 0.6419, F2: 0.0129, Threshold: 0.100, Recall: 0.1975\n",
      "Epoch 4: Train Loss(x1e3): 0.6714, Val Loss(x1e3): 0.6253, F2: 0.0149, Threshold: 0.100, Recall: 0.2860\n",
      "Epoch 5: Train Loss(x1e3): 0.6574, Val Loss(x1e3): 0.6143, F2: 0.0167, Threshold: 0.100, Recall: 0.3985\n",
      "Epoch 6: Train Loss(x1e3): 0.6451, Val Loss(x1e3): 0.6034, F2: 0.0187, Threshold: 0.100, Recall: 0.5466\n",
      "Epoch 7: Train Loss(x1e3): 0.6266, Val Loss(x1e3): 0.5914, F2: 0.0240, Threshold: 0.150, Recall: 0.1461\n",
      "Epoch 8: Train Loss(x1e3): 0.6181, Val Loss(x1e3): 0.5809, F2: 0.0295, Threshold: 0.150, Recall: 0.2147\n",
      "Epoch 9: Train Loss(x1e3): 0.6073, Val Loss(x1e3): 0.5777, F2: 0.0423, Threshold: 0.200, Recall: 0.0638\n",
      "Epoch 10: Train Loss(x1e3): 0.5985, Val Loss(x1e3): 0.5633, F2: 0.0601, Threshold: 0.200, Recall: 0.0995\n",
      "Epoch 11: Train Loss(x1e3): 0.5876, Val Loss(x1e3): 0.5586, F2: 0.0764, Threshold: 0.200, Recall: 0.1337\n",
      "Epoch 12: Train Loss(x1e3): 0.5793, Val Loss(x1e3): 0.5528, F2: 0.0877, Threshold: 0.200, Recall: 0.1728\n",
      "Epoch 13: Train Loss(x1e3): 0.5681, Val Loss(x1e3): 0.5390, F2: 0.0967, Threshold: 0.200, Recall: 0.1975\n",
      "Epoch 14: Train Loss(x1e3): 0.5586, Val Loss(x1e3): 0.5193, F2: 0.1105, Threshold: 0.250, Recall: 0.1070\n",
      "Epoch 15: Train Loss(x1e3): 0.5446, Val Loss(x1e3): 0.4977, F2: 0.1287, Threshold: 0.250, Recall: 0.1248\n",
      "Epoch 16: Train Loss(x1e3): 0.5299, Val Loss(x1e3): 0.4696, F2: 0.1564, Threshold: 0.250, Recall: 0.1564\n",
      "Epoch 17: Train Loss(x1e3): 0.5065, Val Loss(x1e3): 0.4408, F2: 0.1763, Threshold: 0.200, Recall: 0.2908\n",
      "Epoch 18: Train Loss(x1e3): 0.4796, Val Loss(x1e3): 0.4202, F2: 0.2542, Threshold: 0.200, Recall: 0.3368\n",
      "Epoch 19: Train Loss(x1e3): 0.4517, Val Loss(x1e3): 0.3854, F2: 0.3191, Threshold: 0.200, Recall: 0.4959\n",
      "Epoch 20: Train Loss(x1e3): 0.4173, Val Loss(x1e3): 0.3596, F2: 0.3660, Threshold: 0.250, Recall: 0.4294\n",
      "Epoch 21: Train Loss(x1e3): 0.3951, Val Loss(x1e3): 0.3380, F2: 0.4084, Threshold: 0.250, Recall: 0.4877\n",
      "Epoch 22: Train Loss(x1e3): 0.3819, Val Loss(x1e3): 0.3195, F2: 0.4504, Threshold: 0.300, Recall: 0.4438\n",
      "Epoch 23: Train Loss(x1e3): 0.3564, Val Loss(x1e3): 0.3026, F2: 0.4701, Threshold: 0.300, Recall: 0.4753\n",
      "Epoch 24: Train Loss(x1e3): 0.3362, Val Loss(x1e3): 0.2916, F2: 0.4878, Threshold: 0.300, Recall: 0.4870\n",
      "Epoch 25: Train Loss(x1e3): 0.3175, Val Loss(x1e3): 0.2728, F2: 0.5319, Threshold: 0.300, Recall: 0.5391\n",
      "Epoch 26: Train Loss(x1e3): 0.3063, Val Loss(x1e3): 0.2637, F2: 0.5560, Threshold: 0.300, Recall: 0.5494\n",
      "Epoch 27: Train Loss(x1e3): 0.2938, Val Loss(x1e3): 0.2553, F2: 0.5750, Threshold: 0.300, Recall: 0.5624\n",
      "Epoch 28: Train Loss(x1e3): 0.2847, Val Loss(x1e3): 0.2472, F2: 0.5899, Threshold: 0.300, Recall: 0.5761\n",
      "Epoch 29: Train Loss(x1e3): 0.2772, Val Loss(x1e3): 0.2444, F2: 0.6036, Threshold: 0.300, Recall: 0.5947\n",
      "Epoch 30: Train Loss(x1e3): 0.2769, Val Loss(x1e3): 0.2402, F2: 0.6105, Threshold: 0.300, Recall: 0.6043\n",
      "Epoch 31: Train Loss(x1e3): 0.2648, Val Loss(x1e3): 0.2493, F2: 0.5981, Threshold: 0.300, Recall: 0.5981\n",
      "Epoch 32: Train Loss(x1e3): 0.2681, Val Loss(x1e3): 0.2352, F2: 0.6260, Threshold: 0.300, Recall: 0.6145\n",
      "Epoch 33: Train Loss(x1e3): 0.2580, Val Loss(x1e3): 0.2293, F2: 0.6355, Threshold: 0.300, Recall: 0.6166\n",
      "Epoch 34: Train Loss(x1e3): 0.2530, Val Loss(x1e3): 0.2224, F2: 0.6354, Threshold: 0.300, Recall: 0.6310\n",
      "Epoch 35: Train Loss(x1e3): 0.2528, Val Loss(x1e3): 0.2206, F2: 0.6462, Threshold: 0.300, Recall: 0.6324\n",
      "Epoch 36: Train Loss(x1e3): 0.2469, Val Loss(x1e3): 0.2214, F2: 0.6386, Threshold: 0.300, Recall: 0.6379\n",
      "Epoch 37: Train Loss(x1e3): 0.2411, Val Loss(x1e3): 0.2136, F2: 0.6604, Threshold: 0.300, Recall: 0.6481\n",
      "Epoch 38: Train Loss(x1e3): 0.2371, Val Loss(x1e3): 0.2163, F2: 0.6511, Threshold: 0.300, Recall: 0.6468\n",
      "Epoch 39: Train Loss(x1e3): 0.2340, Val Loss(x1e3): 0.2095, F2: 0.6634, Threshold: 0.300, Recall: 0.6564\n",
      "Epoch 40: Train Loss(x1e3): 0.2329, Val Loss(x1e3): 0.2121, F2: 0.6587, Threshold: 0.300, Recall: 0.6468\n",
      "Epoch 41: Train Loss(x1e3): 0.2313, Val Loss(x1e3): 0.2076, F2: 0.6697, Threshold: 0.300, Recall: 0.6543\n",
      "Epoch 42: Train Loss(x1e3): 0.2260, Val Loss(x1e3): 0.2072, F2: 0.6667, Threshold: 0.300, Recall: 0.6502\n",
      "Epoch 43: Train Loss(x1e3): 0.2240, Val Loss(x1e3): 0.2037, F2: 0.6716, Threshold: 0.300, Recall: 0.6591\n",
      "Epoch 44: Train Loss(x1e3): 0.2304, Val Loss(x1e3): 0.2459, F2: 0.6251, Threshold: 0.300, Recall: 0.5981\n",
      "Epoch 45: Train Loss(x1e3): 0.2471, Val Loss(x1e3): 0.2091, F2: 0.6518, Threshold: 0.300, Recall: 0.6536\n",
      "Epoch 46: Train Loss(x1e3): 0.2305, Val Loss(x1e3): 0.2030, F2: 0.6619, Threshold: 0.300, Recall: 0.6646\n",
      "Epoch 47: Train Loss(x1e3): 0.2265, Val Loss(x1e3): 0.2031, F2: 0.6683, Threshold: 0.300, Recall: 0.6564\n",
      "Epoch 48: Train Loss(x1e3): 0.2240, Val Loss(x1e3): 0.2019, F2: 0.6668, Threshold: 0.300, Recall: 0.6632\n",
      "Epoch 49: Train Loss(x1e3): 0.2205, Val Loss(x1e3): 0.2003, F2: 0.6717, Threshold: 0.300, Recall: 0.6619\n",
      "Epoch 50: Train Loss(x1e3): 0.2162, Val Loss(x1e3): 0.1994, F2: 0.6770, Threshold: 0.300, Recall: 0.6646\n",
      "Epoch 51: Train Loss(x1e3): 0.2235, Val Loss(x1e3): 0.2066, F2: 0.6592, Threshold: 0.300, Recall: 0.6488\n",
      "Epoch 52: Train Loss(x1e3): 0.2180, Val Loss(x1e3): 0.1948, F2: 0.6769, Threshold: 0.350, Recall: 0.6578\n",
      "Epoch 53: Train Loss(x1e3): 0.2137, Val Loss(x1e3): 0.1950, F2: 0.6769, Threshold: 0.350, Recall: 0.6584\n",
      "Epoch 54: Train Loss(x1e3): 0.2125, Val Loss(x1e3): 0.1925, F2: 0.6825, Threshold: 0.300, Recall: 0.6776\n",
      "Epoch 55: Train Loss(x1e3): 0.2083, Val Loss(x1e3): 0.1923, F2: 0.6897, Threshold: 0.300, Recall: 0.6824\n",
      "Epoch 56: Train Loss(x1e3): 0.2050, Val Loss(x1e3): 0.1923, F2: 0.6798, Threshold: 0.300, Recall: 0.6763\n",
      "Epoch 57: Train Loss(x1e3): 0.2021, Val Loss(x1e3): 0.1940, F2: 0.6728, Threshold: 0.350, Recall: 0.6557\n",
      "Epoch 58: Train Loss(x1e3): 0.2017, Val Loss(x1e3): 0.1966, F2: 0.6831, Threshold: 0.250, Recall: 0.6872\n",
      "Epoch 59: Train Loss(x1e3): 0.2020, Val Loss(x1e3): 0.1888, F2: 0.6903, Threshold: 0.350, Recall: 0.6770\n",
      "Epoch 60: Train Loss(x1e3): 0.1985, Val Loss(x1e3): 0.1902, F2: 0.6895, Threshold: 0.300, Recall: 0.6886\n",
      "Epoch 61: Train Loss(x1e3): 0.1980, Val Loss(x1e3): 0.1895, F2: 0.6923, Threshold: 0.300, Recall: 0.6866\n",
      "Epoch 62: Train Loss(x1e3): 0.1969, Val Loss(x1e3): 0.1885, F2: 0.6979, Threshold: 0.300, Recall: 0.6879\n",
      "Epoch 63: Train Loss(x1e3): 0.1991, Val Loss(x1e3): 0.1898, F2: 0.6903, Threshold: 0.300, Recall: 0.6859\n",
      "Epoch 64: Train Loss(x1e3): 0.1960, Val Loss(x1e3): 0.1895, F2: 0.6894, Threshold: 0.350, Recall: 0.6722\n",
      "Epoch 65: Train Loss(x1e3): 0.1924, Val Loss(x1e3): 0.1870, F2: 0.6877, Threshold: 0.350, Recall: 0.6735\n",
      "Epoch 66: Train Loss(x1e3): 0.2316, Val Loss(x1e3): 0.1938, F2: 0.6740, Threshold: 0.250, Recall: 0.6914\n",
      "Epoch 67: Train Loss(x1e3): 0.2054, Val Loss(x1e3): 0.1882, F2: 0.6953, Threshold: 0.350, Recall: 0.6783\n",
      "Epoch 68: Train Loss(x1e3): 0.2014, Val Loss(x1e3): 0.1841, F2: 0.7037, Threshold: 0.300, Recall: 0.6962\n",
      "Epoch 69: Train Loss(x1e3): 0.1998, Val Loss(x1e3): 0.1852, F2: 0.6978, Threshold: 0.350, Recall: 0.6770\n",
      "Epoch 70: Train Loss(x1e3): 0.1979, Val Loss(x1e3): 0.1829, F2: 0.6994, Threshold: 0.300, Recall: 0.6879\n",
      "Epoch 71: Train Loss(x1e3): 0.1979, Val Loss(x1e3): 0.1835, F2: 0.6939, Threshold: 0.300, Recall: 0.6886\n",
      "Epoch 72: Train Loss(x1e3): 0.1974, Val Loss(x1e3): 0.1840, F2: 0.7021, Threshold: 0.300, Recall: 0.6900\n",
      "Epoch 73: Train Loss(x1e3): 0.1944, Val Loss(x1e3): 0.1824, F2: 0.7059, Threshold: 0.300, Recall: 0.6920\n",
      "Epoch 74: Train Loss(x1e3): 0.1925, Val Loss(x1e3): 0.1789, F2: 0.7085, Threshold: 0.350, Recall: 0.6900\n",
      "Epoch 75: Train Loss(x1e3): 0.1888, Val Loss(x1e3): 0.1809, F2: 0.7072, Threshold: 0.350, Recall: 0.6879\n"
     ]
    }
   ],
   "source": [
    "trainer = ModelTrainer(config=Config())\n",
    "results = trainer.train_model(snapshots, global_num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb0d7038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_probs': array([0.04439412, 0.03517108, 0.00195555, ..., 0.03217799, 0.01735922,\n",
       "        0.05669279], shape=(1458820,), dtype=float32),\n",
       " 'val_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1458820,), dtype=float32),\n",
       " 'val_threshold': np.float64(0.35000000000000003),\n",
       " 'val_precision': 0.7966640190627482,\n",
       " 'val_recall': 0.6879286694101509,\n",
       " 'val_f1': 0.7383143172616857,\n",
       " 'val_f2': 0.7072345226343252,\n",
       " 'val_roc_auc': 0.9881692509092603,\n",
       " 'val_pr_auc': 0.7208553920144931,\n",
       " 'test_probs': array([0.00096185, 0.0022514 , 0.01160922, ..., 0.03006493, 0.09680287,\n",
       "        0.04543658], shape=(1384809,), dtype=float32),\n",
       " 'test_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1384809,), dtype=float32),\n",
       " 'test_threshold': np.float64(0.3),\n",
       " 'test_precision': 0.7808219178082192,\n",
       " 'test_recall': 0.6946983546617916,\n",
       " 'test_f1': 0.7352466946146404,\n",
       " 'test_f2': 0.7103688933200398,\n",
       " 'test_roc_auc': 0.9861133837996455,\n",
       " 'test_pr_auc': 0.7309307965292554,\n",
       " 'train_loss_history': [0.0041068994851229945,\n",
       "  0.0007504584964408423,\n",
       "  0.0006961119188417797,\n",
       "  0.000671352159770322,\n",
       "  0.0006574185590579873,\n",
       "  0.0006451214894696022,\n",
       "  0.0006266367108764825,\n",
       "  0.0006181496928547858,\n",
       "  0.0006072957921787747,\n",
       "  0.000598507253016578,\n",
       "  0.0005876016866750433,\n",
       "  0.0005792822903458728,\n",
       "  0.0005681473821823602,\n",
       "  0.000558645620913012,\n",
       "  0.0005445738734124461,\n",
       "  0.0005298567712088698,\n",
       "  0.0005064505166956224,\n",
       "  0.0004796240691575804,\n",
       "  0.00045165763367549516,\n",
       "  0.0004173011011516792,\n",
       "  0.0003951297258026898,\n",
       "  0.0003818516515821102,\n",
       "  0.0003563754676179087,\n",
       "  0.0003362209931765392,\n",
       "  0.0003174991147716355,\n",
       "  0.0003063012086386152,\n",
       "  0.0002938107732006756,\n",
       "  0.000284736008325126,\n",
       "  0.0002771952003968181,\n",
       "  0.00027688599129760405,\n",
       "  0.00026479111602384364,\n",
       "  0.0002680735187823302,\n",
       "  0.0002580255500106432,\n",
       "  0.00025302257290604757,\n",
       "  0.00025277851682403707,\n",
       "  0.0002469261303303938,\n",
       "  0.0002411251653029467,\n",
       "  0.00023708281332801562,\n",
       "  0.0002340268915759225,\n",
       "  0.00023285560291697038,\n",
       "  0.00023128750808609766,\n",
       "  0.00022598134410145576,\n",
       "  0.00022402730746762245,\n",
       "  0.00023038383051243727,\n",
       "  0.00024711760352147394,\n",
       "  0.000230499981171306,\n",
       "  0.00022654530630461522,\n",
       "  0.00022396332724383683,\n",
       "  0.00022050074539947673,\n",
       "  0.00021622676467814017,\n",
       "  0.00022352620135279722,\n",
       "  0.00021798443640363985,\n",
       "  0.00021366091141317156,\n",
       "  0.00021245867355901282,\n",
       "  0.00020828624292335007,\n",
       "  0.00020501723474808387,\n",
       "  0.00020208950127198477,\n",
       "  0.00020166566218904336,\n",
       "  0.00020198661331960466,\n",
       "  0.00019847918520099483,\n",
       "  0.00019800281597781577,\n",
       "  0.0001969438962987624,\n",
       "  0.00019913677124350215,\n",
       "  0.00019600967152655357,\n",
       "  0.00019243505448685028,\n",
       "  0.0002315915248800593,\n",
       "  0.00020537170394163695,\n",
       "  0.00020136059674769058,\n",
       "  0.00019982349112979136,\n",
       "  0.0001979004332497425,\n",
       "  0.00019793781711996417,\n",
       "  0.00019738883565878496,\n",
       "  0.0001943795550687355,\n",
       "  0.00019250604782428127,\n",
       "  0.00018875537671192433],\n",
       " 'val_loss_history': [0.0007793992990627885,\n",
       "  0.0006872751774998116,\n",
       "  0.0006418514822144061,\n",
       "  0.0006253031440012689,\n",
       "  0.0006143059207326067,\n",
       "  0.0006034250878396311,\n",
       "  0.0005913950361511004,\n",
       "  0.000580922733726246,\n",
       "  0.0005777475349272468,\n",
       "  0.0005632910470012575,\n",
       "  0.0005586265469901264,\n",
       "  0.0005528387513809971,\n",
       "  0.0005390206476606961,\n",
       "  0.0005193350121511944,\n",
       "  0.0004977285030430981,\n",
       "  0.0004695941419673285,\n",
       "  0.0004407897566644741,\n",
       "  0.0004201560514047742,\n",
       "  0.0003854241970527385,\n",
       "  0.00035956044614847215,\n",
       "  0.0003380088268646172,\n",
       "  0.0003195364219469151,\n",
       "  0.0003026392369065434,\n",
       "  0.00029162992931170654,\n",
       "  0.0002728310916739117,\n",
       "  0.0002637159653074507,\n",
       "  0.00025527617253828794,\n",
       "  0.0002471683484535398,\n",
       "  0.00024444808410148004,\n",
       "  0.0002402447197320206,\n",
       "  0.0002493444397779448,\n",
       "  0.0002352007120082687,\n",
       "  0.0002293250394619203,\n",
       "  0.00022243512752798518,\n",
       "  0.0002206228278477543,\n",
       "  0.00022143279576474533,\n",
       "  0.00021357183452762132,\n",
       "  0.0002162961193659742,\n",
       "  0.00020952443966442452,\n",
       "  0.00021211024639861925,\n",
       "  0.00020764451307643737,\n",
       "  0.00020719375710801354,\n",
       "  0.00020370799133421054,\n",
       "  0.0002459024586382189,\n",
       "  0.0002091200668863686,\n",
       "  0.0002030365472559684,\n",
       "  0.00020310148205940744,\n",
       "  0.00020185770907638862,\n",
       "  0.00020026447808569564,\n",
       "  0.00019935443248998906,\n",
       "  0.0002066046727122739,\n",
       "  0.00019479811557435563,\n",
       "  0.00019504648558462838,\n",
       "  0.00019253597045982524,\n",
       "  0.00019230550138412843,\n",
       "  0.00019225782723099525,\n",
       "  0.00019401270921142505,\n",
       "  0.00019661736067584052,\n",
       "  0.00018879651906900108,\n",
       "  0.00019021143712702075,\n",
       "  0.00018945206206158867,\n",
       "  0.00018846874133617218,\n",
       "  0.00018979248125106096,\n",
       "  0.00018949450376177474,\n",
       "  0.000187020973368947,\n",
       "  0.00019381236675794104,\n",
       "  0.00018816286215691695,\n",
       "  0.00018407059958138104,\n",
       "  0.00018517217540647835,\n",
       "  0.0001829045047218512,\n",
       "  0.0001834843839917864,\n",
       "  0.0001839827621422176,\n",
       "  0.00018241353557511632,\n",
       "  0.00017886229034047574,\n",
       "  0.00018089724887561585],\n",
       " 'f2_history': [0.01064588918246514,\n",
       "  0.011609830968732167,\n",
       "  0.012914682379530229,\n",
       "  0.01491597690706309,\n",
       "  0.01670385022310134,\n",
       "  0.018739272530624723,\n",
       "  0.023995674019331725,\n",
       "  0.029547814594543566,\n",
       "  0.042311191992720654,\n",
       "  0.0601111018986817,\n",
       "  0.0764406115248922,\n",
       "  0.08774984330385124,\n",
       "  0.09673518742442563,\n",
       "  0.11054421768707483,\n",
       "  0.12871287128712872,\n",
       "  0.15642151481888036,\n",
       "  0.17628471644769667,\n",
       "  0.2541670980432757,\n",
       "  0.3191207627118644,\n",
       "  0.36595346661989947,\n",
       "  0.408385985066054,\n",
       "  0.4503689266323263,\n",
       "  0.4700854700854701,\n",
       "  0.487838394942971,\n",
       "  0.5319436924742826,\n",
       "  0.556018325697626,\n",
       "  0.5750350631136045,\n",
       "  0.5898876404494382,\n",
       "  0.6035923141186299,\n",
       "  0.6105336105336105,\n",
       "  0.598079561042524,\n",
       "  0.6259605980159285,\n",
       "  0.6355153400254488,\n",
       "  0.6354468849288576,\n",
       "  0.6462012895991028,\n",
       "  0.638648537288834,\n",
       "  0.660377358490566,\n",
       "  0.6510632421982878,\n",
       "  0.6633855538610841,\n",
       "  0.6587035484772282,\n",
       "  0.6696616594131686,\n",
       "  0.6666666666666666,\n",
       "  0.6715583508036338,\n",
       "  0.625089605734767,\n",
       "  0.6518467852257182,\n",
       "  0.6618852459016393,\n",
       "  0.6682960893854749,\n",
       "  0.6668045786788029,\n",
       "  0.671724906028122,\n",
       "  0.6769596199524941,\n",
       "  0.659233449477352,\n",
       "  0.6768774703557312,\n",
       "  0.6769143985333521,\n",
       "  0.6825089803813208,\n",
       "  0.6897268820185776,\n",
       "  0.6798124655267512,\n",
       "  0.6727656579873329,\n",
       "  0.6831197163894192,\n",
       "  0.6903063365505665,\n",
       "  0.6894657327290208,\n",
       "  0.6922544951590595,\n",
       "  0.6978847759532424,\n",
       "  0.6903216899074969,\n",
       "  0.6893640967923467,\n",
       "  0.6876750700280112,\n",
       "  0.6739769991976464,\n",
       "  0.6953037120359955,\n",
       "  0.7036882972823073,\n",
       "  0.6978223981900452,\n",
       "  0.699442119944212,\n",
       "  0.6939452585015206,\n",
       "  0.7021217197096594,\n",
       "  0.7058905834615923,\n",
       "  0.7084507042253522,\n",
       "  0.7072345226343252],\n",
       " 'model': TemporalEdgeClassifier(\n",
       "   (node_encoder): Sequential(\n",
       "     (0): Linear(in_features=15, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "   )\n",
       "   (gnn1): GATConv(256, 256, heads=4)\n",
       "   (gnn2): GATConv(256, 256, heads=2)\n",
       "   (dropout): Dropout(p=0.3, inplace=False)\n",
       "   (classifier): Sequential(\n",
       "     (0): Linear(in_features=265, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Dropout(p=0.3, inplace=False)\n",
       "     (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "     (4): ReLU()\n",
       "     (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82e25fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Function to compute and print confusion matrix\n",
    "def compute_confusion_matrix(labels, preds, threshold=0.5):\n",
    "\n",
    "    # Convert probabilities to binary predictions using the threshold\n",
    "    binary_preds = (preds >= threshold).astype(int)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(labels, binary_preds)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Optional: Extract and print TP, TN, FP, FN\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"False Negatives (FN): {fn}\")\n",
    "    print(f\"True Positives (TP): {tp}\")\n",
    "    print(f\"Precision: {tp / (tp + fp + 1e-8):.4f}\")\n",
    "    print(f\"Recall: {tp / (tp + fn + 1e-8):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51d19dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = results['test_probs']\n",
    "test_labels = results['test_labels']\n",
    "val_probs = results['val_probs']\n",
    "val_labels = results['val_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f1f36ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1457173     189]\n",
      " [    485     973]]\n",
      "True Negatives (TN): 1457173\n",
      "False Positives (FP): 189\n",
      "False Negatives (FN): 485\n",
      "True Positives (TP): 973\n",
      "Precision: 0.8373\n",
      "Recall: 0.6674\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(val_labels, val_probs, threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c31c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1382992     176]\n",
      " [    544    1097]]\n",
      "True Negatives (TN): 1382992\n",
      "False Positives (FP): 176\n",
      "False Negatives (FN): 544\n",
      "True Positives (TP): 1097\n",
      "Precision: 0.8617\n",
      "Recall: 0.6685\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(test_labels, test_probs, threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b1255f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC Score: 0.7309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate PR curve data\n",
    "precision, recall, thresholds = precision_recall_curve(test_labels, test_probs)\n",
    "pr_auc = average_precision_score(test_labels, test_probs)\n",
    "\n",
    "# Plot PR curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, linewidth=2, label=f'PR AUC = {pr_auc:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"PR AUC Score: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d663748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-backup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
