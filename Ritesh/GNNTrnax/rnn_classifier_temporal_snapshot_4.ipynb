{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83228cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Improved Temporal Graph Neural Network for Anti-Money Laundering Detection\n",
    "==========================================================================\n",
    "Optimized for F2 Score with structured code organization\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (precision_recall_curve, roc_auc_score, f1_score, \n",
    "                           precision_score, recall_score, fbeta_score, \n",
    "                           confusion_matrix, average_precision_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f74ecce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent.parent))  # Adjust as needed\n",
    "from config import DATAPATH, SAMPLE_DATAPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ddba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f457192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration class for hyperparameters and settings\"\"\"\n",
    "    # Model architecture\n",
    "    HIDDEN_DIM = 256  # Increased from 128\n",
    "    NODE_DIM = 15\n",
    "    EDGE_DIM = 9\n",
    "    DROPOUT_RATE = 0.3\n",
    "    \n",
    "    # Training parameters\n",
    "    LEARNING_RATE = 0.0005  # Reduced for better convergence\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    EPOCHS = 75\n",
    "    PATIENCE = 10\n",
    "    \n",
    "    # F2 score optimization\n",
    "    BETA = 2  # For F2 score (emphasizes recall)\n",
    "    CLASS_WEIGHT_MULTIPLIER = 10  # Strong emphasis on minority class\n",
    "\n",
    "    # Criterion parameters\n",
    "    FOCAL_LOSS_ALPHA = 0.25\n",
    "    FOCAL_LOSS_GAMMA = 2.0\n",
    "    \n",
    "    # Data processing\n",
    "    TIME_WINDOW = '7D'\n",
    "    VALIDATION_SPLIT = 0.17\n",
    "    TEST_SPLIT = 0.13\n",
    "    \n",
    "    # Threshold optimization\n",
    "    THRESHOLD_SEARCH_RANGE = np.arange(0.05, 0.95, 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0671bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for addressing class imbalance - better than BCE for F2 optimization\"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08365f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGraphDataProcessor:\n",
    "    \"\"\"Enhanced data processor with better feature engineering for F2 optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, time_window='7D'):\n",
    "        self.time_window = time_window\n",
    "        self.scalers = {}\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_and_preprocess(self, df):\n",
    "        \"\"\"Load SAML-D dataset and perform initial preprocessing\"\"\"\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        \n",
    "        # Combine date and time into datetime\n",
    "        df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "        df = df.sort_values('datetime').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Loaded {len(df)} transactions\")\n",
    "        print(f\"Suspicious transactions: {df['Is_laundering'].sum()} ({df['Is_laundering'].mean()*100:.3f}%)\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def engineer_features(self, df):\n",
    "        \"\"\"Enhanced feature engineering for better detection\"\"\"\n",
    "        print(\"Engineering enhanced features...\")\n",
    "        \n",
    "        # Time-based features (more granular)\n",
    "        df['hour'] = df['datetime'].dt.hour.astype('int8')\n",
    "        df['month'] = df['datetime'].dt.month.astype('int8')\n",
    "        df['day_of_week'] = df['datetime'].dt.dayofweek.astype('int8')\n",
    "        df['day_of_month'] = df['datetime'].dt.day.astype('int8')\n",
    "        df['is_weekend'] = (df['day_of_week'] >= 5).astype('int8')\n",
    "        df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 5)).astype('int8')  # Night transactions\n",
    "        \n",
    "        # Amount-based features\n",
    "        df['log_amount'] = np.log1p(df['Amount']).astype('float32')\n",
    "        \n",
    "        # Calculate amount percentiles for anomaly detection\n",
    "        # amount_percentiles = df['Amount'].quantile([0.95, 0.99]).values\n",
    "        # df['high_amount'] = (df['Amount'] > amount_percentiles[0]).astype('int8')\n",
    "        # df['very_high_amount'] = (df['Amount'] > amount_percentiles[1]).astype('int8')\n",
    "        \n",
    "        # Geographic risk features\n",
    "        df['cross_border'] = (df['Payment_type'] == 'Cross-border').astype('int8')\n",
    "        risky_countries = {'Mexico', 'Turkey', 'Morocco', 'UAE'}\n",
    "        df['high_risk_sender'] = df['Sender_bank_location'].isin(risky_countries).astype('int8')\n",
    "        df['high_risk_receiver'] = df['Receiver_bank_location'].isin(risky_countries).astype('int8')\n",
    "        # df['both_high_risk'] = (df['high_risk_sender'] & df['high_risk_receiver']).astype('int8')\n",
    "        \n",
    "        # Currency features\n",
    "        df['currency_mismatch'] = (df['Payment_currency'] != df['Received_currency']).astype('int8')\n",
    "        \n",
    "        # Convert target\n",
    "        df['Is_laundering'] = df['Is_laundering'].astype('int8')\n",
    "        \n",
    "        # Clean up\n",
    "        columns_to_drop = ['Date', 'Time', 'Amount', 'Sender_bank_location', \n",
    "                          'Receiver_bank_location', 'Payment_currency', 'Received_currency', \n",
    "                          'Laundering_type']\n",
    "        df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_temporal_snapshots(self, df, account_features):\n",
    "        \"\"\"Create temporal graph snapshots with enhanced features\"\"\"\n",
    "        print(\"Creating temporal graph snapshots...\")\n",
    "        \n",
    "        # Global account mapping\n",
    "        all_accounts = list(set(df['Sender_account'].unique()) | set(df['Receiver_account'].unique()))\n",
    "        global_account_to_idx = {acc: idx for idx, acc in enumerate(all_accounts)}\n",
    "        global_num_nodes = len(all_accounts)\n",
    "        \n",
    "        # Time windows\n",
    "        start_date = df['datetime'].min().normalize().date()\n",
    "        end_date = df['datetime'].max().normalize().date()\n",
    "        \n",
    "        snapshots = []\n",
    "        print(f\"Processing time range: {start_date} to {end_date}\")\n",
    "\n",
    "        for window_start in pd.date_range(start=start_date, end=end_date, freq=self.time_window, inclusive='left'):\n",
    "            window_end = window_start + pd.Timedelta(days=7)\n",
    "            window_start_str = pd.to_datetime(window_start).strftime('%Y-%m-%d')\n",
    "            window_end_str = pd.to_datetime(window_end).strftime('%Y-%m-%d')\n",
    "            print(f\"Processing window: {window_start_str} to {window_end_str}\")\n",
    "            \n",
    "            # Get transactions in current window\n",
    "            window_mask = (df['datetime'] >= window_start_str) & (df['datetime'] < window_end_str)\n",
    "            window_trnx_data = df[window_mask].copy()\n",
    "            \n",
    "            # Account features for this window\n",
    "            window_accounts_features = account_features[account_features['window_start'] == window_start_str]\n",
    "            \n",
    "            if len(window_trnx_data) > 0:\n",
    "                graph_data = self._create_graph_snapshot(\n",
    "                    window_trnx_data, window_accounts_features,\n",
    "                    window_start_str, global_account_to_idx, global_num_nodes\n",
    "                )\n",
    "                if graph_data is not None:\n",
    "                    snapshots.append(graph_data)\n",
    "\n",
    "        print(f\"Created {len(snapshots)} temporal snapshots\")\n",
    "        return snapshots, global_num_nodes\n",
    "\n",
    "    def _create_graph_snapshot(self, window_trnx_data, window_accounts_features, \n",
    "                              timestamp, global_account_to_idx, global_num_nodes):\n",
    "        \"\"\"Create enhanced graph snapshot\"\"\"\n",
    "        if len(window_trnx_data) == 0:\n",
    "            return None\n",
    "\n",
    "        # Enhanced edge features\n",
    "        edge_feature_columns = [\n",
    "            'Payment_type_encoded', 'log_amount', 'month', 'day_of_week', 'hour', \n",
    "            'currency_mismatch', 'cross_border', 'high_risk_sender', 'high_risk_receiver',\n",
    "        ]\n",
    "        \n",
    "        # Filter available columns\n",
    "        edge_feature_columns = [col for col in edge_feature_columns if col in window_trnx_data.columns]\n",
    "\n",
    "        # Node features\n",
    "        node_feature_columns = ['sent_txns_count', 'fan_out', 'recv_txns_count', 'fan_in', \n",
    "                               'max_sent_txn_count', 'max_recv_txn_count', 'sent_recv_ratio', \n",
    "                               'fanout_fanin_ratio', 'log_med_sent_amt', 'log_std_sent_amt', \n",
    "                               'log_med_recv_amt', 'log_std_recv_amt', 'log_max_sent_txn_amt', \n",
    "                               'log_max_recv_txn_amt', 'log_total_txns_amt']\n",
    "\n",
    "        # Create mappings and features\n",
    "        sender_mapped = window_trnx_data['Sender_account'].map(global_account_to_idx)\n",
    "        receiver_mapped = window_trnx_data['Receiver_account'].map(global_account_to_idx)\n",
    "        edge_index = np.column_stack((sender_mapped, receiver_mapped))\n",
    "        edge_features = window_trnx_data[edge_feature_columns].values\n",
    "        transaction_labels = window_trnx_data['Is_laundering'].values\n",
    "\n",
    "        # Node features\n",
    "        node_features = np.zeros((global_num_nodes, len(node_feature_columns)))\n",
    "        try:\n",
    "            window_accounts_features['global_idx'] = window_accounts_features['account'].map(global_account_to_idx)\n",
    "            node_features[window_accounts_features['global_idx'].values] = window_accounts_features[node_feature_columns].values\n",
    "        except: \n",
    "            raise ValueError(\"Error in mapping account features to global indices.\")\n",
    "\n",
    "        # Convert to tensors\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "        edge_features = torch.tensor(edge_features, dtype=torch.float)\n",
    "        transaction_labels = torch.tensor(transaction_labels, dtype=torch.float)\n",
    "\n",
    "        return Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_features,\n",
    "            y=transaction_labels,\n",
    "            timestamp=timestamp,\n",
    "            num_nodes=global_num_nodes\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e55e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal GNN Model for Edge Classification\n",
    "class TemporalEdgeClassifier(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, dropout_rate):\n",
    "        super(TemporalEdgeClassifier, self).__init__()\n",
    "        self.rnn = nn.GRUCell(node_dim, hidden_dim)\n",
    "        self.gnn1 = GATConv(hidden_dim, hidden_dim, heads=2, concat=False)\n",
    "        self.gnn2 = GATConv(hidden_dim, hidden_dim, heads=2, concat=False)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.classifier = nn.Linear(hidden_dim * 2 + edge_dim, 1)  # Binary classification\n",
    "\n",
    "    def forward(self, data, h):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        \n",
    "        # Update node hidden states with RNN (using current x)\n",
    "        h = self.rnn(x, h)\n",
    "        \n",
    "        # Apply GNN layers\n",
    "        h = F.relu(self.gnn1(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.gnn2(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        \n",
    "        # Edge features: concat sender h, receiver h, edge_attr\n",
    "        h_i = h[edge_index[0]]\n",
    "        h_j = h[edge_index[1]]\n",
    "        edge_input = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
    "        \n",
    "        # Prediction\n",
    "        out = self.classifier(edge_input)\n",
    "        \n",
    "        return out, h  # Return logits and updated h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59dd2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"Enhanced trainer class optimized for F2 score\"\"\"\n",
    "    \n",
    "    def __init__(self, config=Config()):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "    \n",
    "    def find_optimal_threshold(self, probs, labels):\n",
    "        \"\"\"Find optimal threshold for F2 score\"\"\"\n",
    "        best_f2 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in self.config.THRESHOLD_SEARCH_RANGE:\n",
    "            preds = (probs >= threshold).astype(int)\n",
    "            f2 = fbeta_score(labels, preds, beta=self.config.BETA, average='binary', zero_division=0)\n",
    "            if f2 > best_f2:\n",
    "                best_f2 = f2\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        return best_threshold, best_f2\n",
    "    \n",
    "    def compute_class_weights(self, snapshots):\n",
    "        \"\"\"Compute class weights for focal loss\"\"\"\n",
    "        all_labels = []\n",
    "        for snap in snapshots:\n",
    "            all_labels.extend(snap.y.cpu().numpy())\n",
    "        \n",
    "        all_labels = np.array(all_labels)\n",
    "        pos_weight = len(all_labels) / (2 * np.sum(all_labels))\n",
    "        return torch.tensor(pos_weight, dtype=torch.float).to(self.device)\n",
    "    \n",
    "    def train_model(self, snapshots, global_num_nodes):\n",
    "        \"\"\"Enhanced training with F2 optimization\"\"\"\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(len(snapshots) * (1 - self.config.VALIDATION_SPLIT - self.config.TEST_SPLIT))\n",
    "        val_size = int(len(snapshots) * self.config.VALIDATION_SPLIT)\n",
    "        \n",
    "        train_snaps = snapshots[:train_size]\n",
    "        val_snaps = snapshots[train_size:train_size + val_size]\n",
    "        test_snaps = snapshots[train_size + val_size:]\n",
    "        \n",
    "        print(f\"Data split - Train: {len(train_snaps)}, Val: {len(val_snaps)}, Test: {len(test_snaps)}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = TemporalEdgeClassifier(\n",
    "            self.config.NODE_DIM, \n",
    "            self.config.EDGE_DIM, \n",
    "            self.config.HIDDEN_DIM,\n",
    "            self.config.DROPOUT_RATE\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Compute class weights for focal loss\n",
    "        pos_weight = self.compute_class_weights(train_snaps)\n",
    "        criterion = FocalLoss(alpha=self.config.FOCAL_LOSS_ALPHA, gamma=self.config.FOCAL_LOSS_GAMMA)\n",
    "        \n",
    "        # Optimizer with different learning rates for different components\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': model.rnn.parameters(), 'lr': self.config.LEARNING_RATE * 0.5},\n",
    "            {'params': model.gnn1.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.gnn2.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            # {'params': model.gnn3.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.classifier.parameters(), 'lr': self.config.LEARNING_RATE * 1.5}\n",
    "        ], weight_decay=self.config.WEIGHT_DECAY)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.7, patience=5, verbose=True\n",
    "        )\n",
    "        \n",
    "        # Training loop\n",
    "        best_f2_score = 0\n",
    "        patience_counter = 0\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "        f2_history = []\n",
    "        \n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "            \n",
    "            for snap in train_snaps:\n",
    "                snap = snap.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                out, h = model(snap, h.detach())  # Detach to prevent gradient explosion\n",
    "                loss = criterion(out.squeeze(), snap.y)\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_snaps)\n",
    "            train_loss_history.append(avg_train_loss)\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_probs_list, val_labels_list = [], []\n",
    "            val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "                for snap in val_snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, h = model(snap, h)\n",
    "                    loss = criterion(out.squeeze(), snap.y)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    preds = torch.sigmoid(out).squeeze()\n",
    "                    val_probs_list.append(preds.cpu())\n",
    "                    val_labels_list.append(snap.y.cpu())\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_snaps)\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "            \n",
    "            # Scale\n",
    "            avg_train_loss *= 1000\n",
    "            avg_val_loss *= 1000\n",
    "            \n",
    "            # Calculate F2 score with optimal threshold\n",
    "            val_probs = torch.cat(val_probs_list).numpy()\n",
    "            val_labels = torch.cat(val_labels_list).numpy()\n",
    "            \n",
    "            optimal_threshold, f2_score = self.find_optimal_threshold(val_probs, val_labels)\n",
    "            f2_history.append(f2_score)\n",
    "            recall = recall_score(val_labels, (val_probs >= optimal_threshold).astype(int), zero_division=0)\n",
    "            \n",
    "            scheduler.step(f2_score)\n",
    "            \n",
    "            # Early stopping based on F2 score\n",
    "            if f2_score > best_f2_score:\n",
    "                best_f2_score = f2_score\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                # torch.save(model.state_dict(), './outputs/best_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}: Train Loss(x1e3): {avg_train_loss:.4f}, Val Loss(x1e3): {avg_val_loss:.4f}, \"\n",
    "                        f\"F2: {f2_score:.4f}, Threshold: {optimal_threshold:.3f}, Recall: {recall:.4f}\")\n",
    "            \n",
    "            if patience_counter >= self.config.PATIENCE:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # Load best model and evaluate\n",
    "        # model.load_state_dict(torch.load('./outputs/best_model.pth'))\n",
    "        \n",
    "        # Final evaluation\n",
    "        results = self._evaluate_model(model, train_snaps, val_snaps, test_snaps, global_num_nodes)\n",
    "        results.update({\n",
    "            'train_loss_history': train_loss_history,\n",
    "            'val_loss_history': val_loss_history,\n",
    "            'f2_history': f2_history,\n",
    "            'model': model\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_model(self, model, train_snaps, val_snaps, test_snaps, global_num_nodes):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        model.eval()\n",
    "        results = {}\n",
    "        \n",
    "        for split_name, snaps in [('val', val_snaps), ('test', test_snaps)]:\n",
    "            probs_list, labels_list = [], []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "                for snap in snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, h = model(snap, h)\n",
    "                    preds = torch.sigmoid(out).squeeze().cpu().numpy()\n",
    "                    probs_list.extend(preds)\n",
    "                    labels_list.extend(snap.y.cpu().numpy())\n",
    "            \n",
    "            probs = np.array(probs_list)\n",
    "            labels = np.array(labels_list)\n",
    "            \n",
    "            # Find optimal threshold\n",
    "            optimal_threshold, best_f2 = self.find_optimal_threshold(probs, labels)\n",
    "            binary_preds = (probs >= optimal_threshold).astype(int)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            precision = precision_score(labels, binary_preds, zero_division=0)\n",
    "            recall = recall_score(labels, binary_preds, zero_division=0)\n",
    "            f1 = f1_score(labels, binary_preds, zero_division=0)\n",
    "            roc_auc = roc_auc_score(labels, probs)\n",
    "            pr_auc = average_precision_score(labels, probs)\n",
    "            \n",
    "            results[f'{split_name}_probs'] = probs\n",
    "            results[f'{split_name}_labels'] = labels\n",
    "            results[f'{split_name}_threshold'] = optimal_threshold\n",
    "            results[f'{split_name}_precision'] = precision\n",
    "            results[f'{split_name}_recall'] = recall\n",
    "            results[f'{split_name}_f1'] = f1\n",
    "            results[f'{split_name}_f2'] = best_f2\n",
    "            results[f'{split_name}_roc_auc'] = roc_auc\n",
    "            results[f'{split_name}_pr_auc'] = pr_auc\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2124555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset\n",
    "df = pd.read_csv(DATAPATH)\n",
    "\n",
    "# Filter by data range\n",
    "# df = df[df['Date'] < '2023-08-18']\n",
    "# df = df.head(300000).copy()\n",
    "\n",
    "# run feature engg.ipynb to get the account_stats_7D.csv\n",
    "account_stats = pd.read_csv('../account_stats_7D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9178de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Loaded 9504852 transactions\n",
      "Suspicious transactions: 9873 (0.104%)\n",
      "Engineering enhanced features...\n"
     ]
    }
   ],
   "source": [
    "graph_processor = TemporalGraphDataProcessor()\n",
    "df = graph_processor.load_and_preprocess(df)\n",
    "df = graph_processor.engineer_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8bfb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For each categorical column\n",
    "# categorical_cols = ['Payment_currency', 'Received_currency', 'Sender_bank_location', \n",
    "#                    'Receiver_bank_location', 'Payment_type']\n",
    "categorical_cols = ['Payment_type']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "# Drop original object columns\n",
    "df = df.drop(categorical_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43c740f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process accont_stats\n",
    "columns = ['med_sent_amt', 'std_sent_amt', 'med_recv_amt', 'std_recv_amt', \n",
    "           'max_sent_txn_amt', 'max_recv_txn_amt', 'total_txns_amt']\n",
    "\n",
    "for col in columns:\n",
    "    account_stats['log_' + col] = np.log1p(account_stats[col]).astype('float32')\n",
    "\n",
    "account_stats = account_stats.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "094d1677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data types to optimize memory\n",
    "account_stats = account_stats.astype({\n",
    "    'sent_txns_count': 'int32',\n",
    "    'recv_txns_count': 'int32',\n",
    "    'fan_out': 'int32',\n",
    "    'fan_in': 'int32',\n",
    "    'max_sent_txn_count': 'int32',\n",
    "    'max_recv_txn_count': 'int32',\n",
    "    'sent_recv_ratio': 'float32',\n",
    "    'fanout_fanin_ratio': 'float32'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79bf8e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporal graph snapshots...\n",
      "Processing time range: 2022-10-07 to 2023-08-23\n",
      "Processing window: 2022-10-07 to 2022-10-14\n",
      "Processing window: 2022-10-14 to 2022-10-21\n",
      "Processing window: 2022-10-21 to 2022-10-28\n",
      "Processing window: 2022-10-28 to 2022-11-04\n",
      "Processing window: 2022-11-04 to 2022-11-11\n",
      "Processing window: 2022-11-11 to 2022-11-18\n",
      "Processing window: 2022-11-18 to 2022-11-25\n",
      "Processing window: 2022-11-25 to 2022-12-02\n",
      "Processing window: 2022-12-02 to 2022-12-09\n",
      "Processing window: 2022-12-09 to 2022-12-16\n",
      "Processing window: 2022-12-16 to 2022-12-23\n",
      "Processing window: 2022-12-23 to 2022-12-30\n",
      "Processing window: 2022-12-30 to 2023-01-06\n",
      "Processing window: 2023-01-06 to 2023-01-13\n",
      "Processing window: 2023-01-13 to 2023-01-20\n",
      "Processing window: 2023-01-20 to 2023-01-27\n",
      "Processing window: 2023-01-27 to 2023-02-03\n",
      "Processing window: 2023-02-03 to 2023-02-10\n",
      "Processing window: 2023-02-10 to 2023-02-17\n",
      "Processing window: 2023-02-17 to 2023-02-24\n",
      "Processing window: 2023-02-24 to 2023-03-03\n",
      "Processing window: 2023-03-03 to 2023-03-10\n",
      "Processing window: 2023-03-10 to 2023-03-17\n",
      "Processing window: 2023-03-17 to 2023-03-24\n",
      "Processing window: 2023-03-24 to 2023-03-31\n",
      "Processing window: 2023-03-31 to 2023-04-07\n",
      "Processing window: 2023-04-07 to 2023-04-14\n",
      "Processing window: 2023-04-14 to 2023-04-21\n",
      "Processing window: 2023-04-21 to 2023-04-28\n",
      "Processing window: 2023-04-28 to 2023-05-05\n",
      "Processing window: 2023-05-05 to 2023-05-12\n",
      "Processing window: 2023-05-12 to 2023-05-19\n",
      "Processing window: 2023-05-19 to 2023-05-26\n",
      "Processing window: 2023-05-26 to 2023-06-02\n",
      "Processing window: 2023-06-02 to 2023-06-09\n",
      "Processing window: 2023-06-09 to 2023-06-16\n",
      "Processing window: 2023-06-16 to 2023-06-23\n",
      "Processing window: 2023-06-23 to 2023-06-30\n",
      "Processing window: 2023-06-30 to 2023-07-07\n",
      "Processing window: 2023-07-07 to 2023-07-14\n",
      "Processing window: 2023-07-14 to 2023-07-21\n",
      "Processing window: 2023-07-21 to 2023-07-28\n",
      "Processing window: 2023-07-28 to 2023-08-04\n",
      "Processing window: 2023-08-04 to 2023-08-11\n",
      "Processing window: 2023-08-11 to 2023-08-18\n",
      "Processing window: 2023-08-18 to 2023-08-25\n",
      "Created 46 temporal snapshots\n"
     ]
    }
   ],
   "source": [
    "snapshots, global_num_nodes = graph_processor.create_temporal_snapshots(df, account_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89fc6783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Data split - Train: 32, Val: 7, Test: 7\n",
      "Epoch 1: Train Loss(x1e3): 6.0528, Val Loss(x1e3): 1.0555, F2: 0.0059, Threshold: 0.050, Recall: 0.0103\n",
      "Epoch 2: Train Loss(x1e3): 0.7969, Val Loss(x1e3): 0.6501, F2: 0.0101, Threshold: 0.150, Recall: 0.0274\n",
      "Epoch 3: Train Loss(x1e3): 0.6773, Val Loss(x1e3): 0.6558, F2: 0.0097, Threshold: 0.050, Recall: 0.7743\n",
      "Epoch 4: Train Loss(x1e3): 0.6656, Val Loss(x1e3): 0.6375, F2: 0.0145, Threshold: 0.100, Recall: 0.1420\n",
      "Epoch 5: Train Loss(x1e3): 0.6503, Val Loss(x1e3): 0.6299, F2: 0.0183, Threshold: 0.100, Recall: 0.1859\n",
      "Epoch 6: Train Loss(x1e3): 0.6426, Val Loss(x1e3): 0.6214, F2: 0.0209, Threshold: 0.100, Recall: 0.2181\n",
      "Epoch 7: Train Loss(x1e3): 0.6336, Val Loss(x1e3): 0.6142, F2: 0.0235, Threshold: 0.100, Recall: 0.2538\n",
      "Epoch 8: Train Loss(x1e3): 0.6242, Val Loss(x1e3): 0.6016, F2: 0.0271, Threshold: 0.100, Recall: 0.3045\n",
      "Epoch 9: Train Loss(x1e3): 0.6164, Val Loss(x1e3): 0.5889, F2: 0.0305, Threshold: 0.100, Recall: 0.3669\n",
      "Epoch 10: Train Loss(x1e3): 0.6009, Val Loss(x1e3): 0.5623, F2: 0.0609, Threshold: 0.150, Recall: 0.1358\n",
      "Epoch 11: Train Loss(x1e3): 0.5786, Val Loss(x1e3): 0.5448, F2: 0.0846, Threshold: 0.200, Recall: 0.0837\n",
      "Epoch 12: Train Loss(x1e3): 0.5606, Val Loss(x1e3): 0.5317, F2: 0.1093, Threshold: 0.200, Recall: 0.1152\n",
      "Epoch 13: Train Loss(x1e3): 0.5495, Val Loss(x1e3): 0.5236, F2: 0.1221, Threshold: 0.200, Recall: 0.1262\n",
      "Epoch 14: Train Loss(x1e3): 0.5394, Val Loss(x1e3): 0.5162, F2: 0.1361, Threshold: 0.200, Recall: 0.1385\n",
      "Epoch 15: Train Loss(x1e3): 0.5263, Val Loss(x1e3): 0.5054, F2: 0.1528, Threshold: 0.200, Recall: 0.1529\n",
      "Epoch 16: Train Loss(x1e3): 0.5177, Val Loss(x1e3): 0.4930, F2: 0.1704, Threshold: 0.200, Recall: 0.1694\n",
      "Epoch 17: Train Loss(x1e3): 0.5037, Val Loss(x1e3): 0.4794, F2: 0.1800, Threshold: 0.200, Recall: 0.1776\n",
      "Epoch 18: Train Loss(x1e3): 0.4888, Val Loss(x1e3): 0.4671, F2: 0.1957, Threshold: 0.200, Recall: 0.1900\n",
      "Epoch 19: Train Loss(x1e3): 0.4765, Val Loss(x1e3): 0.4502, F2: 0.2136, Threshold: 0.200, Recall: 0.2140\n",
      "Epoch 20: Train Loss(x1e3): 0.4611, Val Loss(x1e3): 0.4353, F2: 0.2320, Threshold: 0.150, Recall: 0.3704\n",
      "Epoch 21: Train Loss(x1e3): 0.4446, Val Loss(x1e3): 0.4212, F2: 0.2542, Threshold: 0.200, Recall: 0.2620\n",
      "Epoch 22: Train Loss(x1e3): 0.4278, Val Loss(x1e3): 0.4102, F2: 0.2735, Threshold: 0.200, Recall: 0.3018\n",
      "Epoch 23: Train Loss(x1e3): 0.4049, Val Loss(x1e3): 0.3944, F2: 0.2742, Threshold: 0.200, Recall: 0.3464\n",
      "Epoch 24: Train Loss(x1e3): 0.3821, Val Loss(x1e3): 0.3748, F2: 0.3021, Threshold: 0.200, Recall: 0.3923\n",
      "Epoch 25: Train Loss(x1e3): 0.3655, Val Loss(x1e3): 0.3568, F2: 0.3224, Threshold: 0.200, Recall: 0.4630\n",
      "Epoch 26: Train Loss(x1e3): 0.3516, Val Loss(x1e3): 0.3559, F2: 0.3384, Threshold: 0.250, Recall: 0.3697\n",
      "Epoch 27: Train Loss(x1e3): 0.3331, Val Loss(x1e3): 0.3281, F2: 0.3919, Threshold: 0.250, Recall: 0.4287\n",
      "Epoch 28: Train Loss(x1e3): 0.3151, Val Loss(x1e3): 0.3182, F2: 0.4275, Threshold: 0.250, Recall: 0.4794\n",
      "Epoch 29: Train Loss(x1e3): 0.3047, Val Loss(x1e3): 0.3040, F2: 0.4467, Threshold: 0.250, Recall: 0.5130\n",
      "Epoch 30: Train Loss(x1e3): 0.2930, Val Loss(x1e3): 0.3282, F2: 0.3844, Threshold: 0.300, Recall: 0.4609\n",
      "Epoch 31: Train Loss(x1e3): 0.3105, Val Loss(x1e3): 0.3007, F2: 0.4628, Threshold: 0.250, Recall: 0.5247\n",
      "Epoch 32: Train Loss(x1e3): 0.2752, Val Loss(x1e3): 0.2758, F2: 0.4952, Threshold: 0.300, Recall: 0.4966\n",
      "Epoch 33: Train Loss(x1e3): 0.2673, Val Loss(x1e3): 0.2683, F2: 0.5183, Threshold: 0.300, Recall: 0.5137\n",
      "Epoch 34: Train Loss(x1e3): 0.2541, Val Loss(x1e3): 0.2686, F2: 0.5398, Threshold: 0.300, Recall: 0.5521\n",
      "Epoch 35: Train Loss(x1e3): 0.2436, Val Loss(x1e3): 0.2561, F2: 0.5504, Threshold: 0.300, Recall: 0.5528\n",
      "Epoch 36: Train Loss(x1e3): 0.2367, Val Loss(x1e3): 0.2609, F2: 0.5545, Threshold: 0.300, Recall: 0.5844\n",
      "Epoch 37: Train Loss(x1e3): 0.2310, Val Loss(x1e3): 0.2527, F2: 0.5522, Threshold: 0.300, Recall: 0.6104\n",
      "Epoch 38: Train Loss(x1e3): 0.2211, Val Loss(x1e3): 0.2425, F2: 0.5726, Threshold: 0.300, Recall: 0.6180\n",
      "Epoch 39: Train Loss(x1e3): 0.2171, Val Loss(x1e3): 0.2366, F2: 0.5791, Threshold: 0.300, Recall: 0.5988\n",
      "Epoch 40: Train Loss(x1e3): 0.2115, Val Loss(x1e3): 0.2403, F2: 0.5861, Threshold: 0.350, Recall: 0.5796\n",
      "Epoch 41: Train Loss(x1e3): 0.2039, Val Loss(x1e3): 0.2233, F2: 0.5972, Threshold: 0.350, Recall: 0.5830\n",
      "Epoch 42: Train Loss(x1e3): 0.1976, Val Loss(x1e3): 0.2271, F2: 0.6241, Threshold: 0.350, Recall: 0.6248\n",
      "Epoch 43: Train Loss(x1e3): 0.1950, Val Loss(x1e3): 0.2125, F2: 0.6317, Threshold: 0.350, Recall: 0.6173\n",
      "Epoch 44: Train Loss(x1e3): 0.1836, Val Loss(x1e3): 0.2198, F2: 0.6329, Threshold: 0.350, Recall: 0.6337\n",
      "Epoch 45: Train Loss(x1e3): 0.1846, Val Loss(x1e3): 0.2140, F2: 0.6375, Threshold: 0.350, Recall: 0.6461\n",
      "Epoch 46: Train Loss(x1e3): 0.1755, Val Loss(x1e3): 0.1984, F2: 0.6602, Threshold: 0.350, Recall: 0.6502\n",
      "Epoch 47: Train Loss(x1e3): 0.1741, Val Loss(x1e3): 0.2071, F2: 0.6595, Threshold: 0.350, Recall: 0.6646\n",
      "Epoch 48: Train Loss(x1e3): 0.1684, Val Loss(x1e3): 0.1951, F2: 0.6669, Threshold: 0.350, Recall: 0.6708\n",
      "Epoch 49: Train Loss(x1e3): 0.1728, Val Loss(x1e3): 0.1869, F2: 0.6749, Threshold: 0.350, Recall: 0.6715\n",
      "Epoch 50: Train Loss(x1e3): 0.1659, Val Loss(x1e3): 0.1922, F2: 0.6772, Threshold: 0.350, Recall: 0.6886\n",
      "Epoch 51: Train Loss(x1e3): 0.1652, Val Loss(x1e3): 0.1815, F2: 0.6792, Threshold: 0.350, Recall: 0.6694\n",
      "Epoch 52: Train Loss(x1e3): 0.1556, Val Loss(x1e3): 0.1946, F2: 0.6745, Threshold: 0.400, Recall: 0.6536\n",
      "Epoch 53: Train Loss(x1e3): 0.1575, Val Loss(x1e3): 0.1774, F2: 0.6895, Threshold: 0.350, Recall: 0.6872\n",
      "Epoch 54: Train Loss(x1e3): 0.1521, Val Loss(x1e3): 0.1825, F2: 0.6890, Threshold: 0.350, Recall: 0.6955\n",
      "Epoch 55: Train Loss(x1e3): 0.1517, Val Loss(x1e3): 0.1774, F2: 0.6957, Threshold: 0.350, Recall: 0.7099\n",
      "Epoch 56: Train Loss(x1e3): 0.1519, Val Loss(x1e3): 0.1710, F2: 0.6996, Threshold: 0.350, Recall: 0.7030\n",
      "Epoch 57: Train Loss(x1e3): 0.1467, Val Loss(x1e3): 0.1793, F2: 0.7058, Threshold: 0.350, Recall: 0.7263\n",
      "Epoch 58: Train Loss(x1e3): 0.1457, Val Loss(x1e3): 0.1653, F2: 0.7144, Threshold: 0.350, Recall: 0.7160\n",
      "Epoch 59: Train Loss(x1e3): 0.1423, Val Loss(x1e3): 0.1749, F2: 0.7095, Threshold: 0.350, Recall: 0.7325\n",
      "Epoch 60: Train Loss(x1e3): 0.1481, Val Loss(x1e3): 0.1594, F2: 0.7163, Threshold: 0.300, Recall: 0.7483\n",
      "Epoch 61: Train Loss(x1e3): 0.1326, Val Loss(x1e3): 0.1846, F2: 0.7085, Threshold: 0.400, Recall: 0.7099\n",
      "Epoch 62: Train Loss(x1e3): 0.1475, Val Loss(x1e3): 0.1569, F2: 0.7212, Threshold: 0.300, Recall: 0.7421\n",
      "Epoch 63: Train Loss(x1e3): 0.1348, Val Loss(x1e3): 0.1683, F2: 0.7149, Threshold: 0.350, Recall: 0.7401\n",
      "Epoch 64: Train Loss(x1e3): 0.1356, Val Loss(x1e3): 0.1565, F2: 0.7252, Threshold: 0.300, Recall: 0.7407\n",
      "Epoch 65: Train Loss(x1e3): 0.1266, Val Loss(x1e3): 0.1707, F2: 0.7196, Threshold: 0.400, Recall: 0.7222\n",
      "Epoch 66: Train Loss(x1e3): 0.1323, Val Loss(x1e3): 0.1477, F2: 0.7442, Threshold: 0.300, Recall: 0.7627\n",
      "Epoch 67: Train Loss(x1e3): 0.1228, Val Loss(x1e3): 0.1844, F2: 0.7026, Threshold: 0.400, Recall: 0.7263\n",
      "Epoch 68: Train Loss(x1e3): 0.1362, Val Loss(x1e3): 0.1456, F2: 0.7415, Threshold: 0.300, Recall: 0.7675\n",
      "Epoch 69: Train Loss(x1e3): 0.1222, Val Loss(x1e3): 0.1555, F2: 0.7335, Threshold: 0.350, Recall: 0.7565\n",
      "Epoch 70: Train Loss(x1e3): 0.1250, Val Loss(x1e3): 0.1418, F2: 0.7524, Threshold: 0.300, Recall: 0.7840\n",
      "Epoch 71: Train Loss(x1e3): 0.1191, Val Loss(x1e3): 0.1530, F2: 0.7401, Threshold: 0.350, Recall: 0.7627\n",
      "Epoch 72: Train Loss(x1e3): 0.1266, Val Loss(x1e3): 0.1433, F2: 0.7568, Threshold: 0.300, Recall: 0.7798\n",
      "Epoch 73: Train Loss(x1e3): 0.1180, Val Loss(x1e3): 0.1579, F2: 0.7292, Threshold: 0.400, Recall: 0.7318\n",
      "Epoch 74: Train Loss(x1e3): 0.1241, Val Loss(x1e3): 0.1376, F2: 0.7566, Threshold: 0.350, Recall: 0.7599\n",
      "Epoch 75: Train Loss(x1e3): 0.1198, Val Loss(x1e3): 0.1399, F2: 0.7621, Threshold: 0.350, Recall: 0.7723\n"
     ]
    }
   ],
   "source": [
    "trainer = ModelTrainer(config=Config())\n",
    "results = trainer.train_model(snapshots, global_num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb0d7038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_probs': array([0.07899866, 0.07995822, 0.00606675, ..., 0.01257651, 0.00890599,\n",
       "        0.00903852], shape=(1458820,), dtype=float32),\n",
       " 'val_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1458820,), dtype=float32),\n",
       " 'val_threshold': np.float64(0.35000000000000003),\n",
       " 'val_precision': 0.7241157556270097,\n",
       " 'val_recall': 0.7722908093278463,\n",
       " 'val_f1': 0.7474278128111517,\n",
       " 'val_f2': 0.7621497224854474,\n",
       " 'val_roc_auc': 0.9937157993132749,\n",
       " 'val_pr_auc': 0.798174630665277,\n",
       " 'test_probs': array([0.00250259, 0.00191039, 0.00267571, ..., 0.00906547, 0.171373  ,\n",
       "        0.01048531], shape=(1384809,), dtype=float32),\n",
       " 'test_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1384809,), dtype=float32),\n",
       " 'test_threshold': np.float64(0.35000000000000003),\n",
       " 'test_precision': 0.6040299906279287,\n",
       " 'test_recall': 0.785496648385131,\n",
       " 'test_f1': 0.6829139072847682,\n",
       " 'test_f2': 0.7409749367670729,\n",
       " 'test_roc_auc': 0.994747991703762,\n",
       " 'test_pr_auc': 0.7729621324675919,\n",
       " 'train_loss_history': [0.006052789984096307,\n",
       "  0.0007968635036377236,\n",
       "  0.0006772688248020131,\n",
       "  0.0006655827564827632,\n",
       "  0.0006502643245767104,\n",
       "  0.000642572354990989,\n",
       "  0.0006335758389468538,\n",
       "  0.000624210661953839,\n",
       "  0.0006163712814668543,\n",
       "  0.0006009145745338174,\n",
       "  0.0005786017018181155,\n",
       "  0.0005605720034509432,\n",
       "  0.0005495498126038001,\n",
       "  0.0005394254048951552,\n",
       "  0.0005263239190753666,\n",
       "  0.000517691833920253,\n",
       "  0.000503699814544234,\n",
       "  0.0004888453577223117,\n",
       "  0.0004764572886415408,\n",
       "  0.0004610630730894627,\n",
       "  0.0004446444718269049,\n",
       "  0.0004278284413885558,\n",
       "  0.00040486487523594406,\n",
       "  0.00038207372972465237,\n",
       "  0.0003654887595985201,\n",
       "  0.00035156443482264876,\n",
       "  0.00033305981787634664,\n",
       "  0.0003151011392219516,\n",
       "  0.00030468534532701597,\n",
       "  0.0002930284917965764,\n",
       "  0.00031054807959662867,\n",
       "  0.0002752379232333624,\n",
       "  0.0002672560281098413,\n",
       "  0.0002540700634199311,\n",
       "  0.00024364219780181884,\n",
       "  0.00023666138667977066,\n",
       "  0.00023099750114852213,\n",
       "  0.00022111290354587254,\n",
       "  0.00021708129042963265,\n",
       "  0.00021151681767150876,\n",
       "  0.00020388084294609143,\n",
       "  0.00019762997817451833,\n",
       "  0.00019501883366501715,\n",
       "  0.0001836409524003102,\n",
       "  0.00018458077215655067,\n",
       "  0.00017554618557369395,\n",
       "  0.00017407570999239397,\n",
       "  0.0001684081998973852,\n",
       "  0.0001727730630136648,\n",
       "  0.00016586079300395795,\n",
       "  0.00016518244524377224,\n",
       "  0.00015555678101009107,\n",
       "  0.00015754512696730671,\n",
       "  0.00015210740752991114,\n",
       "  0.000151734560404293,\n",
       "  0.00015190868498393684,\n",
       "  0.0001467374736421334,\n",
       "  0.00014565694755219738,\n",
       "  0.0001423163578238018,\n",
       "  0.00014809026515649748,\n",
       "  0.00013257826844892406,\n",
       "  0.00014746967576684256,\n",
       "  0.0001347589779925329,\n",
       "  0.00013555402983911335,\n",
       "  0.0001266488127384946,\n",
       "  0.00013231921820988646,\n",
       "  0.00012280467285563645,\n",
       "  0.00013624838334180822,\n",
       "  0.00012222935970385151,\n",
       "  0.00012496742283474305,\n",
       "  0.00011905424139513343,\n",
       "  0.00012663706274906872,\n",
       "  0.0001179935140953603,\n",
       "  0.00012409482292241591,\n",
       "  0.00011978844304394443],\n",
       " 'val_loss_history': [0.0010555459219696267,\n",
       "  0.0006501400785055012,\n",
       "  0.0006558115710504353,\n",
       "  0.0006374824900246624,\n",
       "  0.0006298638098607105,\n",
       "  0.0006214421300683171,\n",
       "  0.0006142079572392893,\n",
       "  0.0006015849441090333,\n",
       "  0.0005888910091016442,\n",
       "  0.0005622713153050947,\n",
       "  0.0005447946771580194,\n",
       "  0.0005316601974690067,\n",
       "  0.000523644029661747,\n",
       "  0.0005162146990187466,\n",
       "  0.0005054279588096376,\n",
       "  0.0004929916301210012,\n",
       "  0.00047937493322284093,\n",
       "  0.00046711157275629897,\n",
       "  0.0004501616640482098,\n",
       "  0.00043529232581412155,\n",
       "  0.00042118364529285045,\n",
       "  0.00041023951988401156,\n",
       "  0.0003943546991130071,\n",
       "  0.0003747772550143834,\n",
       "  0.0003568124125844666,\n",
       "  0.00035594156361185014,\n",
       "  0.00032807835460906584,\n",
       "  0.0003182339174340346,\n",
       "  0.0003039953693847305,\n",
       "  0.00032820147420612296,\n",
       "  0.00030068509555089155,\n",
       "  0.0002758315677056089,\n",
       "  0.00026827995524009954,\n",
       "  0.0002685794627593298,\n",
       "  0.00025606198011830984,\n",
       "  0.00026089851287127076,\n",
       "  0.00025266828223331165,\n",
       "  0.00024253739060701003,\n",
       "  0.00023658184883450822,\n",
       "  0.00024025752541742155,\n",
       "  0.00022331096780752496,\n",
       "  0.00022711850345201259,\n",
       "  0.00021247575308994522,\n",
       "  0.00021975436746808036,\n",
       "  0.00021404699821557318,\n",
       "  0.00019835446957066388,\n",
       "  0.0002070974899522428,\n",
       "  0.00019506238043374781,\n",
       "  0.00018689308178311746,\n",
       "  0.00019218633575032333,\n",
       "  0.00018146352626250258,\n",
       "  0.0001946255090712969,\n",
       "  0.0001773568708033833,\n",
       "  0.00018250042090325484,\n",
       "  0.0001773969197529368,\n",
       "  0.0001710465845202894,\n",
       "  0.00017926012930859412,\n",
       "  0.00016527157068984316,\n",
       "  0.00017489089493340413,\n",
       "  0.00015939684089971706,\n",
       "  0.00018462767288188582,\n",
       "  0.00015694497726924186,\n",
       "  0.0001683205513732641,\n",
       "  0.00015650386402350186,\n",
       "  0.00017071854277414137,\n",
       "  0.00014768461551284418,\n",
       "  0.00018440244873220633,\n",
       "  0.0001455864975079229,\n",
       "  0.00015550535317743197,\n",
       "  0.00014179765068027855,\n",
       "  0.00015299599804815704,\n",
       "  0.0001433232069497795,\n",
       "  0.00015789095154364726,\n",
       "  0.00013761324018040405,\n",
       "  0.0001398514016597931],\n",
       " 'f2_history': [0.005935422602089269,\n",
       "  0.010130172719444866,\n",
       "  0.009743392357521226,\n",
       "  0.014529170644056375,\n",
       "  0.01831873242483236,\n",
       "  0.020913347714000104,\n",
       "  0.023508780847332707,\n",
       "  0.027050408802349244,\n",
       "  0.03050831993248252,\n",
       "  0.060881864583973926,\n",
       "  0.08456952724247886,\n",
       "  0.10927540002601795,\n",
       "  0.12209688122096882,\n",
       "  0.13611859838274934,\n",
       "  0.1528025215842127,\n",
       "  0.17039183222958057,\n",
       "  0.18003614625330183,\n",
       "  0.19573205200678348,\n",
       "  0.2135523613963039,\n",
       "  0.23195876288659795,\n",
       "  0.2541921746073995,\n",
       "  0.27346177750155376,\n",
       "  0.2741585233441911,\n",
       "  0.3020701309674694,\n",
       "  0.32244196044711954,\n",
       "  0.33835530445699935,\n",
       "  0.39194782390568167,\n",
       "  0.42752293577981654,\n",
       "  0.4466738325570285,\n",
       "  0.3843514070006863,\n",
       "  0.4627949183303085,\n",
       "  0.4952120383036936,\n",
       "  0.5183391003460207,\n",
       "  0.5398336909871244,\n",
       "  0.5503960666484567,\n",
       "  0.554470909800859,\n",
       "  0.5521776895396451,\n",
       "  0.572572445348246,\n",
       "  0.5791428950510813,\n",
       "  0.5860729643501179,\n",
       "  0.5971617254461149,\n",
       "  0.6241436009865716,\n",
       "  0.6316676024705222,\n",
       "  0.6328767123287671,\n",
       "  0.6375203031943693,\n",
       "  0.6601671309192201,\n",
       "  0.6595426082221617,\n",
       "  0.6669394435351882,\n",
       "  0.674893147663036,\n",
       "  0.6771887225145016,\n",
       "  0.6791927627000696,\n",
       "  0.6745469988674971,\n",
       "  0.6895127993393889,\n",
       "  0.6889523033020791,\n",
       "  0.6956580185508805,\n",
       "  0.6995631995631996,\n",
       "  0.7058117835243934,\n",
       "  0.714383467907486,\n",
       "  0.7095402604305076,\n",
       "  0.7162552521008403,\n",
       "  0.7085158817086528,\n",
       "  0.7212371683775497,\n",
       "  0.7149483169891333,\n",
       "  0.7252215954875101,\n",
       "  0.7195571955719557,\n",
       "  0.7442109490028108,\n",
       "  0.7026273885350318,\n",
       "  0.7414524251258945,\n",
       "  0.7334751961697035,\n",
       "  0.7523696682464455,\n",
       "  0.7401490947816827,\n",
       "  0.7567891373801917,\n",
       "  0.7292236194641881,\n",
       "  0.7566238732586725,\n",
       "  0.7621497224854474],\n",
       " 'model': TemporalEdgeClassifier(\n",
       "   (rnn): GRUCell(15, 256)\n",
       "   (gnn1): GATConv(256, 256, heads=2)\n",
       "   (gnn2): GATConv(256, 256, heads=2)\n",
       "   (dropout): Dropout(p=0.3, inplace=False)\n",
       "   (classifier): Linear(in_features=521, out_features=1, bias=True)\n",
       " )}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82e25fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Function to compute and print confusion matrix\n",
    "def compute_confusion_matrix(labels, preds, threshold=0.5):\n",
    "\n",
    "    # Convert probabilities to binary predictions using the threshold\n",
    "    binary_preds = (preds >= threshold).astype(int)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(labels, binary_preds)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Optional: Extract and print TP, TN, FP, FN\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"False Negatives (FN): {fn}\")\n",
    "    print(f\"True Positives (TP): {tp}\")\n",
    "    print(f\"Precision: {tp / (tp + fp + 1e-8):.4f}\")\n",
    "    print(f\"Recall: {tp / (tp + fn + 1e-8):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51d19dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = results['test_probs']\n",
    "test_labels = results['test_labels']\n",
    "val_probs = results['val_probs']\n",
    "val_labels = results['val_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f1f36ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1453249    4113]\n",
      " [    185    1273]]\n",
      "True Negatives (TN): 1453249\n",
      "False Positives (FP): 4113\n",
      "False Negatives (FN): 185\n",
      "True Positives (TP): 1273\n",
      "Precision: 0.2364\n",
      "Recall: 0.8731\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(val_labels, val_probs, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c31c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1378130    5038]\n",
      " [    185    1456]]\n",
      "True Negatives (TN): 1378130\n",
      "False Positives (FP): 5038\n",
      "False Negatives (FN): 185\n",
      "True Positives (TP): 1456\n",
      "Precision: 0.2242\n",
      "Recall: 0.8873\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(test_labels, test_probs, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b1255f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC Score: 0.7730\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate PR curve data\n",
    "precision, recall, thresholds = precision_recall_curve(test_labels, test_probs)\n",
    "pr_auc = average_precision_score(test_labels, test_probs)\n",
    "\n",
    "# Plot PR curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, linewidth=2, label=f'PR AUC = {pr_auc:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"PR AUC Score: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5373b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae20c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-backup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
