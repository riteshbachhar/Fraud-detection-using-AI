{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83228cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Improved Temporal Graph Neural Network for Anti-Money Laundering Detection\n",
    "==========================================================================\n",
    "Optimized for F2 Score with structured code organization\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (precision_recall_curve, roc_auc_score, f1_score, \n",
    "                           precision_score, recall_score, fbeta_score, \n",
    "                           confusion_matrix, average_precision_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74ecce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent.parent))  # Adjust as needed\n",
    "from config import DATAPATH, SAMPLE_DATAPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ddba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f457192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration class for hyperparameters and settings\"\"\"\n",
    "    # Model architecture\n",
    "    HIDDEN_DIM = 256  # Increased from 128\n",
    "    NODE_DIM = 15\n",
    "    EDGE_DIM = 9\n",
    "    DROPOUT_RATE = 0.3\n",
    "    \n",
    "    # Training parameters\n",
    "    LEARNING_RATE = 0.0005  # Reduced for better convergence\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    EPOCHS = 75\n",
    "    PATIENCE = 10\n",
    "    \n",
    "    # F2 score optimization\n",
    "    BETA = 2  # For F2 score (emphasizes recall)\n",
    "    CLASS_WEIGHT_MULTIPLIER = 10  # Strong emphasis on minority class\n",
    "\n",
    "    # Criterion parameters\n",
    "    FOCAL_LOSS_ALPHA = 0.25\n",
    "    FOCAL_LOSS_GAMMA = 2.0\n",
    "    \n",
    "    # Data processing\n",
    "    TIME_WINDOW = '7D'\n",
    "    VALIDATION_SPLIT = 0.17\n",
    "    TEST_SPLIT = 0.13\n",
    "    \n",
    "    # Threshold optimization\n",
    "    THRESHOLD_SEARCH_RANGE = np.arange(0.05, 0.95, 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0671bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for addressing class imbalance - better than BCE for F2 optimization\"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08365f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGraphDataProcessor:\n",
    "    \"\"\"Enhanced data processor with better feature engineering for F2 optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, time_window='7D'):\n",
    "        self.time_window = time_window\n",
    "        self.scalers = {}\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_and_preprocess(self, df):\n",
    "        \"\"\"Load SAML-D dataset and perform initial preprocessing\"\"\"\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        \n",
    "        # Combine date and time into datetime\n",
    "        df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "        df = df.sort_values('datetime').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Loaded {len(df)} transactions\")\n",
    "        print(f\"Suspicious transactions: {df['Is_laundering'].sum()} ({df['Is_laundering'].mean()*100:.3f}%)\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def engineer_features(self, df):\n",
    "        \"\"\"Enhanced feature engineering for better detection\"\"\"\n",
    "        print(\"Engineering enhanced features...\")\n",
    "        \n",
    "        # Time-based features (more granular)\n",
    "        df['hour'] = df['datetime'].dt.hour.astype('int8')\n",
    "        df['month'] = df['datetime'].dt.month.astype('int8')\n",
    "        df['day_of_week'] = df['datetime'].dt.dayofweek.astype('int8')\n",
    "        df['day_of_month'] = df['datetime'].dt.day.astype('int8')\n",
    "        df['is_weekend'] = (df['day_of_week'] >= 5).astype('int8')\n",
    "        df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 5)).astype('int8')  # Night transactions\n",
    "        \n",
    "        # Amount-based features\n",
    "        df['log_amount'] = np.log1p(df['Amount']).astype('float32')\n",
    "        \n",
    "        # Calculate amount percentiles for anomaly detection\n",
    "        # amount_percentiles = df['Amount'].quantile([0.95, 0.99]).values\n",
    "        # df['high_amount'] = (df['Amount'] > amount_percentiles[0]).astype('int8')\n",
    "        # df['very_high_amount'] = (df['Amount'] > amount_percentiles[1]).astype('int8')\n",
    "        \n",
    "        # Geographic risk features\n",
    "        df['cross_border'] = (df['Payment_type'] == 'Cross-border').astype('int8')\n",
    "        risky_countries = {'Mexico', 'Turkey', 'Morocco', 'UAE'}\n",
    "        df['high_risk_sender'] = df['Sender_bank_location'].isin(risky_countries).astype('int8')\n",
    "        df['high_risk_receiver'] = df['Receiver_bank_location'].isin(risky_countries).astype('int8')\n",
    "        # df['both_high_risk'] = (df['high_risk_sender'] & df['high_risk_receiver']).astype('int8')\n",
    "        \n",
    "        # Currency features\n",
    "        df['currency_mismatch'] = (df['Payment_currency'] != df['Received_currency']).astype('int8')\n",
    "        \n",
    "        # Convert target\n",
    "        df['Is_laundering'] = df['Is_laundering'].astype('int8')\n",
    "        \n",
    "        # Clean up\n",
    "        columns_to_drop = ['Date', 'Time', 'Amount', 'Sender_bank_location', \n",
    "                          'Receiver_bank_location', 'Payment_currency', 'Received_currency', \n",
    "                          'Laundering_type']\n",
    "        df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_temporal_snapshots(self, df, account_features):\n",
    "        \"\"\"Create temporal graph snapshots with enhanced features\"\"\"\n",
    "        print(\"Creating temporal graph snapshots...\")\n",
    "        \n",
    "        # Global account mapping\n",
    "        all_accounts = list(set(df['Sender_account'].unique()) | set(df['Receiver_account'].unique()))\n",
    "        global_account_to_idx = {acc: idx for idx, acc in enumerate(all_accounts)}\n",
    "        global_num_nodes = len(all_accounts)\n",
    "        \n",
    "        # Time windows\n",
    "        start_date = df['datetime'].min().normalize().date()\n",
    "        end_date = df['datetime'].max().normalize().date()\n",
    "        \n",
    "        snapshots = []\n",
    "        print(f\"Processing time range: {start_date} to {end_date}\")\n",
    "\n",
    "        for window_start in pd.date_range(start=start_date, end=end_date, freq=self.time_window, inclusive='left'):\n",
    "            window_end = window_start + pd.Timedelta(days=7)\n",
    "            window_start_str = pd.to_datetime(window_start).strftime('%Y-%m-%d')\n",
    "            window_end_str = pd.to_datetime(window_end).strftime('%Y-%m-%d')\n",
    "            print(f\"Processing window: {window_start_str} to {window_end_str}\")\n",
    "            \n",
    "            # Get transactions in current window\n",
    "            window_mask = (df['datetime'] >= window_start_str) & (df['datetime'] < window_end_str)\n",
    "            window_trnx_data = df[window_mask].copy()\n",
    "            \n",
    "            # Account features for this window\n",
    "            window_accounts_features = account_features[account_features['window_start'] == window_start_str]\n",
    "            \n",
    "            if len(window_trnx_data) > 0:\n",
    "                graph_data = self._create_graph_snapshot(\n",
    "                    window_trnx_data, window_accounts_features,\n",
    "                    window_start_str, global_account_to_idx, global_num_nodes\n",
    "                )\n",
    "                if graph_data is not None:\n",
    "                    snapshots.append(graph_data)\n",
    "\n",
    "        print(f\"Created {len(snapshots)} temporal snapshots\")\n",
    "        return snapshots, global_num_nodes\n",
    "\n",
    "    def _create_graph_snapshot(self, window_trnx_data, window_accounts_features, \n",
    "                              timestamp, global_account_to_idx, global_num_nodes):\n",
    "        \"\"\"Create enhanced graph snapshot\"\"\"\n",
    "        if len(window_trnx_data) == 0:\n",
    "            return None\n",
    "\n",
    "        # Enhanced edge features\n",
    "        edge_feature_columns = [\n",
    "            'Payment_type_encoded', 'log_amount', 'month', 'day_of_week', 'hour', \n",
    "            'currency_mismatch', 'cross_border', 'high_risk_sender', 'high_risk_receiver',\n",
    "        ]\n",
    "        \n",
    "        # Filter available columns\n",
    "        edge_feature_columns = [col for col in edge_feature_columns if col in window_trnx_data.columns]\n",
    "\n",
    "        # Node features\n",
    "        node_feature_columns = ['sent_txns_count', 'fan_out', 'recv_txns_count', 'fan_in', \n",
    "                               'max_sent_txn_count', 'max_recv_txn_count', 'sent_recv_ratio', \n",
    "                               'fanout_fanin_ratio', 'log_med_sent_amt', 'log_std_sent_amt', \n",
    "                               'log_med_recv_amt', 'log_std_recv_amt', 'log_max_sent_txn_amt', \n",
    "                               'log_max_recv_txn_amt', 'log_total_txns_amt']\n",
    "\n",
    "        # Create mappings and features\n",
    "        sender_mapped = window_trnx_data['Sender_account'].map(global_account_to_idx)\n",
    "        receiver_mapped = window_trnx_data['Receiver_account'].map(global_account_to_idx)\n",
    "        edge_index = np.column_stack((sender_mapped, receiver_mapped))\n",
    "        edge_features = window_trnx_data[edge_feature_columns].values\n",
    "        transaction_labels = window_trnx_data['Is_laundering'].values\n",
    "\n",
    "        # Node features\n",
    "        node_features = np.zeros((global_num_nodes, len(node_feature_columns)))\n",
    "        try:\n",
    "            window_accounts_features['global_idx'] = window_accounts_features['account'].map(global_account_to_idx)\n",
    "            node_features[window_accounts_features['global_idx'].values] = window_accounts_features[node_feature_columns].values\n",
    "        except: \n",
    "            raise ValueError(\"Error in mapping account features to global indices.\")\n",
    "\n",
    "        # Convert to tensors\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "        edge_features = torch.tensor(edge_features, dtype=torch.float)\n",
    "        transaction_labels = torch.tensor(transaction_labels, dtype=torch.float)\n",
    "\n",
    "        return Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_features,\n",
    "            y=transaction_labels,\n",
    "            timestamp=timestamp,\n",
    "            num_nodes=global_num_nodes\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e55e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal GNN Model for Edge Classification\n",
    "class TemporalEdgeClassifier(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, dropout_rate):\n",
    "        super(TemporalEdgeClassifier, self).__init__()\n",
    "        self.rnn = nn.GRUCell(node_dim, hidden_dim)\n",
    "        self.gnn1 = GATConv(hidden_dim, hidden_dim)\n",
    "        self.gnn2 = GATConv(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.classifier = nn.Linear(hidden_dim * 2 + edge_dim, 1)  # Binary classification\n",
    "\n",
    "    def forward(self, data, h):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        \n",
    "        # Update node hidden states with RNN (using current x)\n",
    "        h = self.rnn(x, h)\n",
    "        \n",
    "        # Apply GNN layers\n",
    "        h = F.relu(self.gnn1(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.gnn2(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        \n",
    "        # Edge features: concat sender h, receiver h, edge_attr\n",
    "        h_i = h[edge_index[0]]\n",
    "        h_j = h[edge_index[1]]\n",
    "        edge_input = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
    "        \n",
    "        # Prediction\n",
    "        out = self.classifier(edge_input)\n",
    "        \n",
    "        return out, h  # Return logits and updated h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fbfa562",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedTemporalEdgeClassifier(nn.Module):\n",
    "    \"\"\"Enhanced temporal GNN classifier optimized for F2 score\"\"\"\n",
    "    \n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, dropout_rate=0.3):\n",
    "        super(ImprovedTemporalEdgeClassifier, self).__init__()\n",
    "        \n",
    "        # Enhanced RNN component\n",
    "        self.rnn = nn.GRUCell(node_dim, hidden_dim)\n",
    "        \n",
    "        # Multi-head attention GNN layers\n",
    "        self.gnn1 = GATConv(hidden_dim, hidden_dim, heads=4, concat=False, dropout=dropout_rate)\n",
    "        self.gnn2 = GATConv(hidden_dim, hidden_dim, heads=4, concat=False, dropout=dropout_rate)\n",
    "        self.gnn3 = GATConv(hidden_dim, hidden_dim//2, heads=2, concat=False, dropout=dropout_rate)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Enhanced classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim//2 + edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim//2, 1)\n",
    "        )\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "    def forward(self, data, h):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "\n",
    "        # Update node hidden states with RNN\n",
    "        h = self.rnn(x, h)\n",
    "        \n",
    "        # Apply GNN layers with residual connections\n",
    "        h_residual = h\n",
    "        h = F.relu(self.gnn1(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = h + h_residual  # Residual connection\n",
    "        \n",
    "        h_residual = h\n",
    "        h = F.relu(self.gnn2(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = h + h_residual  # Residual connection\n",
    "        \n",
    "        h = F.relu(self.gnn3(h, edge_index))\n",
    "\n",
    "        # Enhanced edge representation\n",
    "        h_i = h[edge_index[0]]\n",
    "        h_j = h[edge_index[1]]\n",
    "        \n",
    "        # Combine node and edge features\n",
    "        edge_input = torch.cat([h_i + h_j, edge_attr], dim=-1)  # Use sum instead of concat for better interaction\n",
    "        \n",
    "        # Classification\n",
    "        out = self.classifier(edge_input)\n",
    "        \n",
    "        return out, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59dd2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"Enhanced trainer class optimized for F2 score\"\"\"\n",
    "    \n",
    "    def __init__(self, config=Config()):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "    \n",
    "    def find_optimal_threshold(self, probs, labels):\n",
    "        \"\"\"Find optimal threshold for F2 score\"\"\"\n",
    "        best_f2 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in self.config.THRESHOLD_SEARCH_RANGE:\n",
    "            preds = (probs >= threshold).astype(int)\n",
    "            f2 = fbeta_score(labels, preds, beta=self.config.BETA, average='binary', zero_division=0)\n",
    "            if f2 > best_f2:\n",
    "                best_f2 = f2\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        return best_threshold, best_f2\n",
    "    \n",
    "    def compute_class_weights(self, snapshots):\n",
    "        \"\"\"Compute class weights for focal loss\"\"\"\n",
    "        all_labels = []\n",
    "        for snap in snapshots:\n",
    "            all_labels.extend(snap.y.cpu().numpy())\n",
    "        \n",
    "        all_labels = np.array(all_labels)\n",
    "        pos_weight = len(all_labels) / (2 * np.sum(all_labels))\n",
    "        return torch.tensor(pos_weight, dtype=torch.float).to(self.device)\n",
    "    \n",
    "    def train_model(self, snapshots, global_num_nodes):\n",
    "        \"\"\"Enhanced training with F2 optimization\"\"\"\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(len(snapshots) * (1 - self.config.VALIDATION_SPLIT - self.config.TEST_SPLIT))\n",
    "        val_size = int(len(snapshots) * self.config.VALIDATION_SPLIT)\n",
    "        \n",
    "        train_snaps = snapshots[:train_size]\n",
    "        val_snaps = snapshots[train_size:train_size + val_size]\n",
    "        test_snaps = snapshots[train_size + val_size:]\n",
    "        \n",
    "        print(f\"Data split - Train: {len(train_snaps)}, Val: {len(val_snaps)}, Test: {len(test_snaps)}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = TemporalEdgeClassifier(\n",
    "            self.config.NODE_DIM, \n",
    "            self.config.EDGE_DIM, \n",
    "            self.config.HIDDEN_DIM,\n",
    "            self.config.DROPOUT_RATE\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Compute class weights for focal loss\n",
    "        pos_weight = self.compute_class_weights(train_snaps)\n",
    "        criterion = FocalLoss(alpha=self.config.FOCAL_LOSS_ALPHA, gamma=self.config.FOCAL_LOSS_GAMMA)\n",
    "        \n",
    "        # Optimizer with different learning rates for different components\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': model.rnn.parameters(), 'lr': self.config.LEARNING_RATE * 0.5},\n",
    "            {'params': model.gnn1.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.gnn2.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            # {'params': model.gnn3.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.classifier.parameters(), 'lr': self.config.LEARNING_RATE * 1.5}\n",
    "        ], weight_decay=self.config.WEIGHT_DECAY)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.7, patience=5, verbose=True\n",
    "        )\n",
    "        \n",
    "        # Training loop\n",
    "        best_f2_score = 0\n",
    "        patience_counter = 0\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "        f2_history = []\n",
    "        \n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "            \n",
    "            for snap in train_snaps:\n",
    "                snap = snap.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                out, h = model(snap, h.detach())  # Detach to prevent gradient explosion\n",
    "                loss = criterion(out.squeeze(), snap.y)\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_snaps)\n",
    "            train_loss_history.append(avg_train_loss)\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_probs_list, val_labels_list = [], []\n",
    "            val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "                for snap in val_snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, h = model(snap, h)\n",
    "                    loss = criterion(out.squeeze(), snap.y)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    preds = torch.sigmoid(out).squeeze()\n",
    "                    val_probs_list.append(preds.cpu())\n",
    "                    val_labels_list.append(snap.y.cpu())\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_snaps)\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "            \n",
    "            # Scale\n",
    "            avg_train_loss *= 1000\n",
    "            avg_val_loss *= 1000\n",
    "            \n",
    "            # Calculate F2 score with optimal threshold\n",
    "            val_probs = torch.cat(val_probs_list).numpy()\n",
    "            val_labels = torch.cat(val_labels_list).numpy()\n",
    "            \n",
    "            optimal_threshold, f2_score = self.find_optimal_threshold(val_probs, val_labels)\n",
    "            f2_history.append(f2_score)\n",
    "            recall = recall_score(val_labels, (val_probs >= optimal_threshold).astype(int), zero_division=0)\n",
    "            \n",
    "            scheduler.step(f2_score)\n",
    "            \n",
    "            # Early stopping based on F2 score\n",
    "            if f2_score > best_f2_score:\n",
    "                best_f2_score = f2_score\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                torch.save(model.state_dict(), './outputs/best_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}: Train Loss(x1e3): {avg_train_loss:.4f}, Val Loss(x1e3): {avg_val_loss:.4f}, \"\n",
    "                        f\"F2: {f2_score:.4f}, Threshold: {optimal_threshold:.3f}, Recall: {recall:.4f}\")\n",
    "            \n",
    "            if patience_counter >= self.config.PATIENCE:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # Load best model and evaluate\n",
    "        model.load_state_dict(torch.load('./outputs/best_model.pth'))\n",
    "        \n",
    "        # Final evaluation\n",
    "        results = self._evaluate_model(model, train_snaps, val_snaps, test_snaps, global_num_nodes)\n",
    "        results.update({\n",
    "            'train_loss_history': train_loss_history,\n",
    "            'val_loss_history': val_loss_history,\n",
    "            'f2_history': f2_history,\n",
    "            'model': model\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_model(self, model, train_snaps, val_snaps, test_snaps, global_num_nodes):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        model.eval()\n",
    "        results = {}\n",
    "        \n",
    "        for split_name, snaps in [('val', val_snaps), ('test', test_snaps)]:\n",
    "            probs_list, labels_list = [], []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "                for snap in snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, h = model(snap, h)\n",
    "                    preds = torch.sigmoid(out).squeeze().cpu().numpy()\n",
    "                    probs_list.extend(preds)\n",
    "                    labels_list.extend(snap.y.cpu().numpy())\n",
    "            \n",
    "            probs = np.array(probs_list)\n",
    "            labels = np.array(labels_list)\n",
    "            \n",
    "            # Find optimal threshold\n",
    "            optimal_threshold, best_f2 = self.find_optimal_threshold(probs, labels)\n",
    "            binary_preds = (probs >= optimal_threshold).astype(int)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            precision = precision_score(labels, binary_preds, zero_division=0)\n",
    "            recall = recall_score(labels, binary_preds, zero_division=0)\n",
    "            f1 = f1_score(labels, binary_preds, zero_division=0)\n",
    "            roc_auc = roc_auc_score(labels, probs)\n",
    "            pr_auc = average_precision_score(labels, probs)\n",
    "            \n",
    "            results[f'{split_name}_probs'] = probs\n",
    "            results[f'{split_name}_labels'] = labels\n",
    "            results[f'{split_name}_threshold'] = optimal_threshold\n",
    "            results[f'{split_name}_precision'] = precision\n",
    "            results[f'{split_name}_recall'] = recall\n",
    "            results[f'{split_name}_f1'] = f1\n",
    "            results[f'{split_name}_f2'] = best_f2\n",
    "            results[f'{split_name}_roc_auc'] = roc_auc\n",
    "            results[f'{split_name}_pr_auc'] = pr_auc\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2124555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset\n",
    "df = pd.read_csv(DATAPATH)\n",
    "\n",
    "# Filter by data range\n",
    "# df = df[df['Date'] < '2023-08-18']\n",
    "# df = df.head(300000).copy()\n",
    "\n",
    "# run feature engg.ipynb to get the account_stats_7D.csv\n",
    "account_stats = pd.read_csv('../account_stats_7D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9178de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Loaded 9504852 transactions\n",
      "Suspicious transactions: 9873 (0.104%)\n",
      "Engineering enhanced features...\n"
     ]
    }
   ],
   "source": [
    "graph_processor = TemporalGraphDataProcessor()\n",
    "df = graph_processor.load_and_preprocess(df)\n",
    "df = graph_processor.engineer_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8bfb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For each categorical column\n",
    "# categorical_cols = ['Payment_currency', 'Received_currency', 'Sender_bank_location', \n",
    "#                    'Receiver_bank_location', 'Payment_type']\n",
    "categorical_cols = ['Payment_type']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "# Drop original object columns\n",
    "df = df.drop(categorical_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43c740f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process accont_stats\n",
    "columns = ['med_sent_amt', 'std_sent_amt', 'med_recv_amt', 'std_recv_amt', \n",
    "           'max_sent_txn_amt', 'max_recv_txn_amt', 'total_txns_amt']\n",
    "\n",
    "for col in columns:\n",
    "    account_stats['log_' + col] = np.log1p(account_stats[col]).astype('float32')\n",
    "\n",
    "account_stats = account_stats.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "094d1677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data types to optimize memory\n",
    "account_stats = account_stats.astype({\n",
    "    'sent_txns_count': 'int32',\n",
    "    'recv_txns_count': 'int32',\n",
    "    'fan_out': 'int32',\n",
    "    'fan_in': 'int32',\n",
    "    'max_sent_txn_count': 'int32',\n",
    "    'max_recv_txn_count': 'int32',\n",
    "    'sent_recv_ratio': 'float32',\n",
    "    'fanout_fanin_ratio': 'float32'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79bf8e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporal graph snapshots...\n",
      "Processing time range: 2022-10-07 to 2023-08-23\n",
      "Processing window: 2022-10-07 to 2022-10-14\n",
      "Processing window: 2022-10-14 to 2022-10-21\n",
      "Processing window: 2022-10-21 to 2022-10-28\n",
      "Processing window: 2022-10-28 to 2022-11-04\n",
      "Processing window: 2022-11-04 to 2022-11-11\n",
      "Processing window: 2022-11-11 to 2022-11-18\n",
      "Processing window: 2022-11-18 to 2022-11-25\n",
      "Processing window: 2022-11-25 to 2022-12-02\n",
      "Processing window: 2022-12-02 to 2022-12-09\n",
      "Processing window: 2022-12-09 to 2022-12-16\n",
      "Processing window: 2022-12-16 to 2022-12-23\n",
      "Processing window: 2022-12-23 to 2022-12-30\n",
      "Processing window: 2022-12-30 to 2023-01-06\n",
      "Processing window: 2023-01-06 to 2023-01-13\n",
      "Processing window: 2023-01-13 to 2023-01-20\n",
      "Processing window: 2023-01-20 to 2023-01-27\n",
      "Processing window: 2023-01-27 to 2023-02-03\n",
      "Processing window: 2023-02-03 to 2023-02-10\n",
      "Processing window: 2023-02-10 to 2023-02-17\n",
      "Processing window: 2023-02-17 to 2023-02-24\n",
      "Processing window: 2023-02-24 to 2023-03-03\n",
      "Processing window: 2023-03-03 to 2023-03-10\n",
      "Processing window: 2023-03-10 to 2023-03-17\n",
      "Processing window: 2023-03-17 to 2023-03-24\n",
      "Processing window: 2023-03-24 to 2023-03-31\n",
      "Processing window: 2023-03-31 to 2023-04-07\n",
      "Processing window: 2023-04-07 to 2023-04-14\n",
      "Processing window: 2023-04-14 to 2023-04-21\n",
      "Processing window: 2023-04-21 to 2023-04-28\n",
      "Processing window: 2023-04-28 to 2023-05-05\n",
      "Processing window: 2023-05-05 to 2023-05-12\n",
      "Processing window: 2023-05-12 to 2023-05-19\n",
      "Processing window: 2023-05-19 to 2023-05-26\n",
      "Processing window: 2023-05-26 to 2023-06-02\n",
      "Processing window: 2023-06-02 to 2023-06-09\n",
      "Processing window: 2023-06-09 to 2023-06-16\n",
      "Processing window: 2023-06-16 to 2023-06-23\n",
      "Processing window: 2023-06-23 to 2023-06-30\n",
      "Processing window: 2023-06-30 to 2023-07-07\n",
      "Processing window: 2023-07-07 to 2023-07-14\n",
      "Processing window: 2023-07-14 to 2023-07-21\n",
      "Processing window: 2023-07-21 to 2023-07-28\n",
      "Processing window: 2023-07-28 to 2023-08-04\n",
      "Processing window: 2023-08-04 to 2023-08-11\n",
      "Processing window: 2023-08-11 to 2023-08-18\n",
      "Processing window: 2023-08-18 to 2023-08-25\n",
      "Created 46 temporal snapshots\n"
     ]
    }
   ],
   "source": [
    "snapshots, global_num_nodes = graph_processor.create_temporal_snapshots(df, account_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89fc6783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Data split - Train: 32, Val: 7, Test: 7\n",
      "Epoch 1: Train Loss(x1e3): 7.4149, Val Loss(x1e3): 1.1543, F2: 0.0056, Threshold: 0.050, Recall: 0.0069\n",
      "Epoch 2: Train Loss(x1e3): 0.8898, Val Loss(x1e3): 0.6910, F2: 0.0092, Threshold: 0.050, Recall: 0.8621\n",
      "Epoch 3: Train Loss(x1e3): 0.7005, Val Loss(x1e3): 0.6521, F2: 0.0106, Threshold: 0.150, Recall: 0.0288\n",
      "Epoch 4: Train Loss(x1e3): 0.6643, Val Loss(x1e3): 0.6346, F2: 0.0127, Threshold: 0.100, Recall: 0.3073\n",
      "Epoch 5: Train Loss(x1e3): 0.6495, Val Loss(x1e3): 0.6264, F2: 0.0149, Threshold: 0.100, Recall: 0.3903\n",
      "Epoch 6: Train Loss(x1e3): 0.6320, Val Loss(x1e3): 0.6174, F2: 0.0169, Threshold: 0.100, Recall: 0.4294\n",
      "Epoch 7: Train Loss(x1e3): 0.6217, Val Loss(x1e3): 0.6040, F2: 0.0214, Threshold: 0.150, Recall: 0.1241\n",
      "Epoch 8: Train Loss(x1e3): 0.6047, Val Loss(x1e3): 0.5916, F2: 0.0289, Threshold: 0.150, Recall: 0.2064\n",
      "Epoch 9: Train Loss(x1e3): 0.5844, Val Loss(x1e3): 0.5809, F2: 0.0335, Threshold: 0.150, Recall: 0.3025\n",
      "Epoch 10: Train Loss(x1e3): 0.5653, Val Loss(x1e3): 0.5717, F2: 0.0517, Threshold: 0.200, Recall: 0.1173\n",
      "Epoch 11: Train Loss(x1e3): 0.5425, Val Loss(x1e3): 0.5401, F2: 0.0783, Threshold: 0.200, Recall: 0.1852\n",
      "Epoch 12: Train Loss(x1e3): 0.5178, Val Loss(x1e3): 0.5007, F2: 0.1241, Threshold: 0.200, Recall: 0.2750\n",
      "Epoch 13: Train Loss(x1e3): 0.4940, Val Loss(x1e3): 0.4904, F2: 0.1498, Threshold: 0.250, Recall: 0.1804\n",
      "Epoch 14: Train Loss(x1e3): 0.4742, Val Loss(x1e3): 0.4692, F2: 0.1917, Threshold: 0.250, Recall: 0.2627\n",
      "Epoch 15: Train Loss(x1e3): 0.4555, Val Loss(x1e3): 0.4667, F2: 0.2075, Threshold: 0.250, Recall: 0.3251\n",
      "Epoch 16: Train Loss(x1e3): 0.4420, Val Loss(x1e3): 0.4315, F2: 0.2321, Threshold: 0.250, Recall: 0.3429\n",
      "Epoch 17: Train Loss(x1e3): 0.4144, Val Loss(x1e3): 0.4042, F2: 0.2571, Threshold: 0.250, Recall: 0.3676\n",
      "Epoch 18: Train Loss(x1e3): 0.3961, Val Loss(x1e3): 0.3927, F2: 0.2718, Threshold: 0.250, Recall: 0.4307\n",
      "Epoch 19: Train Loss(x1e3): 0.3720, Val Loss(x1e3): 0.3844, F2: 0.2806, Threshold: 0.250, Recall: 0.4719\n",
      "Epoch 20: Train Loss(x1e3): 0.3701, Val Loss(x1e3): 0.3669, F2: 0.3031, Threshold: 0.300, Recall: 0.3752\n",
      "Epoch 21: Train Loss(x1e3): 0.3398, Val Loss(x1e3): 0.3607, F2: 0.3360, Threshold: 0.300, Recall: 0.4252\n",
      "Epoch 22: Train Loss(x1e3): 0.3434, Val Loss(x1e3): 0.3484, F2: 0.3438, Threshold: 0.300, Recall: 0.4458\n",
      "Epoch 23: Train Loss(x1e3): 0.3197, Val Loss(x1e3): 0.3481, F2: 0.3788, Threshold: 0.300, Recall: 0.4925\n",
      "Epoch 24: Train Loss(x1e3): 0.3313, Val Loss(x1e3): 0.3537, F2: 0.3462, Threshold: 0.300, Recall: 0.4369\n",
      "Epoch 25: Train Loss(x1e3): 0.3044, Val Loss(x1e3): 0.3459, F2: 0.4038, Threshold: 0.300, Recall: 0.5130\n",
      "Epoch 26: Train Loss(x1e3): 0.3305, Val Loss(x1e3): 0.3575, F2: 0.3517, Threshold: 0.300, Recall: 0.4602\n",
      "Epoch 27: Train Loss(x1e3): 0.2890, Val Loss(x1e3): 0.3177, F2: 0.4235, Threshold: 0.300, Recall: 0.5316\n",
      "Epoch 28: Train Loss(x1e3): 0.2999, Val Loss(x1e3): 0.3299, F2: 0.4112, Threshold: 0.350, Recall: 0.4390\n",
      "Epoch 29: Train Loss(x1e3): 0.2794, Val Loss(x1e3): 0.3076, F2: 0.4502, Threshold: 0.350, Recall: 0.4746\n",
      "Epoch 30: Train Loss(x1e3): 0.2916, Val Loss(x1e3): 0.3159, F2: 0.4320, Threshold: 0.350, Recall: 0.4424\n",
      "Epoch 31: Train Loss(x1e3): 0.2774, Val Loss(x1e3): 0.2815, F2: 0.4682, Threshold: 0.300, Recall: 0.5624\n",
      "Epoch 32: Train Loss(x1e3): 0.2643, Val Loss(x1e3): 0.3137, F2: 0.4311, Threshold: 0.350, Recall: 0.4636\n",
      "Epoch 33: Train Loss(x1e3): 0.2771, Val Loss(x1e3): 0.2793, F2: 0.4809, Threshold: 0.350, Recall: 0.5021\n",
      "Epoch 34: Train Loss(x1e3): 0.2781, Val Loss(x1e3): 0.3049, F2: 0.4700, Threshold: 0.350, Recall: 0.5021\n",
      "Epoch 35: Train Loss(x1e3): 0.2596, Val Loss(x1e3): 0.2729, F2: 0.5015, Threshold: 0.350, Recall: 0.5460\n",
      "Epoch 36: Train Loss(x1e3): 0.2759, Val Loss(x1e3): 0.2885, F2: 0.4951, Threshold: 0.350, Recall: 0.5391\n",
      "Epoch 37: Train Loss(x1e3): 0.2619, Val Loss(x1e3): 0.2553, F2: 0.5107, Threshold: 0.350, Recall: 0.5117\n",
      "Epoch 38: Train Loss(x1e3): 0.2526, Val Loss(x1e3): 0.2691, F2: 0.5083, Threshold: 0.350, Recall: 0.5768\n",
      "Epoch 39: Train Loss(x1e3): 0.2727, Val Loss(x1e3): 0.2531, F2: 0.5124, Threshold: 0.300, Recall: 0.5597\n",
      "Epoch 40: Train Loss(x1e3): 0.2411, Val Loss(x1e3): 0.2690, F2: 0.5047, Threshold: 0.300, Recall: 0.5823\n",
      "Epoch 41: Train Loss(x1e3): 0.2610, Val Loss(x1e3): 0.2573, F2: 0.4954, Threshold: 0.350, Recall: 0.5219\n",
      "Epoch 42: Train Loss(x1e3): 0.2707, Val Loss(x1e3): 0.3001, F2: 0.5082, Threshold: 0.350, Recall: 0.6015\n",
      "Epoch 43: Train Loss(x1e3): 0.2771, Val Loss(x1e3): 0.2590, F2: 0.5220, Threshold: 0.300, Recall: 0.6468\n",
      "Epoch 44: Train Loss(x1e3): 0.2419, Val Loss(x1e3): 0.2497, F2: 0.5281, Threshold: 0.350, Recall: 0.5446\n",
      "Epoch 45: Train Loss(x1e3): 0.2273, Val Loss(x1e3): 0.2356, F2: 0.5552, Threshold: 0.350, Recall: 0.5830\n",
      "Epoch 46: Train Loss(x1e3): 0.2428, Val Loss(x1e3): 0.2531, F2: 0.5680, Threshold: 0.400, Recall: 0.5809\n",
      "Epoch 47: Train Loss(x1e3): 0.2422, Val Loss(x1e3): 0.2218, F2: 0.5831, Threshold: 0.350, Recall: 0.6104\n",
      "Epoch 48: Train Loss(x1e3): 0.2250, Val Loss(x1e3): 0.2268, F2: 0.5775, Threshold: 0.350, Recall: 0.6427\n",
      "Epoch 49: Train Loss(x1e3): 0.2214, Val Loss(x1e3): 0.2132, F2: 0.5918, Threshold: 0.350, Recall: 0.6015\n",
      "Epoch 50: Train Loss(x1e3): 0.2036, Val Loss(x1e3): 0.2138, F2: 0.5907, Threshold: 0.350, Recall: 0.6166\n",
      "Epoch 51: Train Loss(x1e3): 0.2045, Val Loss(x1e3): 0.2103, F2: 0.5975, Threshold: 0.350, Recall: 0.6241\n",
      "Epoch 52: Train Loss(x1e3): 0.2140, Val Loss(x1e3): 0.2050, F2: 0.5954, Threshold: 0.300, Recall: 0.6687\n",
      "Epoch 53: Train Loss(x1e3): 0.2073, Val Loss(x1e3): 0.2071, F2: 0.6002, Threshold: 0.300, Recall: 0.6838\n",
      "Epoch 54: Train Loss(x1e3): 0.2138, Val Loss(x1e3): 0.2106, F2: 0.6037, Threshold: 0.350, Recall: 0.6564\n",
      "Epoch 55: Train Loss(x1e3): 0.2091, Val Loss(x1e3): 0.2025, F2: 0.6126, Threshold: 0.350, Recall: 0.6605\n",
      "Epoch 56: Train Loss(x1e3): 0.2149, Val Loss(x1e3): 0.2151, F2: 0.6224, Threshold: 0.400, Recall: 0.6447\n",
      "Epoch 57: Train Loss(x1e3): 0.2186, Val Loss(x1e3): 0.1945, F2: 0.6391, Threshold: 0.350, Recall: 0.6708\n",
      "Epoch 58: Train Loss(x1e3): 0.1922, Val Loss(x1e3): 0.1944, F2: 0.6387, Threshold: 0.350, Recall: 0.7010\n",
      "Epoch 59: Train Loss(x1e3): 0.1922, Val Loss(x1e3): 0.1815, F2: 0.6536, Threshold: 0.300, Recall: 0.6982\n",
      "Epoch 60: Train Loss(x1e3): 0.1823, Val Loss(x1e3): 0.1887, F2: 0.6398, Threshold: 0.400, Recall: 0.6303\n",
      "Epoch 61: Train Loss(x1e3): 0.1939, Val Loss(x1e3): 0.1799, F2: 0.6571, Threshold: 0.350, Recall: 0.6749\n",
      "Epoch 62: Train Loss(x1e3): 0.1847, Val Loss(x1e3): 0.1833, F2: 0.6521, Threshold: 0.350, Recall: 0.7016\n",
      "Epoch 63: Train Loss(x1e3): 0.1844, Val Loss(x1e3): 0.1789, F2: 0.6638, Threshold: 0.350, Recall: 0.7092\n",
      "Epoch 64: Train Loss(x1e3): 0.1818, Val Loss(x1e3): 0.1745, F2: 0.6774, Threshold: 0.350, Recall: 0.7147\n",
      "Epoch 65: Train Loss(x1e3): 0.1816, Val Loss(x1e3): 0.1759, F2: 0.6695, Threshold: 0.350, Recall: 0.7092\n",
      "Epoch 66: Train Loss(x1e3): 0.1718, Val Loss(x1e3): 0.1728, F2: 0.6664, Threshold: 0.350, Recall: 0.6763\n",
      "Epoch 67: Train Loss(x1e3): 0.1671, Val Loss(x1e3): 0.1660, F2: 0.6830, Threshold: 0.350, Recall: 0.6920\n",
      "Epoch 68: Train Loss(x1e3): 0.1674, Val Loss(x1e3): 0.1689, F2: 0.6804, Threshold: 0.350, Recall: 0.7195\n",
      "Epoch 69: Train Loss(x1e3): 0.1756, Val Loss(x1e3): 0.1700, F2: 0.6754, Threshold: 0.350, Recall: 0.6968\n",
      "Epoch 70: Train Loss(x1e3): 0.1707, Val Loss(x1e3): 0.1609, F2: 0.6969, Threshold: 0.350, Recall: 0.7263\n",
      "Epoch 71: Train Loss(x1e3): 0.1730, Val Loss(x1e3): 0.1670, F2: 0.6850, Threshold: 0.350, Recall: 0.7222\n",
      "Epoch 72: Train Loss(x1e3): 0.1660, Val Loss(x1e3): 0.1612, F2: 0.7012, Threshold: 0.350, Recall: 0.7325\n",
      "Epoch 73: Train Loss(x1e3): 0.1597, Val Loss(x1e3): 0.1633, F2: 0.6965, Threshold: 0.400, Recall: 0.6941\n",
      "Epoch 74: Train Loss(x1e3): 0.1640, Val Loss(x1e3): 0.1575, F2: 0.7093, Threshold: 0.350, Recall: 0.7318\n",
      "Epoch 75: Train Loss(x1e3): 0.1559, Val Loss(x1e3): 0.1535, F2: 0.7047, Threshold: 0.350, Recall: 0.7277\n"
     ]
    }
   ],
   "source": [
    "trainer = ModelTrainer(config=Config())\n",
    "results = trainer.train_model(snapshots, global_num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb0d7038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_probs': array([0.04463527, 0.04453965, 0.00753709, ..., 0.01482729, 0.02684389,\n",
       "        0.03097707], shape=(1458820,), dtype=float32),\n",
       " 'val_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1458820,), dtype=float32),\n",
       " 'val_threshold': np.float64(0.35000000000000003),\n",
       " 'val_precision': 0.6313609467455621,\n",
       " 'val_recall': 0.7318244170096022,\n",
       " 'val_f1': 0.6778907242693774,\n",
       " 'val_f2': 0.7092528582823717,\n",
       " 'val_roc_auc': 0.9943133448730218,\n",
       " 'val_pr_auc': 0.7481761558442597,\n",
       " 'test_probs': array([5.4932156e-05, 1.4769097e-03, 9.2687580e-05, ..., 5.8621392e-03,\n",
       "        1.7979592e-01, 1.3312852e-02], shape=(1384809,), dtype=float32),\n",
       " 'test_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1384809,), dtype=float32),\n",
       " 'test_threshold': np.float64(0.35000000000000003),\n",
       " 'test_precision': 0.6679347826086957,\n",
       " 'test_recall': 0.748933577087142,\n",
       " 'test_f1': 0.7061189313415686,\n",
       " 'test_f2': 0.7311994288434079,\n",
       " 'test_roc_auc': 0.9944430201205591,\n",
       " 'test_pr_auc': 0.769599428103947,\n",
       " 'train_loss_history': [0.007414923406940943,\n",
       "  0.0008898255582607817,\n",
       "  0.0007005133311395184,\n",
       "  0.0006643435854130075,\n",
       "  0.0006495354718936142,\n",
       "  0.0006320197298919084,\n",
       "  0.0006216880501597188,\n",
       "  0.0006046588960089139,\n",
       "  0.0005844320357937249,\n",
       "  0.0005653374719258863,\n",
       "  0.0005424857226898894,\n",
       "  0.0005178092815185664,\n",
       "  0.0004940455501127872,\n",
       "  0.0004742499950225465,\n",
       "  0.0004555221075861482,\n",
       "  0.00044200920365256025,\n",
       "  0.00041438781317992834,\n",
       "  0.0003961437487305375,\n",
       "  0.00037199779490038054,\n",
       "  0.00037011799486208474,\n",
       "  0.00033977433486143127,\n",
       "  0.00034340388356213225,\n",
       "  0.00031970978488971014,\n",
       "  0.00033126244807135663,\n",
       "  0.0003044423156097764,\n",
       "  0.0003304824808765261,\n",
       "  0.00028903804332003347,\n",
       "  0.0002999344901581935,\n",
       "  0.0002793878138618311,\n",
       "  0.0002915813893196173,\n",
       "  0.0002774344925455807,\n",
       "  0.00026430462412463385,\n",
       "  0.0002771291729004588,\n",
       "  0.000278124478427344,\n",
       "  0.0002596098197500396,\n",
       "  0.0002758638133855129,\n",
       "  0.0002618777484713064,\n",
       "  0.00025264555461035343,\n",
       "  0.00027269771226201556,\n",
       "  0.00024113427389238495,\n",
       "  0.000261019605659385,\n",
       "  0.00027072023249274935,\n",
       "  0.00027710489894161583,\n",
       "  0.00024185638039853075,\n",
       "  0.00022727024861524114,\n",
       "  0.00024276929934785585,\n",
       "  0.00024218373710027663,\n",
       "  0.00022498153566630208,\n",
       "  0.00022138460144560668,\n",
       "  0.00020364856140986376,\n",
       "  0.00020445591007955954,\n",
       "  0.00021397493583208416,\n",
       "  0.00020734070903927204,\n",
       "  0.0002137694591510808,\n",
       "  0.00020907899943267694,\n",
       "  0.0002149297379219206,\n",
       "  0.00021864843620278407,\n",
       "  0.00019215490578972094,\n",
       "  0.00019216495752516494,\n",
       "  0.00018233427681479952,\n",
       "  0.00019394507671677275,\n",
       "  0.00018473184923095687,\n",
       "  0.00018438102074469498,\n",
       "  0.0001818216217088775,\n",
       "  0.00018161671732741524,\n",
       "  0.00017181708130920015,\n",
       "  0.0001671069819622062,\n",
       "  0.0001673602055234369,\n",
       "  0.00017561412732902681,\n",
       "  0.00017072720584110357,\n",
       "  0.00017298527632192418,\n",
       "  0.00016601467314103502,\n",
       "  0.00015974922371242428,\n",
       "  0.0001640442665120645,\n",
       "  0.00015585116716465564],\n",
       " 'val_loss_history': [0.0011542537166470928,\n",
       "  0.0006910153356979468,\n",
       "  0.0006521351585563805,\n",
       "  0.0006345599665239986,\n",
       "  0.0006264063371678016,\n",
       "  0.000617379551321002,\n",
       "  0.0006039511146289962,\n",
       "  0.0005915870091744832,\n",
       "  0.0005809436261188239,\n",
       "  0.0005717031391603607,\n",
       "  0.0005401461010998381,\n",
       "  0.0005006868367282939,\n",
       "  0.0004904430492648057,\n",
       "  0.0004692312629361238,\n",
       "  0.00046668707260063717,\n",
       "  0.0004314620496838221,\n",
       "  0.00040415898131738814,\n",
       "  0.0003926616419838475,\n",
       "  0.00038442766942482976,\n",
       "  0.0003669194453063288,\n",
       "  0.00036074959955710383,\n",
       "  0.00034842502541973123,\n",
       "  0.00034814395725594034,\n",
       "  0.000353693770843425,\n",
       "  0.0003459439633713503,\n",
       "  0.00035753698154751746,\n",
       "  0.0003176524894245501,\n",
       "  0.0003298565633096067,\n",
       "  0.00030763965956534127,\n",
       "  0.00031590008334855417,\n",
       "  0.0002815005178230682,\n",
       "  0.00031370252171265226,\n",
       "  0.0002792852631370936,\n",
       "  0.00030488941411022097,\n",
       "  0.0002728887089428359,\n",
       "  0.00028845492800298544,\n",
       "  0.00025528305559419096,\n",
       "  0.0002690523937677166,\n",
       "  0.0002530789601483515,\n",
       "  0.0002689991982021768,\n",
       "  0.0002572528589683186,\n",
       "  0.0003000932400547234,\n",
       "  0.0002589976564714951,\n",
       "  0.00024974979169201106,\n",
       "  0.00023556102990239327,\n",
       "  0.00025306868857504535,\n",
       "  0.00022179488067714765,\n",
       "  0.00022676913483467485,\n",
       "  0.00021320263580751738,\n",
       "  0.00021379941400872276,\n",
       "  0.00021033796864295646,\n",
       "  0.00020498265595441417,\n",
       "  0.00020707675970957747,\n",
       "  0.00021063176557488208,\n",
       "  0.00020251048720508282,\n",
       "  0.00021514727684137012,\n",
       "  0.0001945300942419895,\n",
       "  0.00019442430181827928,\n",
       "  0.00018152231807887022,\n",
       "  0.00018869825414315398,\n",
       "  0.00017992107521942153,\n",
       "  0.00018327490917207406,\n",
       "  0.00017889001797552088,\n",
       "  0.0001745326548448897,\n",
       "  0.00017585281914632236,\n",
       "  0.00017275844584219158,\n",
       "  0.00016599495886891549,\n",
       "  0.00016888228544433202,\n",
       "  0.00016997365206147412,\n",
       "  0.0001609199690782199,\n",
       "  0.00016699717005914344,\n",
       "  0.00016121123085862825,\n",
       "  0.00016331374042368094,\n",
       "  0.00015749047244233743,\n",
       "  0.00015345607140001709],\n",
       " 'f2_history': [0.0055660692419013695,\n",
       "  0.009159364192933955,\n",
       "  0.010617858226312064,\n",
       "  0.012657083446343007,\n",
       "  0.014934618392940571,\n",
       "  0.016907768930759175,\n",
       "  0.021400870223231176,\n",
       "  0.02886404173299323,\n",
       "  0.03348519362186788,\n",
       "  0.05166475315729047,\n",
       "  0.07826994434137291,\n",
       "  0.12410250061896509,\n",
       "  0.1497892698485021,\n",
       "  0.19174927405627315,\n",
       "  0.20751247701602313,\n",
       "  0.23208317861121425,\n",
       "  0.2571236688093639,\n",
       "  0.27183793610942775,\n",
       "  0.2805872756933116,\n",
       "  0.30308067375886527,\n",
       "  0.33600693691740735,\n",
       "  0.3438061990902359,\n",
       "  0.3788118602933418,\n",
       "  0.34615802630148895,\n",
       "  0.4037568822195833,\n",
       "  0.3517140161442499,\n",
       "  0.42345098896295486,\n",
       "  0.4111525118848773,\n",
       "  0.450227716330514,\n",
       "  0.4319582105545138,\n",
       "  0.4681968710745689,\n",
       "  0.4310674658844535,\n",
       "  0.480946123521682,\n",
       "  0.4700141261076153,\n",
       "  0.5015120967741935,\n",
       "  0.4951493007433539,\n",
       "  0.5107490072572916,\n",
       "  0.5082799468149402,\n",
       "  0.5124340617935192,\n",
       "  0.5046962311259066,\n",
       "  0.4954427083333333,\n",
       "  0.5082290217895225,\n",
       "  0.5220327723649247,\n",
       "  0.5281362245576693,\n",
       "  0.5551926845199217,\n",
       "  0.5679989270386266,\n",
       "  0.5831476870659154,\n",
       "  0.5774682608159744,\n",
       "  0.5917678812415654,\n",
       "  0.5907477986594822,\n",
       "  0.5975049244911359,\n",
       "  0.5953834880312653,\n",
       "  0.600168552853359,\n",
       "  0.6037093111279334,\n",
       "  0.6125954198473282,\n",
       "  0.6224341146867964,\n",
       "  0.6391321395895961,\n",
       "  0.6386701662292213,\n",
       "  0.6535695942475603,\n",
       "  0.6397939292676135,\n",
       "  0.6571390410044077,\n",
       "  0.6520907700152984,\n",
       "  0.6638418079096046,\n",
       "  0.6774151605772981,\n",
       "  0.6695156695156695,\n",
       "  0.6663963233306299,\n",
       "  0.6829565452822526,\n",
       "  0.6803735893111947,\n",
       "  0.6753522999202339,\n",
       "  0.6968939194524875,\n",
       "  0.6850117096018735,\n",
       "  0.7011554621848739,\n",
       "  0.6964900206469373,\n",
       "  0.7092528582823717,\n",
       "  0.7047024442082891],\n",
       " 'model': TemporalEdgeClassifier(\n",
       "   (rnn): GRUCell(15, 256)\n",
       "   (gnn1): GATConv(256, 256, heads=1)\n",
       "   (gnn2): GATConv(256, 256, heads=1)\n",
       "   (dropout): Dropout(p=0.3, inplace=False)\n",
       "   (classifier): Linear(in_features=521, out_features=1, bias=True)\n",
       " )}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82e25fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Function to compute and print confusion matrix\n",
    "def compute_confusion_matrix(labels, preds, threshold=0.5):\n",
    "\n",
    "    # Convert probabilities to binary predictions using the threshold\n",
    "    binary_preds = (preds >= threshold).astype(int)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(labels, binary_preds)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Optional: Extract and print TP, TN, FP, FN\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"False Negatives (FN): {fn}\")\n",
    "    print(f\"True Positives (TP): {tp}\")\n",
    "    print(f\"Precision: {tp / (tp + fp + 1e-8):.4f}\")\n",
    "    print(f\"Recall: {tp / (tp + fn + 1e-8):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51d19dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = results['test_probs']\n",
    "test_labels = results['test_labels']\n",
    "val_probs = results['val_probs']\n",
    "val_labels = results['val_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f1f36ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1451753    5609]\n",
      " [    207    1251]]\n",
      "True Negatives (TN): 1451753\n",
      "False Positives (FP): 5609\n",
      "False Negatives (FN): 207\n",
      "True Positives (TP): 1251\n",
      "Precision: 0.1824\n",
      "Recall: 0.8580\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(val_labels, val_probs, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c31c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1376955    6213]\n",
      " [    210    1431]]\n",
      "True Negatives (TN): 1376955\n",
      "False Positives (FP): 6213\n",
      "False Negatives (FN): 210\n",
      "True Positives (TP): 1431\n",
      "Precision: 0.1872\n",
      "Recall: 0.8720\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(test_labels, test_probs, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b1255f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC Score: 0.7696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate PR curve data\n",
    "precision, recall, thresholds = precision_recall_curve(test_labels, test_probs)\n",
    "pr_auc = average_precision_score(test_labels, test_probs)\n",
    "\n",
    "# Plot PR curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, linewidth=2, label=f'PR AUC = {pr_auc:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"PR AUC Score: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5373b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae20c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fastai-backup]",
   "language": "python",
   "name": "conda-env-.conda-fastai-backup-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
