{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83228cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Improved Temporal Graph Neural Network for Anti-Money Laundering Detection\n",
    "==========================================================================\n",
    "Optimized for F2 Score with structured code organization\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (precision_recall_curve, roc_auc_score, f1_score, \n",
    "                           precision_score, recall_score, fbeta_score, \n",
    "                           confusion_matrix, average_precision_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74ecce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent.parent))  # Adjust as needed\n",
    "from config import DATAPATH, SAMPLE_DATAPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ddba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f457192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration class for hyperparameters and settings\"\"\"\n",
    "    # Model architecture\n",
    "    HIDDEN_DIM = 128\n",
    "    NODE_DIM = 15\n",
    "    EDGE_DIM = 9\n",
    "    DROPOUT_RATE = 0.3\n",
    "    \n",
    "    # Training parameters\n",
    "    LEARNING_RATE = 0.0005  # Reduced for better convergence\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    EPOCHS = 75\n",
    "    PATIENCE = 10\n",
    "    \n",
    "    # F2 score optimization\n",
    "    BETA = 2  # For F2 score (emphasizes recall)\n",
    "    CLASS_WEIGHT_MULTIPLIER = 10  # Strong emphasis on minority class\n",
    "\n",
    "    # Criterion parameters\n",
    "    FOCAL_LOSS_ALPHA = 0.25\n",
    "    FOCAL_LOSS_GAMMA = 2.0\n",
    "    \n",
    "    # Data processing\n",
    "    TIME_WINDOW = '7D'\n",
    "    VALIDATION_SPLIT = 0.17\n",
    "    TEST_SPLIT = 0.13\n",
    "    \n",
    "    # Threshold optimization\n",
    "    THRESHOLD_SEARCH_RANGE = np.arange(0.05, 0.95, 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0671bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for addressing class imbalance - better than BCE for F2 optimization\"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08365f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGraphDataProcessor:\n",
    "    \"\"\"Enhanced data processor with better feature engineering for F2 optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, time_window='7D'):\n",
    "        self.time_window = time_window\n",
    "        self.scalers = {}\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_and_preprocess(self, df):\n",
    "        \"\"\"Load SAML-D dataset and perform initial preprocessing\"\"\"\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        \n",
    "        # Combine date and time into datetime\n",
    "        df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "        df = df.sort_values('datetime').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Loaded {len(df)} transactions\")\n",
    "        print(f\"Suspicious transactions: {df['Is_laundering'].sum()} ({df['Is_laundering'].mean()*100:.3f}%)\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def engineer_features(self, df):\n",
    "        \"\"\"Enhanced feature engineering for better detection\"\"\"\n",
    "        print(\"Engineering enhanced features...\")\n",
    "        \n",
    "        # Time-based features (more granular)\n",
    "        df['hour'] = df['datetime'].dt.hour.astype('int8')\n",
    "        df['month'] = df['datetime'].dt.month.astype('int8')\n",
    "        df['day_of_week'] = df['datetime'].dt.dayofweek.astype('int8')\n",
    "        df['day_of_month'] = df['datetime'].dt.day.astype('int8')\n",
    "        df['is_weekend'] = (df['day_of_week'] >= 5).astype('int8')\n",
    "        df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 5)).astype('int8')  # Night transactions\n",
    "        \n",
    "        # Amount-based features\n",
    "        df['log_amount'] = np.log1p(df['Amount']).astype('float32')\n",
    "        \n",
    "        # Calculate amount percentiles for anomaly detection\n",
    "        # amount_percentiles = df['Amount'].quantile([0.95, 0.99]).values\n",
    "        # df['high_amount'] = (df['Amount'] > amount_percentiles[0]).astype('int8')\n",
    "        # df['very_high_amount'] = (df['Amount'] > amount_percentiles[1]).astype('int8')\n",
    "        \n",
    "        # Geographic risk features\n",
    "        df['cross_border'] = (df['Payment_type'] == 'Cross-border').astype('int8')\n",
    "        risky_countries = {'Mexico', 'Turkey', 'Morocco', 'UAE'}\n",
    "        df['high_risk_sender'] = df['Sender_bank_location'].isin(risky_countries).astype('int8')\n",
    "        df['high_risk_receiver'] = df['Receiver_bank_location'].isin(risky_countries).astype('int8')\n",
    "        # df['both_high_risk'] = (df['high_risk_sender'] & df['high_risk_receiver']).astype('int8')\n",
    "        \n",
    "        # Currency features\n",
    "        df['currency_mismatch'] = (df['Payment_currency'] != df['Received_currency']).astype('int8')\n",
    "        \n",
    "        # Convert target\n",
    "        df['Is_laundering'] = df['Is_laundering'].astype('int8')\n",
    "        \n",
    "        # Clean up\n",
    "        columns_to_drop = ['Date', 'Time', 'Amount', 'Sender_bank_location', \n",
    "                          'Receiver_bank_location', 'Payment_currency', 'Received_currency', \n",
    "                          'Laundering_type']\n",
    "        df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_temporal_snapshots(self, df, account_features):\n",
    "        \"\"\"Create temporal graph snapshots with enhanced features\"\"\"\n",
    "        print(\"Creating temporal graph snapshots...\")\n",
    "        \n",
    "        # Global account mapping\n",
    "        all_accounts = list(set(df['Sender_account'].unique()) | set(df['Receiver_account'].unique()))\n",
    "        global_account_to_idx = {acc: idx for idx, acc in enumerate(all_accounts)}\n",
    "        global_num_nodes = len(all_accounts)\n",
    "        \n",
    "        # Time windows\n",
    "        start_date = df['datetime'].min().normalize().date()\n",
    "        end_date = df['datetime'].max().normalize().date()\n",
    "        \n",
    "        snapshots = []\n",
    "        print(f\"Processing time range: {start_date} to {end_date}\")\n",
    "\n",
    "        for window_start in pd.date_range(start=start_date, end=end_date, freq=self.time_window, inclusive='left'):\n",
    "            window_end = window_start + pd.Timedelta(days=7)\n",
    "            window_start_str = pd.to_datetime(window_start).strftime('%Y-%m-%d')\n",
    "            window_end_str = pd.to_datetime(window_end).strftime('%Y-%m-%d')\n",
    "            print(f\"Processing window: {window_start_str} to {window_end_str}\")\n",
    "            \n",
    "            # Get transactions in current window\n",
    "            window_mask = (df['datetime'] >= window_start_str) & (df['datetime'] < window_end_str)\n",
    "            window_trnx_data = df[window_mask].copy()\n",
    "            \n",
    "            # Account features for this window\n",
    "            window_accounts_features = account_features[account_features['window_start'] == window_start_str]\n",
    "            \n",
    "            if len(window_trnx_data) > 0:\n",
    "                graph_data = self._create_graph_snapshot(\n",
    "                    window_trnx_data, window_accounts_features,\n",
    "                    window_start_str, global_account_to_idx, global_num_nodes\n",
    "                )\n",
    "                if graph_data is not None:\n",
    "                    snapshots.append(graph_data)\n",
    "\n",
    "        print(f\"Created {len(snapshots)} temporal snapshots\")\n",
    "        return snapshots, global_num_nodes\n",
    "\n",
    "    def _create_graph_snapshot(self, window_trnx_data, window_accounts_features, \n",
    "                              timestamp, global_account_to_idx, global_num_nodes):\n",
    "        \"\"\"Create enhanced graph snapshot\"\"\"\n",
    "        if len(window_trnx_data) == 0:\n",
    "            return None\n",
    "\n",
    "        # Enhanced edge features\n",
    "        edge_feature_columns = [\n",
    "            'Payment_type_encoded', 'log_amount', 'month', 'day_of_week', 'hour', \n",
    "            'currency_mismatch', 'cross_border', 'high_risk_sender', 'high_risk_receiver',\n",
    "        ]\n",
    "        \n",
    "        # Filter available columns\n",
    "        edge_feature_columns = [col for col in edge_feature_columns if col in window_trnx_data.columns]\n",
    "\n",
    "        # Node features\n",
    "        node_feature_columns = ['sent_txns_count', 'fan_out', 'recv_txns_count', 'fan_in', \n",
    "                               'max_sent_txn_count', 'max_recv_txn_count', 'sent_recv_ratio', \n",
    "                               'fanout_fanin_ratio', 'log_med_sent_amt', 'log_std_sent_amt', \n",
    "                               'log_med_recv_amt', 'log_std_recv_amt', 'log_max_sent_txn_amt', \n",
    "                               'log_max_recv_txn_amt', 'log_total_txns_amt']\n",
    "\n",
    "        # Create mappings and features\n",
    "        sender_mapped = window_trnx_data['Sender_account'].map(global_account_to_idx)\n",
    "        receiver_mapped = window_trnx_data['Receiver_account'].map(global_account_to_idx)\n",
    "        edge_index = np.column_stack((sender_mapped, receiver_mapped))\n",
    "        edge_features = window_trnx_data[edge_feature_columns].values\n",
    "        transaction_labels = window_trnx_data['Is_laundering'].values\n",
    "\n",
    "        # Node features\n",
    "        node_features = np.zeros((global_num_nodes, len(node_feature_columns)))\n",
    "        try:\n",
    "            window_accounts_features['global_idx'] = window_accounts_features['account'].map(global_account_to_idx)\n",
    "            node_features[window_accounts_features['global_idx'].values] = window_accounts_features[node_feature_columns].values\n",
    "        except: \n",
    "            raise ValueError(\"Error in mapping account features to global indices.\")\n",
    "\n",
    "        # Convert to tensors\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "        edge_features = torch.tensor(edge_features, dtype=torch.float)\n",
    "        transaction_labels = torch.tensor(transaction_labels, dtype=torch.float)\n",
    "\n",
    "        return Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_features,\n",
    "            y=transaction_labels,\n",
    "            timestamp=timestamp,\n",
    "            num_nodes=global_num_nodes\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fbfa562",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalEdgeClassifier(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, dropout_rate):\n",
    "        super(TemporalEdgeClassifier, self).__init__()\n",
    "        \n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(node_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Change 2: Multi-head attention in GNN layers\n",
    "        self.gnn1 = GATConv(hidden_dim, hidden_dim, heads=4, concat=False)\n",
    "        self.gnn2 = GATConv(hidden_dim, hidden_dim, heads=2, concat=False)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        # Change 3: Larger classifier with residual connection\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 + edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        \n",
    "        h = self.node_encoder(x)\n",
    "        \n",
    "        # Apply GNN layers\n",
    "        h = F.relu(self.gnn1(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.gnn2(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        \n",
    "        # Edge features\n",
    "        h_i = h[edge_index[0]]\n",
    "        h_j = h[edge_index[1]]\n",
    "        edge_input = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
    "        \n",
    "        # Prediction\n",
    "        out = self.classifier(edge_input)\n",
    "        \n",
    "        return out, h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"Enhanced trainer class optimized for F2 score\"\"\"\n",
    "    \n",
    "    def __init__(self, config=Config()):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "    \n",
    "    def find_optimal_threshold(self, probs, labels):\n",
    "        \"\"\"Find optimal threshold for F2 score\"\"\"\n",
    "        best_f2 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in self.config.THRESHOLD_SEARCH_RANGE:\n",
    "            preds = (probs >= threshold).astype(int)\n",
    "            f2 = fbeta_score(labels, preds, beta=self.config.BETA, average='binary', zero_division=0)\n",
    "            if f2 > best_f2:\n",
    "                best_f2 = f2\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        return best_threshold, best_f2\n",
    "    \n",
    "    def compute_class_weights(self, snapshots):\n",
    "        \"\"\"Compute class weights for focal loss\"\"\"\n",
    "        all_labels = []\n",
    "        for snap in snapshots:\n",
    "            all_labels.extend(snap.y.cpu().numpy())\n",
    "        \n",
    "        all_labels = np.array(all_labels)\n",
    "        pos_weight = len(all_labels) / (2 * np.sum(all_labels))\n",
    "        return torch.tensor(pos_weight, dtype=torch.float).to(self.device)\n",
    "    \n",
    "    def train_model(self, snapshots, global_num_nodes):\n",
    "        \"\"\"Enhanced training with F2 optimization\"\"\"\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(len(snapshots) * (1 - self.config.VALIDATION_SPLIT - self.config.TEST_SPLIT))\n",
    "        val_size = int(len(snapshots) * self.config.VALIDATION_SPLIT)\n",
    "        \n",
    "        train_snaps = snapshots[:train_size]\n",
    "        val_snaps = snapshots[train_size:train_size + val_size]\n",
    "        test_snaps = snapshots[train_size + val_size:]\n",
    "        \n",
    "        print(f\"Data split - Train: {len(train_snaps)}, Val: {len(val_snaps)}, Test: {len(test_snaps)}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = TemporalEdgeClassifier(\n",
    "            self.config.NODE_DIM, \n",
    "            self.config.EDGE_DIM, \n",
    "            self.config.HIDDEN_DIM,\n",
    "            self.config.DROPOUT_RATE\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Compute class weights for focal loss\n",
    "        pos_weight = self.compute_class_weights(train_snaps)\n",
    "        criterion = FocalLoss(alpha=self.config.FOCAL_LOSS_ALPHA, gamma=self.config.FOCAL_LOSS_GAMMA)\n",
    "        \n",
    "        # Optimizer with different learning rates for different components\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': model.node_encoder.parameters(), 'lr': self.config.LEARNING_RATE * 0.5},\n",
    "            {'params': model.gnn1.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.gnn2.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            # {'params': model.gnn3.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.classifier.parameters(), 'lr': self.config.LEARNING_RATE * 1.5}\n",
    "        ], weight_decay=self.config.WEIGHT_DECAY)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.7, patience=5, verbose=True\n",
    "        )\n",
    "        \n",
    "        # Training loop\n",
    "        best_f2_score = 0\n",
    "        patience_counter = 0\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "        f2_history = []\n",
    "        \n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            \n",
    "            for snap in train_snaps:\n",
    "                snap = snap.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                out, _ = model(snap)\n",
    "                loss = criterion(out.squeeze(), snap.y)\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_snaps)\n",
    "            train_loss_history.append(avg_train_loss)\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_probs_list, val_labels_list = [], []\n",
    "            val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for snap in val_snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, _ = model(snap)\n",
    "                    loss = criterion(out.squeeze(), snap.y)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    preds = torch.sigmoid(out).squeeze()\n",
    "                    val_probs_list.append(preds.cpu())\n",
    "                    val_labels_list.append(snap.y.cpu())\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_snaps)\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "            \n",
    "            # Scale\n",
    "            avg_train_loss *= 1000\n",
    "            avg_val_loss *= 1000\n",
    "            \n",
    "            # Calculate F2 score with optimal threshold\n",
    "            val_probs = torch.cat(val_probs_list).numpy()\n",
    "            val_labels = torch.cat(val_labels_list).numpy()\n",
    "            \n",
    "            optimal_threshold, f2_score = self.find_optimal_threshold(val_probs, val_labels)\n",
    "            f2_history.append(f2_score)\n",
    "            recall = recall_score(val_labels, (val_probs >= optimal_threshold).astype(int), zero_division=0)\n",
    "            \n",
    "            scheduler.step(f2_score)\n",
    "            \n",
    "            # Early stopping based on F2 score\n",
    "            if f2_score > best_f2_score:\n",
    "                best_f2_score = f2_score\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                # torch.save(model.state_dict(), './outputs/best_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}: Train Loss(x1e3): {avg_train_loss:.4f}, Val Loss(x1e3): {avg_val_loss:.4f}, \"\n",
    "                        f\"F2: {f2_score:.4f}, Threshold: {optimal_threshold:.3f}, Recall: {recall:.4f}\")\n",
    "            \n",
    "            if patience_counter >= self.config.PATIENCE:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # Load best model and evaluate\n",
    "        # model.load_state_dict(torch.load('./outputs/best_model.pth'))\n",
    "        \n",
    "        # Final evaluation\n",
    "        results = self._evaluate_model(model, train_snaps, val_snaps, test_snaps, global_num_nodes)\n",
    "        results.update({\n",
    "            'train_loss_history': train_loss_history,\n",
    "            'val_loss_history': val_loss_history,\n",
    "            'f2_history': f2_history,\n",
    "            'model': model\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_model(self, model, train_snaps, val_snaps, test_snaps, global_num_nodes):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        model.eval()\n",
    "        results = {}\n",
    "        \n",
    "        for split_name, snaps in [('val', val_snaps), ('test', test_snaps)]:\n",
    "            probs_list, labels_list = [], []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for snap in snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, _ = model(snap)\n",
    "                    preds = torch.sigmoid(out).squeeze().cpu().numpy()\n",
    "                    probs_list.extend(preds)\n",
    "                    labels_list.extend(snap.y.cpu().numpy())\n",
    "            \n",
    "            probs = np.array(probs_list)\n",
    "            labels = np.array(labels_list)\n",
    "            \n",
    "            # Find optimal threshold\n",
    "            optimal_threshold, best_f2 = self.find_optimal_threshold(probs, labels)\n",
    "            binary_preds = (probs >= optimal_threshold).astype(int)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            precision = precision_score(labels, binary_preds, zero_division=0)\n",
    "            recall = recall_score(labels, binary_preds, zero_division=0)\n",
    "            f1 = f1_score(labels, binary_preds, zero_division=0)\n",
    "            roc_auc = roc_auc_score(labels, probs)\n",
    "            pr_auc = average_precision_score(labels, probs)\n",
    "            \n",
    "            results[f'{split_name}_probs'] = probs\n",
    "            results[f'{split_name}_labels'] = labels\n",
    "            results[f'{split_name}_threshold'] = optimal_threshold\n",
    "            results[f'{split_name}_precision'] = precision\n",
    "            results[f'{split_name}_recall'] = recall\n",
    "            results[f'{split_name}_f1'] = f1\n",
    "            results[f'{split_name}_f2'] = best_f2\n",
    "            results[f'{split_name}_roc_auc'] = roc_auc\n",
    "            results[f'{split_name}_pr_auc'] = pr_auc\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2124555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset\n",
    "df = pd.read_csv(DATAPATH)\n",
    "\n",
    "# Filter by data range\n",
    "# df = df[df['Date'] < '2023-08-18']\n",
    "# df = df.head(300000).copy()\n",
    "\n",
    "# run feature engg.ipynb to get the account_stats_7D.csv\n",
    "account_stats = pd.read_csv('../account_stats_7D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9178de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Loaded 9504852 transactions\n",
      "Suspicious transactions: 9873 (0.104%)\n",
      "Engineering enhanced features...\n"
     ]
    }
   ],
   "source": [
    "graph_processor = TemporalGraphDataProcessor()\n",
    "df = graph_processor.load_and_preprocess(df)\n",
    "df = graph_processor.engineer_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8bfb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For each categorical column\n",
    "# categorical_cols = ['Payment_currency', 'Received_currency', 'Sender_bank_location', \n",
    "#                    'Receiver_bank_location', 'Payment_type']\n",
    "categorical_cols = ['Payment_type']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "# Drop original object columns\n",
    "df = df.drop(categorical_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43c740f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process accont_stats\n",
    "columns = ['med_sent_amt', 'std_sent_amt', 'med_recv_amt', 'std_recv_amt', \n",
    "           'max_sent_txn_amt', 'max_recv_txn_amt', 'total_txns_amt']\n",
    "\n",
    "for col in columns:\n",
    "    account_stats['log_' + col] = np.log1p(account_stats[col]).astype('float32')\n",
    "\n",
    "account_stats = account_stats.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "094d1677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data types to optimize memory\n",
    "account_stats = account_stats.astype({\n",
    "    'sent_txns_count': 'int32',\n",
    "    'recv_txns_count': 'int32',\n",
    "    'fan_out': 'int32',\n",
    "    'fan_in': 'int32',\n",
    "    'max_sent_txn_count': 'int32',\n",
    "    'max_recv_txn_count': 'int32',\n",
    "    'sent_recv_ratio': 'float32',\n",
    "    'fanout_fanin_ratio': 'float32'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79bf8e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporal graph snapshots...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time range: 2022-10-07 to 2023-08-23\n",
      "Processing window: 2022-10-07 to 2022-10-14\n",
      "Processing window: 2022-10-14 to 2022-10-21\n",
      "Processing window: 2022-10-21 to 2022-10-28\n",
      "Processing window: 2022-10-28 to 2022-11-04\n",
      "Processing window: 2022-11-04 to 2022-11-11\n",
      "Processing window: 2022-11-11 to 2022-11-18\n",
      "Processing window: 2022-11-18 to 2022-11-25\n",
      "Processing window: 2022-11-25 to 2022-12-02\n",
      "Processing window: 2022-12-02 to 2022-12-09\n",
      "Processing window: 2022-12-09 to 2022-12-16\n",
      "Processing window: 2022-12-16 to 2022-12-23\n",
      "Processing window: 2022-12-23 to 2022-12-30\n",
      "Processing window: 2022-12-30 to 2023-01-06\n",
      "Processing window: 2023-01-06 to 2023-01-13\n",
      "Processing window: 2023-01-13 to 2023-01-20\n",
      "Processing window: 2023-01-20 to 2023-01-27\n",
      "Processing window: 2023-01-27 to 2023-02-03\n",
      "Processing window: 2023-02-03 to 2023-02-10\n",
      "Processing window: 2023-02-10 to 2023-02-17\n",
      "Processing window: 2023-02-17 to 2023-02-24\n",
      "Processing window: 2023-02-24 to 2023-03-03\n",
      "Processing window: 2023-03-03 to 2023-03-10\n",
      "Processing window: 2023-03-10 to 2023-03-17\n",
      "Processing window: 2023-03-17 to 2023-03-24\n",
      "Processing window: 2023-03-24 to 2023-03-31\n",
      "Processing window: 2023-03-31 to 2023-04-07\n",
      "Processing window: 2023-04-07 to 2023-04-14\n",
      "Processing window: 2023-04-14 to 2023-04-21\n",
      "Processing window: 2023-04-21 to 2023-04-28\n",
      "Processing window: 2023-04-28 to 2023-05-05\n",
      "Processing window: 2023-05-05 to 2023-05-12\n",
      "Processing window: 2023-05-12 to 2023-05-19\n",
      "Processing window: 2023-05-19 to 2023-05-26\n",
      "Processing window: 2023-05-26 to 2023-06-02\n",
      "Processing window: 2023-06-02 to 2023-06-09\n",
      "Processing window: 2023-06-09 to 2023-06-16\n",
      "Processing window: 2023-06-16 to 2023-06-23\n",
      "Processing window: 2023-06-23 to 2023-06-30\n",
      "Processing window: 2023-06-30 to 2023-07-07\n",
      "Processing window: 2023-07-07 to 2023-07-14\n",
      "Processing window: 2023-07-14 to 2023-07-21\n",
      "Processing window: 2023-07-21 to 2023-07-28\n",
      "Processing window: 2023-07-28 to 2023-08-04\n",
      "Processing window: 2023-08-04 to 2023-08-11\n",
      "Processing window: 2023-08-11 to 2023-08-18\n",
      "Processing window: 2023-08-18 to 2023-08-25\n",
      "Created 46 temporal snapshots\n"
     ]
    }
   ],
   "source": [
    "snapshots, global_num_nodes = graph_processor.create_temporal_snapshots(df, account_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89fc6783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Data split - Train: 32, Val: 7, Test: 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m trainer = ModelTrainer(config=Config())\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m results = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msnapshots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_num_nodes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 91\u001b[39m, in \u001b[36mModelTrainer.train_model\u001b[39m\u001b[34m(self, snapshots, global_num_nodes)\u001b[39m\n\u001b[32m     88\u001b[39m out, _ = model(snap)\n\u001b[32m     89\u001b[39m loss = criterion(out.squeeze(), snap.y)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)  \u001b[38;5;66;03m# Gradient clipping\u001b[39;00m\n\u001b[32m     93\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer = ModelTrainer(config=Config())\n",
    "results = trainer.train_model(snapshots, global_num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb0d7038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_probs': array([0.04621682, 0.04337662, 0.00589867, ..., 0.03448923, 0.01485734,\n",
       "        0.04943531], shape=(1458820,), dtype=float32),\n",
       " 'val_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1458820,), dtype=float32),\n",
       " 'val_threshold': np.float64(0.3),\n",
       " 'val_precision': 0.6472131147540984,\n",
       " 'val_recall': 0.676954732510288,\n",
       " 'val_f1': 0.6617499161917533,\n",
       " 'val_f2': 0.6707897240723121,\n",
       " 'val_roc_auc': 0.986224510804044,\n",
       " 'val_pr_auc': 0.6816643742249918,\n",
       " 'test_probs': array([5.9566184e-05, 5.6704348e-03, 2.1928437e-03, ..., 4.2813461e-02,\n",
       "        4.7779199e-02, 3.2462135e-02], shape=(1384809,), dtype=float32),\n",
       " 'test_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1384809,), dtype=float32),\n",
       " 'test_threshold': np.float64(0.35000000000000003),\n",
       " 'test_precision': 0.7840508115737473,\n",
       " 'test_recall': 0.6770262035344302,\n",
       " 'test_f1': 0.7266187050359713,\n",
       " 'test_f2': 0.6960280666583135,\n",
       " 'test_roc_auc': 0.9833897748713023,\n",
       " 'test_pr_auc': 0.7173841139937946,\n",
       " 'train_loss_history': [0.006838388761025271,\n",
       "  0.0008474909636788652,\n",
       "  0.0006920574987816508,\n",
       "  0.0006863343842269387,\n",
       "  0.0006770719664928038,\n",
       "  0.0006723665437675663,\n",
       "  0.0006626259764743736,\n",
       "  0.0006526075367219164,\n",
       "  0.0006427467951652943,\n",
       "  0.0006301830480879289,\n",
       "  0.0006167004748931504,\n",
       "  0.0006042176928531262,\n",
       "  0.0005921724750805879,\n",
       "  0.0005799356194984284,\n",
       "  0.0005675190705005662,\n",
       "  0.0005497457941601169,\n",
       "  0.0005202966340220883,\n",
       "  0.0005005451839679154,\n",
       "  0.00048341083765990334,\n",
       "  0.0004668976025641314,\n",
       "  0.00045152157053962583,\n",
       "  0.00043356092191970674,\n",
       "  0.00041632568718341645,\n",
       "  0.000397382414121239,\n",
       "  0.00037755954599560937,\n",
       "  0.0003598533521653735,\n",
       "  0.0003470065985311521,\n",
       "  0.0003355065764480969,\n",
       "  0.00032824027630340424,\n",
       "  0.0003166937458445318,\n",
       "  0.00033712886443026946,\n",
       "  0.00034397053696011426,\n",
       "  0.0003057649150832731,\n",
       "  0.00030017259859960177,\n",
       "  0.00029072033203192404,\n",
       "  0.0002987543007293425,\n",
       "  0.0002821940083777008,\n",
       "  0.00027673883914758335,\n",
       "  0.0002688010963538545,\n",
       "  0.00026113121612070245,\n",
       "  0.0002559561403359112,\n",
       "  0.00025429428706047474,\n",
       "  0.0002466412765897985,\n",
       "  0.0002450356737426773,\n",
       "  0.0002466662936058128,\n",
       "  0.00023970566098796553,\n",
       "  0.0002444451588416996,\n",
       "  0.0002387709464528598,\n",
       "  0.00023435560706275282,\n",
       "  0.000232238455737388,\n",
       "  0.00022771985004510498,\n",
       "  0.00023117839418773656,\n",
       "  0.00028573932013387093,\n",
       "  0.00026552410645308555,\n",
       "  0.0002527845699660247,\n",
       "  0.00023994966750251479,\n",
       "  0.00023258923738467274,\n",
       "  0.00022893464574735845,\n",
       "  0.00022812287761553307,\n",
       "  0.0002233572681689111,\n",
       "  0.00022365298491422436,\n",
       "  0.00021937802239335724,\n",
       "  0.00021967398288325057,\n",
       "  0.0002176243251597043,\n",
       "  0.00021636640349242953,\n",
       "  0.00021513002593565034,\n",
       "  0.00021224933607300045,\n",
       "  0.00020982956539228326,\n",
       "  0.0002063061870103411,\n",
       "  0.00020366507260405342,\n",
       "  0.00020127854168094927,\n",
       "  0.0001991027074836893,\n",
       "  0.00019882460810549674,\n",
       "  0.00020039361334056593,\n",
       "  0.00020678399823736981],\n",
       " 'val_loss_history': [0.0012413155803057765,\n",
       "  0.0006564222941441196,\n",
       "  0.0006510816373130572,\n",
       "  0.000640616419592074,\n",
       "  0.0006340882059053651,\n",
       "  0.0006279815237836114,\n",
       "  0.0006196141143196396,\n",
       "  0.0006063446053303778,\n",
       "  0.0005958355655561068,\n",
       "  0.0005874466649921877,\n",
       "  0.0005746250473228949,\n",
       "  0.0005656014088474746,\n",
       "  0.0005482141942983228,\n",
       "  0.0005313306880582656,\n",
       "  0.0005113128032202699,\n",
       "  0.0004887307170845036,\n",
       "  0.0004650321331739958,\n",
       "  0.0004444922170867877,\n",
       "  0.000430638760527862,\n",
       "  0.0004185089034893151,\n",
       "  0.0004033397833284523,\n",
       "  0.00039093878253230026,\n",
       "  0.00037683206859843006,\n",
       "  0.00036214593897706697,\n",
       "  0.0003447135635984263,\n",
       "  0.00033147661348006556,\n",
       "  0.00032260690932162106,\n",
       "  0.00032126260339282453,\n",
       "  0.00031076648156158626,\n",
       "  0.0003029183675867638,\n",
       "  0.00032929953886196017,\n",
       "  0.0003058323761381741,\n",
       "  0.00028926978120580316,\n",
       "  0.0002847327642874526,\n",
       "  0.0002763846839245941,\n",
       "  0.0002775235646238018,\n",
       "  0.00026755961880553514,\n",
       "  0.00026461808634589294,\n",
       "  0.0002552932232252455,\n",
       "  0.0002523240940977952,\n",
       "  0.000249525232772742,\n",
       "  0.00024366278375964612,\n",
       "  0.00023935962235555053,\n",
       "  0.00024383305571973324,\n",
       "  0.0002369730458927474,\n",
       "  0.0002324300876352936,\n",
       "  0.00023322728936493929,\n",
       "  0.00022759460054138408,\n",
       "  0.00022607808516893004,\n",
       "  0.0002219738089479506,\n",
       "  0.00022052508471201042,\n",
       "  0.0002548609918449074,\n",
       "  0.00024310338734981736,\n",
       "  0.0002386668514061187,\n",
       "  0.000229422705680398,\n",
       "  0.00022354113545069204,\n",
       "  0.00021981769324546413,\n",
       "  0.0002193016927256914,\n",
       "  0.0002150626283504867,\n",
       "  0.00021278609554948552,\n",
       "  0.0002133705295688872,\n",
       "  0.00021028916983466064,\n",
       "  0.00020894108872328485,\n",
       "  0.00020752492543709065,\n",
       "  0.00020813126632544612,\n",
       "  0.0002078061703027093,\n",
       "  0.00020427754082317864,\n",
       "  0.00020543696674784378,\n",
       "  0.00020218466774427464,\n",
       "  0.0001998876832658425,\n",
       "  0.00020160060791697885,\n",
       "  0.00020117065702964152,\n",
       "  0.0001995715221190559,\n",
       "  0.0001998915831791237,\n",
       "  0.00020246663604796465],\n",
       " 'f2_history': [0.009946537361680965,\n",
       "  0.013057602072230832,\n",
       "  0.0140020366598778,\n",
       "  0.014633554383284912,\n",
       "  0.015346908857686052,\n",
       "  0.016451692572439232,\n",
       "  0.017277825880077067,\n",
       "  0.018376478108021732,\n",
       "  0.0202582863713531,\n",
       "  0.021683874951534385,\n",
       "  0.025561515253100905,\n",
       "  0.031544025670310546,\n",
       "  0.03998392990377073,\n",
       "  0.05151098901098901,\n",
       "  0.07871386318099417,\n",
       "  0.1142962485021661,\n",
       "  0.15078299776286352,\n",
       "  0.1801292407108239,\n",
       "  0.20123723634195423,\n",
       "  0.22074031809428715,\n",
       "  0.25669642857142855,\n",
       "  0.2804709141274238,\n",
       "  0.3180125441003528,\n",
       "  0.3425580431177446,\n",
       "  0.3921129285234147,\n",
       "  0.4191033138401559,\n",
       "  0.4404424659382166,\n",
       "  0.44160533259269547,\n",
       "  0.4627395315826828,\n",
       "  0.4754118978744812,\n",
       "  0.388412017167382,\n",
       "  0.46571392754168234,\n",
       "  0.4990836035527985,\n",
       "  0.49583213567116985,\n",
       "  0.5174353205849269,\n",
       "  0.5115352925020599,\n",
       "  0.5200218668853355,\n",
       "  0.5293955665702877,\n",
       "  0.5569654067049552,\n",
       "  0.5534557235421166,\n",
       "  0.5502562642369021,\n",
       "  0.5801435406698564,\n",
       "  0.5768956161645009,\n",
       "  0.564808596373405,\n",
       "  0.5939656338790421,\n",
       "  0.5962867597235397,\n",
       "  0.5955567451820128,\n",
       "  0.6099944165270799,\n",
       "  0.6045125585355471,\n",
       "  0.6135593220338983,\n",
       "  0.6214878244581215,\n",
       "  0.5448267041821204,\n",
       "  0.5822098863335977,\n",
       "  0.5910775747948107,\n",
       "  0.6061016949152542,\n",
       "  0.6217303822937625,\n",
       "  0.6247464503042597,\n",
       "  0.6356220258327668,\n",
       "  0.6376967577021391,\n",
       "  0.639845209500934,\n",
       "  0.6455127332153071,\n",
       "  0.6512066873398948,\n",
       "  0.6486998916576381,\n",
       "  0.6561822125813449,\n",
       "  0.6498096791734639,\n",
       "  0.6600523632354968,\n",
       "  0.6635304030332818,\n",
       "  0.6678058783321941,\n",
       "  0.669523675706056,\n",
       "  0.6707897240723121,\n",
       "  0.6698497402050274,\n",
       "  0.6679260558629065,\n",
       "  0.6682153593878108,\n",
       "  0.6681651001225991,\n",
       "  0.6666211790393013],\n",
       " 'model': TemporalEdgeClassifier(\n",
       "   (node_encoder): Sequential(\n",
       "     (0): Linear(in_features=15, out_features=128, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "   )\n",
       "   (gnn1): GATConv(128, 128, heads=4)\n",
       "   (gnn2): GATConv(128, 128, heads=2)\n",
       "   (dropout): Dropout(p=0.3, inplace=False)\n",
       "   (classifier): Sequential(\n",
       "     (0): Linear(in_features=265, out_features=128, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Dropout(p=0.3, inplace=False)\n",
       "     (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "     (4): ReLU()\n",
       "     (5): Linear(in_features=64, out_features=1, bias=True)\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82e25fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Function to compute and print confusion matrix\n",
    "def compute_confusion_matrix(labels, preds, threshold=0.5):\n",
    "\n",
    "    # Convert probabilities to binary predictions using the threshold\n",
    "    binary_preds = (preds >= threshold).astype(int)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(labels, binary_preds)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Optional: Extract and print TP, TN, FP, FN\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"False Negatives (FN): {fn}\")\n",
    "    print(f\"True Positives (TP): {tp}\")\n",
    "    print(f\"Precision: {tp / (tp + fp + 1e-8):.4f}\")\n",
    "    print(f\"Recall: {tp / (tp + fn + 1e-8):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51d19dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = results['test_probs']\n",
    "test_labels = results['test_labels']\n",
    "val_probs = results['val_probs']\n",
    "val_labels = results['val_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f1f36ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1455134    2228]\n",
      " [    402    1056]]\n",
      "True Negatives (TN): 1455134\n",
      "False Positives (FP): 2228\n",
      "False Negatives (FN): 402\n",
      "True Positives (TP): 1056\n",
      "Precision: 0.3216\n",
      "Recall: 0.7243\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(val_labels, val_probs, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c31c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1381165    2003]\n",
      " [    438    1203]]\n",
      "True Negatives (TN): 1381165\n",
      "False Positives (FP): 2003\n",
      "False Negatives (FN): 438\n",
      "True Positives (TP): 1203\n",
      "Precision: 0.3752\n",
      "Recall: 0.7331\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(test_labels, test_probs, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b1255f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIjCAYAAAAQgZNYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAY4tJREFUeJzt3Xd8VFX+xvFnJmWSQBICpFACoSNdg7CIiGDo4rK6wgIqYgMBV40NFER0FVgbrCLYEHZ/KAg2lLYQREVRpIpIL1ITQktCIPXe3x8sA2MKScjMzSSf9+vF7j1nzp37nTmJeXJz5l6baZqmAAAAAC9kt7oAAAAAoKQIswAAAPBahFkAAAB4LcIsAAAAvBZhFgAAAF6LMAsAAACvRZgFAACA1yLMAgAAwGsRZgEAAOC1CLMAKoy7775bMTExxdpn1apVstlsWrVqlVtq8nY33nijbrzxRmd7//79stlsmjVrlmU1AahYCLMA3GbWrFmy2WzOfwEBAWrcuLFGjRqlpKQkq8sr8y4Ewwv/7Ha7qlatql69emnNmjVWl1cqkpKS9Pjjj6tp06YKCgpSpUqVFBsbq3/84x86ffq01eUB8AK+VhcAoPx7/vnnVa9ePWVkZGj16tWaPn26Fi9erF9//VVBQUEeq+Pdd9+VYRjF2ueGG27QuXPn5O/v76aqLm/gwIHq3bu3cnNztXPnTr311lvq0qWLfv75Z7Vs2dKyuq7Uzz//rN69e+vMmTO64447FBsbK0lat26dJk2apG+//Vb//e9/La4SQFlHmAXgdr169VLbtm0lSffdd5+qVaum1157TV988YUGDhyY7z7p6emqVKlSqdbh5+dX7H3sdrsCAgJKtY7iuuaaa3THHXc42506dVKvXr00ffp0vfXWWxZWVnKnT5/WX/7yF/n4+Gjjxo1q2rSpy+Mvvvii3n333VI5lju+lgCUHSwzAOBxXbt2lSTt27dP0vm1rJUrV9aePXvUu3dvBQcHa/DgwZIkwzA0ZcoUNW/eXAEBAYqMjNSwYcN06tSpPM+7ZMkSde7cWcHBwQoJCdG1116rDz/80Pl4fmtm586dq9jYWOc+LVu21NSpU52PF7Rmdv78+YqNjVVgYKCqV6+uO+64Q4cPH3YZc+F1HT58WP369VPlypUVHh6uxx9/XLm5uSV+/zp16iRJ2rNnj0v/6dOn9cgjjyg6OloOh0MNGzbU5MmT85yNNgxDU6dOVcuWLRUQEKDw8HD17NlT69atc4754IMP1LVrV0VERMjhcKhZs2aaPn16iWv+o7fffluHDx/Wa6+9lifISlJkZKTGjh3rbNtsNj333HN5xsXExOjuu+92ti8sbfnmm280YsQIRUREqHbt2lqwYIGzP79abDabfv31V2ff9u3b9de//lVVq1ZVQECA2rZtq4ULF17ZiwbgFpyZBeBxF0JYtWrVnH05OTnq0aOHrr/+er3yyivO5QfDhg3TrFmzNHToUP3973/Xvn379Oabb2rjxo36/vvvnWdbZ82apXvuuUfNmzfXmDFjVKVKFW3cuFFLly7VoEGD8q1j+fLlGjhwoG666SZNnjxZkrRt2zZ9//33evjhhwus/0I91157rSZOnKikpCRNnTpV33//vTZu3KgqVao4x+bm5qpHjx5q3769XnnlFa1YsUKvvvqqGjRooAcffLBE79/+/fslSWFhYc6+s2fPqnPnzjp8+LCGDRumOnXq6IcfftCYMWN09OhRTZkyxTn23nvv1axZs9SrVy/dd999ysnJ0Xfffacff/zReQZ9+vTpat68uW655Rb5+vrqyy+/1IgRI2QYhkaOHFmiui+1cOFCBQYG6q9//esVP1d+RowYofDwcD377LNKT09Xnz59VLlyZX388cfq3Lmzy9h58+apefPmatGihSRp69at6tixo2rVqqXRo0erUqVK+vjjj9WvXz998skn+stf/uKWmgGUkAkAbvLBBx+YkswVK1aYycnJ5sGDB825c+ea1apVMwMDA81Dhw6ZpmmaQ4YMMSWZo0ePdtn/u+++MyWZc+bMcelfunSpS//p06fN4OBgs3379ua5c+dcxhqG4dweMmSIWbduXWf74YcfNkNCQsycnJwCX8PXX39tSjK//vpr0zRNMysry4yIiDBbtGjhcqyvvvrKlGQ+++yzLseTZD7//PMuz3n11VebsbGxBR7zgn379pmSzAkTJpjJyclmYmKi+d1335nXXnutKcmcP3++c+wLL7xgVqpUydy5c6fLc4wePdr08fExDxw4YJqmaa5cudKUZP7973/Pc7xL36uzZ8/mebxHjx5m/fr1Xfo6d+5sdu7cOU/NH3zwQaGvLSwszGzdunWhYy4lyRw/fnye/rp165pDhgxxti98zV1//fV55nXgwIFmRESES//Ro0dNu93uMkc33XST2bJlSzMjI8PZZxiGed1115mNGjUqcs0APINlBgDcLi4uTuHh4YqOjtbf/vY3Va5cWZ999plq1arlMu6PZyrnz5+v0NBQdevWTcePH3f+i42NVeXKlfX1119LOn+GNS0tTaNHj86zvtVmsxVYV5UqVZSenq7ly5cX+bWsW7dOx44d04gRI1yO1adPHzVt2lSLFi3Ks8/w4cNd2p06ddLevXuLfMzx48crPDxcUVFR6tSpk7Zt26ZXX33V5azm/Pnz1alTJ4WFhbm8V3FxccrNzdW3334rSfrkk09ks9k0fvz4PMe59L0KDAx0bqekpOj48ePq3Lmz9u7dq5SUlCLXXpDU1FQFBwdf8fMU5P7775ePj49L34ABA3Ts2DGXJSMLFiyQYRgaMGCAJOnkyZNauXKl+vfvr7S0NOf7eOLECfXo0UO7du3Ks5wEgLVYZgDA7aZNm6bGjRvL19dXkZGRatKkiex219+lfX19Vbt2bZe+Xbt2KSUlRREREfk+77FjxyRdXLZw4c/ERTVixAh9/PHH6tWrl2rVqqXu3burf//+6tmzZ4H7/P7775KkJk2a5HmsadOmWr16tUvfhTWplwoLC3NZ85ucnOyyhrZy5cqqXLmys/3AAw/o9ttvV0ZGhlauXKl//etfedbc7tq1S7/88kueY11w6XtVs2ZNVa1atcDXKEnff/+9xo8frzVr1ujs2bMuj6WkpCg0NLTQ/S8nJCREaWlpV/QchalXr16evp49eyo0NFTz5s3TTTfdJOn8EoM2bdqocePGkqTdu3fLNE2NGzdO48aNy/e5jx07lucXMQDWIcwCcLt27do512IWxOFw5Am4hmEoIiJCc+bMyXefgoJbUUVERGjTpk1atmyZlixZoiVLluiDDz7QXXfdpdmzZ1/Rc1/wx7OD+bn22mudIVk6fyb20g87NWrUSHFxcZKkm2++WT4+Pho9erS6dOnifF8Nw1C3bt305JNP5nuMC2GtKPbs2aObbrpJTZs21Wuvvabo6Gj5+/tr8eLFev3114t9ebP8NG3aVJs2bVJWVtYVXfasoA/SXXpm+QKHw6F+/frps88+01tvvaWkpCR9//33eumll5xjLry2xx9/XD169Mj3uRs2bFjiegGUPsIsgDKrQYMGWrFihTp27JhvOLl0nCT9+uuvxQ4a/v7+6tu3r/r27SvDMDRixAi9/fbbGjduXL7PVbduXUnSjh07nFdluGDHjh3Ox4tjzpw5OnfunLNdv379Qsc/88wzevfddzV27FgtXbpU0vn34MyZM87QW5AGDRpo2bJlOnnyZIFnZ7/88ktlZmZq4cKFqlOnjrP/wrKO0tC3b1+tWbNGn3zySYGXZ7tUWFhYnpsoZGVl6ejRo8U67oABAzR79mwlJCRo27ZtMk3TucRAuvje+/n5Xfa9BFA2sGYWQJnVv39/5ebm6oUXXsjzWE5OjjPcdO/eXcHBwZo4caIyMjJcxpmmWeDznzhxwqVtt9vVqlUrSVJmZma++7Rt21YRERGaMWOGy5glS5Zo27Zt6tOnT5Fe26U6duyouLg457/LhdkqVapo2LBhWrZsmTZt2iTp/Hu1Zs0aLVu2LM/406dPKycnR5J02223yTRNTZgwIc+4C+/VhbPJl753KSkp+uCDD4r92goyfPhw1ahRQ4899ph27tyZ5/Fjx47pH//4h7PdoEED57rfC955551iX+IsLi5OVatW1bx58zRv3jy1a9fOZUlCRESEbrzxRr399tv5BuXk5ORiHQ+A+3FmFkCZ1blzZw0bNkwTJ07Upk2b1L17d/n5+WnXrl2aP3++pk6dqr/+9a8KCQnR66+/rvvuu0/XXnutBg0apLCwMG3evFlnz54tcMnAfffdp5MnT6pr166qXbu2fv/9d73xxhtq06aNrrrqqnz38fPz0+TJkzV06FB17txZAwcOdF6aKyYmRo8++qg73xKnhx9+WFOmTNGkSZM0d+5cPfHEE1q4cKFuvvlm3X333YqNjVV6erq2bNmiBQsWaP/+/apevbq6dOmiO++8U//617+0a9cu9ezZU4Zh6LvvvlOXLl00atQode/e3XnGetiwYTpz5ozeffddRUREFPtMaEHCwsL02WefqXfv3mrTpo3LHcA2bNigjz76SB06dHCOv++++zR8+HDddttt6tatmzZv3qxly5apevXqxTqun5+fbr31Vs2dO1fp6el65ZVX8oyZNm2arr/+erVs2VL333+/6tevr6SkJK1Zs0aHDh3S5s2br+zFAyhdVl5KAUD5duEyST///HOh44YMGWJWqlSpwMffeecdMzY21gwMDDSDg4PNli1bmk8++aR55MgRl3ELFy40r7vuOjMwMNAMCQkx27VrZ3700Ucux7n00lwLFiwwu3fvbkZERJj+/v5mnTp1zGHDhplHjx51jvnjpbkumDdvnnn11VebDofDrFq1qjl48GDnpcYu97rGjx9vFuU/vxcuc/Xyyy/n+/jdd99t+vj4mLt37zZN0zTT0tLMMWPGmA0bNjT9/f3N6tWrm9ddd535yiuvmFlZWc79cnJyzJdfftls2rSp6e/vb4aHh5u9evUy169f7/JetmrVygwICDBjYmLMyZMnmzNnzjQlmfv27XOOK+mluS44cuSI+eijj5qNGzc2AwICzKCgIDM2NtZ88cUXzZSUFOe43Nxc86mnnjKrV69uBgUFmT169DB3795d4KW5CvuaW758uSnJtNls5sGDB/Mds2fPHvOuu+4yo6KiTD8/P7NWrVrmzTffbC5YsKBIrwuA59hMs5C/wQEAAABlGGtmAQAA4LUIswAAAPBahFkAAAB4LcIsAAAAvBZhFgAAAF6LMAsAAACvVeFummAYho4cOaLg4GDZbDarywEAAMAfmKaptLQ01axZU3Z74edeK1yYPXLkiKKjo60uAwAAAJdx8OBB1a5du9AxFS7MBgcHSzr/5oSEhLj9eIZhKDk5WeHh4Zf9zQJlE3Po/ZhD78ccejfmz/t5eg5TU1MVHR3tzG2FqXBh9sLSgpCQEI+F2YyMDIWEhPAN7KWYQ+/HHHo/5tC7MX/ez6o5LMqSUL6iAAAA4LUIswAAAPBahFkAAAB4rQq3ZhYAAFyUm5ur7Oxstx7DMAxlZ2crIyODNbNeyh1z6OfnJx8fnyt+HsIsAAAV1JkzZ3To0CGZpunW45imKcMwlJaWxjXevZQ75tBms6l27dqqXLnyFT0PYRYAgAooNzdXhw4dUlBQkMLDw90aMk3TVE5Ojnx9fQmzXqq059A0TSUnJ+vQoUNq1KjRFZ2hJcwCAFABZWdnyzRNhYeHKzAw0K3HIsx6P3fMYXh4uPbv36/s7OwrCrMsXAEAoAIjXMIqpfW1R5gFAACA1yLMAgAAwGsRZgEAAOC1CLMAAMBr3H333bLZbLLZbPL391fDhg31/PPPKycnR5K0atUq5+M2m03h4eHq3bu3tmzZUuRjNG3aVA6HQ4mJiXkei4mJ0ZQpU/L0P/fcc2rTpo1LX2Jioh566CHVr19fDodD0dHR6tu3rxISEor1motr/vz5atq0qQICAtSyZUstXry40PGXvqeX/mvevLlzzLfffqt+/fqpVq1astls+vzzz/M8T37PYbPZ9PLLL5f2S3RBmAUAAF6lZ8+eOnr0qHbt2qXHHntMzz33XJ7AtGPHDh09elTLli1TZmam+vTpo6ysrMs+9+rVq3Xu3Dn99a9/1ezZs0tc4/79+xUbG6uVK1fq5Zdf1pYtW7R06VJ16dJFI0eOLPHzXs4PP/yggQMH6t5779XGjRvVr18/9evXT7/++muB+0ydOlVHjx51/jt48KCqVq2q22+/3TkmPT1drVq10ptvvlng81z6HEePHtXMmTNls9l02223lepr/CMuzQUAALyKw+FQVFSUJOnBBx/UZ599poULF2rMmDHOMREREapSpYqioqL0yCOP6JZbbtH27dvVqlWrQp/7/fff16BBg9S5c2c9/PDDeuqpp0pU44gRI2Sz2bR27VpVqlTJ2d+8eXPdc889JXrOopg6dap69uypJ554QpL0wgsvaPny5XrzzTc1Y8aMfPcJDQ1VaGios/3555/r1KlTGjp0qLOvV69e6tatm3x9C46OF+bkgi+++EJdunRR/fr1r+QlXZalYfbbb7/Vyy+/rPXr1+vo0aP67LPP1K9fv0L3WbVqleLj47V161ZFR0dr7Nixuvvuuz1SLwAA5VnfN1YrOS3TLc9typRN+V+KKTzYoS8fur7Ezx0YGKgTJ07k+1hKSormzp0rSfL39y/0edLS0jR//nz99NNPatq0qVJSUvTdd9+pU6dOxarn5MmTWrp0qV588UWXIHtBlSpVCtx3zpw5GjZsWKHPv2TJkgJrWrNmjeLj4136evToke+ygIK8//77iouLU926dYu8zx8lJSVp0aJFV3R2u6gsDbPp6elq3bq17rnnHt16662XHb9v3z716dNHw4cP15w5c5SQkKD77rtPNWrUUI8ePTxQMQAA5VdyWqYSUzOsLqPITNNUQkKCli1bpoceesjlsdq1a0s6nzUk6ZZbblHTpk0Lfb65c+eqUaNGzrWif/vb3/T+++8XO8zu3r1bpmle9nj5ueWWW9S+fftCx9SqVavAxxITExUZGenSFxkZme/63/wcOXJES5Ys0Ycfflik8QWZPXu2goODi5TvrpSlYbZXr17q1atXkcfPmDFD9erV06uvvipJuuqqq7R69Wq9/vrrZTbMPrHgF51KS5fDcVhcl9o7maaUmZnBHF5GZEiAHuzcQBEhAR4/tmmaunBrefN/bbvNJrudCQOKIzzY4bbnvtyZ2eL46quvVLlyZWVnZ8swDA0aNEjPPfecy5jvvvtOQUFB+vHHH/XSSy8V+Cf2S82cOVN33HGHs33HHXeoc+fOeuONNxQcHFzk+swL/0EqgeDg4GIdq7TNnj1bVapUuexfyi9n5syZGjx4sAIC3P8zwavWzK5Zs0ZxcXEufT169NAjjzxS4D6ZmZnKzLz4J5PU1FRJkmEYMgzDLXVeasW2JKWcy3H7cYCy4IPv9ys82OESLqX/hU2d/8XA/EP7fM+lj53/oXehrf+NVYH7F6xH80h1aRKuXMNUWlqaKlU6J5vNpj/Vr6r64ZVL86XDzQzDkGmaHvnvdkVx4T298E+SFo7q6LbjZWdny8/Pr8DHixMAu3Tporfeekv+/v6qWbOmcx3npa8lJiZGVapUUePGjZWUlKQBAwbom2++KfA5f/vtN/34449au3atyzrZ3NxcffTRR7r//vslSSEhITp9+nSeek+dOqXQ0FCZpqmGDRvKZrNp27ZtxQ6Fc+bM0fDhwwsds3jx4gLPFkdFRSkxMdGlvsTEREVFRV32PTZN0xno/fz88oy/tH3pe/1H3333nXbs2KG5c+cWeswLz5FfJivO97pXhdmCTp2npqbq3Llz+d5beuLEiZowYUKe/uTkZGVkuP9PKYZR8t/OAG/krvV2JbFsa5KWbU3K97HmUZX0VNc6MnT++9Rut6lR9UD5cDa3TDIMQykpKefPutu5EE9puHBWMycnx3lZK3cxTVO5ubmSrvwWpoZhKDAwUDExMc6+S+u/cJxLX9ewYcM0adIkLViwoMBw+d5776lTp06aOnWqS/+///1vvf/++84PQzVq1Ejr1q3L855t2LBBjRs3Vk5OjkJCQtS9e3e99dZbGjFiRJ51s6dPny5w3Wzv3r31888/F/oe1KpVq8A5a9++vVasWKFRo0Y5+5YvX6727dtfdp6/+eYb7d69W0OGDMkz9tI5lM6/zwU933vvvadrrrlGzZs3L/SYOTk5MgxDJ06cyPOLTlpaWqG1XsqrwmxJjBkzxmUhdGpqqqKjoxUeHq6QkBC3H3/Jw9frxPETqlqtGn/y9FKGYerkCeawMG+u3KOVO47JbrPJZpNsuvD/ci7NsOl8x/k+m/OxC+3zY87/T36PO9/5fJ7/0rYpacOB05eteWtiuu76cFue/r9cXVO5hqlc4/yfRG+9ppaaRgUr1zQVFRJA2LWIYRjOa4YSZktHRkaG0tLS5OvrW+gn1EtTYWdmi8put8tutxdYs4+PjyS5vK6QkBDdd999euGFF3TbbbflCdTZ2dmaM2eOJkyYkOdasQ6HQ1OmTNGOHTvUvHlzxcfH64YbbtDkyZN16623Os/c/vjjj3rrrbecx5w2bZquv/56dezYURMmTFCrVq2Uk5Oj5cuXa8aMGfrtt9/yrT8sLExhYWElfn8eeeQR3XjjjZo6dar69OmjuXPnav369XrnnXectY0ZM0ZHjhzJ8+Gs2bNnq3379nneA0k6c+aMtm/f7nyOAwcO6Ndff1XVqlVVp04d57jU1FR98skneuWVVy77deXr6yu73a5q1arlWY5QnOUJXhVmo6KilJTkepYlKSlJISEh+Z6Vlc5/ETocedfiXPhmcLeaVYLkm3VGEWFB/AfYSxmGIb9s5rAwE28r/FI3nnb8TKYStiUpxzi/dlamqTNn0nQq21dvrdpT6L6fbTzi0v5qy1GX9q3X1FIlf1/lGIZycs+H3pz/hd/sXEN9WtVQi1qhzvb5/zcVGuirhhHWrYMrD2w2m8f+210R2O12lwvbu5Npmhd/aS2lYxX0PJce59IxDz30kF5//XUtWLBA/fv3d9nnyy+/1IkTJ3Trrbfmed5mzZrpqquu0syZM/Xaa6+pY8eOWrJkiZ5//nm99tprstvtatmypRISEtSyZUvnfg0aNNCGDRv04osv6vHHH9fRo0cVHh6u2NhYTZ8+3W3veceOHfXhhx9q7NixeuaZZ9SoUSN9/vnnLrUlJibqwIEDLjWkpKTok08+0dSpU/Otbd26deratauz/dhjj0mShgwZolmzZjn7582bJ9M0NWjQoMu+xgtzlN/3dXG+z23mlaxSLkU2m+2yl+Z66qmntHjxYpe7eAwaNMh5CYyiSE1NVWhoqFJSUjxyZtYwDB07dkwRERH8B9hLMYfe79I5zDZM/WfN79p97IxsNpt87NKiX47q1Nlsj9Ty8bAOalevqkeOVZ7wfVj6MjIytG/fPtWrV8/tH9IxTVM5OTny9fV1e3CGe7hjDgv7GixOXrP0zOyZM2e0e/duZ3vfvn3atGmT85T1mDFjdPjwYf373/+WJA0fPlxvvvmmnnzySd1zzz1auXKlPv74Yy1atMiqlwDAyzh8fXRfJ9cLeP+jX0sdP5Op02ezZLfZ5GO36bcjqVqw/pDsdpv2JJ/R3uT0Ujl+/7fXqE/LGnpj4NUsWwGAUmBpmF23bp26dOnibF9Y23rhlPXRo0d14MAB5+P16tXTokWL9Oijj2rq1KmqXbu23nvvvTJ7WS4A3qN6ZYeqV764JKlutUrq1bKGs30yPUv7jp+Rj90uX/v5wOtrt8nX53x7d/IZfbrhsGySfH1s8rPb5eNjk5/dptlrfnc51qItR7Voy1H1ahEl05Sycg1l5RjO/8/+3/8fS8vULa1r6pk+VynAz8dTbwUAeJUys8zAU1hmgOJiDr1fWZjDb3cm666Za0u8f9VK/jqZnqUnezZRTq6pzJxcZeUYqlklUHd1iCn3H0wrC3NY3rDMAMXBMgMAqOBuaByujeO6qd9b3+v3E2cLHevnY1N2rut5hpPpWZKkfy7dkWf8hC9/U9/WNZVrGBrT6ypFVw0qvcIBoIwjzAKAh4RV8tc3T3RRyrlsJadlyuFrl5+PXf6+5//5+djk73P+E+Yn07M0/P/Wa+2+k0V67i83n78Kw+It529ZOeGW5goO8FVGtiFTpm5qGqmwSn7KyDaUmZ2rjGxDWbm5iqlWSb4+nOmsyCrYH2hRhpTW1x5hFgA8LDTQT6GBhV9vs2olf308rIOzveVQivYePyOHr10OXx/5+dh1x/s/Fbj/+IVbXdrP6NcCx7aoFaJcQ/8Lubk6fiZLKx/vrOqVHazVLccuXI81KyurwMtbAu6UlXX+L04XvhZLijALAF6gZe1Qtawd6tK3f1IfJaedvwrDqh3JenFx3ptAFMWvh1Pz9F0/+Wvn9sy726pBeGXVrVYpzzh4L19fXwUFBSk5OVl+fn5uXYvMmlnvV9pzaBiGkpOTFRQUdMU37SDMAoAXCw92KDzYoUaRwbr/hvr6ef9J/bjnhPx97Qrw89He5DNatOWoalUJlMPPRwF+PgrwtWv/iXTtTDrjfB5/X7uycvK/F/o9s9ZJkq5vWF2xdcOUkZ2r7FxT3ZtHqlXtUAX586PEG9lsNtWoUUP79u3T77//fvkdroBpmjIMw3mjBngfd8yh3W5XnTp1rvj5uJqBm/EJXO/HHHo/5jB/uYaprBxDDl+785q3byTs0qItR7U9sWj3Ra/s8NWK+M6KCnXvp+GZQ/cxDMP55153HuPEiROqVq0a8+el3DGH/v7+BT4XVzMAAFyWj92mQH/XtWoP3dRID93USJI06/t9+uVQij7deLjA5ziTmaM/TUzQ366N1o1NwhUc4KfosCDVqcYVFbyF3W53+6W5DMOQn5+fAgICCLNeqizPIWEWAJCvuzvWkyTFd2+sn/efVICvjwL9ffTTvpOavmqPy9i5Px/U3J8PuvQFB/jqpb+0VEy1SmpeM4Q7ngFwC8IsAKBQtcOCVDvs4pnWG5tE6O9dG+mqZ5cWul9aRo4e+mijs737xV5cBgxAqSPMAgCKLdDfR/sn9dHOpDR9t+u4fjl0WmFB/pr1w/4C92n4zBLt+EdPOXy53BeA0kOYBQCUWOPIYDWODHa2n7uluUzT1MLNR7RkS6KWbk10Gd9k7FIt+vv1al4z9I9PBQAlwt97AAClymaz6c9tamnGnbHa/kLPPI/3+ddqpWVkW1AZgPKIMAsAcJsAPx9tGNdNfj6uH/5q+dx/FTN6kdb/fsqiygCUF4RZAIBbVa3kr53/6KUuTcLzPHbb9B8KvFkDABQFYRYA4HY2m03T74jVTU0j8jz24U+/KyM714KqAJQHfAAMAOARAX4+ev/uayVJN7/xnX49nCpJeu7L3/Tcl79JklrXDtX84dfJ35dzLQCKhv9aAAA87vHuTfLt33woRY3HLuFMLYAi48wsAMDjrm9YXXd1qKuf95/StqOpeR5vOm6pggN8Vdnhq3fvaqtmNYLzeRYAIMwCACzg62PX839uIUkyTVMn07MU+48VLmPSMnKUlpGjm99YrWE31Nefavnr4LlTahVdhRsvAHAizAIALGWz2VStskP7J/VRh4kJOpqSkWfM29/u1dt/6Pt+dFfVqhLomSIBlFmEWQBAmbFmzE3KyjF0+lyW7v/3em0+eLrAsR0nrZQk+fvYtfChjmoaFeKhKgGUJXwADABQpvj72hURHKAvRnbUJw9epyaRwereLFKBfvn/yMrKNdRzync6m5Xj4UoBlAWcmQUAlFmxdcO07NEbZBiGjh07pvDwcI3+9FfNX38oz9hmzy6TJDWJDNbjPZro+obVFejP2lqgvOPMLADAa9hsNr18e2vtn9RHvzzXXf4+eX+M7UhK0/3/Xqernl2qnFzuLgaUd4RZAIBXCgnw0y/PdS90zJ7kdA9VA8AqLDMAAHitAD8f7Z/UR5k5uUo9l6MXF/2mzzcdcT6eY3BmFijvODMLAPB6Dl8fhQc7NOVvV2tw+zrO/j7/Wq2T6VkWVgbA3QizAIBy5WyW661wJy/ZblElADyBMAsAKFde6NfCpT1v3UGZpmlRNQDcjTALAChXKjt89fnIji59bZ5fblE1ANyNMAsAKHcaR1Z2aaecy9Z/1uy3phgAbkWYBQCUO0H+vvrmiRtd+sZ9sVUxoxdp6a9HrSkKgFsQZgEA5VLdapXUqnZonv7h/7dBMaMXKS0j24KqAJQ2wiwAoNxaOOp6zbjjmnwfa/ncfzV91R4PVwSgtBFmAQDlWs8WNbTlue568S8t8jw2eel2ffXLkXz2AuAtCLMAgHIvOMBPg9vX1d6Xeud5bNSHGzXwnR9lGFy+C/BGhFkAQIVht9u0f1IfPdatsUv/mr0nVP/pxcrK4fa3gLchzAIAKpyHbmqkf/61VZ7+xmOXcIMFwMsQZgEAFVL/ttFaEd85T/+cnw5YUA2AkiLMAgAqrIYRlfXzM3EufWM//1Up57hsF+AtCLMAgAotPNih2fe0c+njkl2A9yDMAgAqvLZ1w1zaCduSLKoEQHERZgEAFV4lh6/mPvAnZ3vXsTNKTMmwsCIARUWYBQBAUuvaVVzaXV9dZUkdAIqHMAsAgKRAfx/d2CTc2T6blauZq/dZWBGAoiDMAgDwP1MHXO3Sfv6r37T+95MWVQOgKAizAAD8T2iQnx6Nc7072O8nzlpUDYCiIMwCAHCJh+MaaVD7Os52/MebLawGwOUQZgEA+IOro6u4tI+fybSmEACXRZgFAOAP+rau6dIe/8VWiyoBcDmEWQAA/iDAz8dlqcHRlHMWVgOgMIRZAADy8VTPps7tDQdOa+mviRZWA6AghFkAAPJRyd/HpT38/9brifl8GAwoawizAADkw9fHrtuuqe3SN3/9IYuqAVAQwiwAAAV4tX9rvTX4Gpe+jOxci6oBkB/CLAAAhejdsoZL+zGWGgBlCmEWAIDLqFstyLm96Jej2nc83cJqAFyKMAsAwGXMH9bBpd3llVVa+utRi6oBcCnCLAAAlxEREqAqQX4ufcP/b4MMw7SoIgAXEGYBACiCjeO66dqYMJe+bYmpFlUD4ALCLAAARWCz2TR/+HUufeeyuLIBYDXCLAAAxXB/p3rO7Y0HTltXCABJhFkAAIolLSPHuf3i4m06lZ5lYTUACLMAABRDjxZRLu1tR1k3C1iJMAsAQDF0aRKhqpX8ne0dSWkWVgOAMAsAQDH9uU1N5/Zbq/ZYWAkAwiwAAMX0p/rVnNvJaZkWVgKAMAsAQDF1aRLh0ibQAtYhzAIAUEz+vnZFBDuc7eksNQAsQ5gFAKAEWtYKdW5zRQPAOoRZAABK4Jk+Vzm31+w9odSMbAurASouwiwAACVQIzTQpT137QGLKgEqNsIsAAAlEOjv47Ju9qXF25VrmBZWBFRMlofZadOmKSYmRgEBAWrfvr3Wrl1b6PgpU6aoSZMmCgwMVHR0tB599FFlZGR4qFoAAC6aNvgal/bq3cctqgSouCwNs/PmzVN8fLzGjx+vDRs2qHXr1urRo4eOHTuW7/gPP/xQo0eP1vjx47Vt2za9//77mjdvnp5++mkPVw4AgHRtTFWX9qn0LIsqASouS8Psa6+9pvvvv19Dhw5Vs2bNNGPGDAUFBWnmzJn5jv/hhx/UsWNHDRo0SDExMerevbsGDhx42bO5AAC4y/i+zawuAajQfK06cFZWltavX68xY8Y4++x2u+Li4rRmzZp897nuuuv0f//3f1q7dq3atWunvXv3avHixbrzzjsLPE5mZqYyMy9ezDo19fzlUwzDkGEYpfRqCmYYhkzT9Mix4B7MofdjDr1fmZ5D8+I62R2JqTKMGhYWUzaV6flDkXh6DotzHMvC7PHjx5Wbm6vIyEiX/sjISG3fvj3ffQYNGqTjx4/r+uuvl2maysnJ0fDhwwtdZjBx4kRNmDAhT39ycrJH1toahqGUlBSZpim73fIlyigB5tD7MYferyzP4enUNOf29G/26s9Ng1Ul0LIfr2VSWZ4/FI2n5zAtLe3yg/7Hq77bVq1apZdeeklvvfWW2rdvr927d+vhhx/WCy+8oHHjxuW7z5gxYxQfH+9sp6amKjo6WuHh4QoJCXF7zYZhyGazKTw8nG9gL8Ucej/m0PuV5TmMa+XQ1G8POdv9Z2/Vpme7WVhR2VOW5w9F4+k5DAgIKPJYy8Js9erV5ePjo6SkJJf+pKQkRUVF5bvPuHHjdOedd+q+++6TJLVs2VLp6el64IEH9Mwzz+T75jocDjkcjjz9drvdY99QNpvNo8dD6WMOvR9z6P3K6hy2rB2mkABfpWbkSJJSM3KUfCZLkSFF/2FcEZTV+UPReXIOi3MMy76i/P39FRsbq4SEBGefYRhKSEhQhw4d8t3n7NmzeV6cj4+PJMk0ubYfAMAaG8a5nold+muiRZUAFY+lvx7Fx8fr3Xff1ezZs7Vt2zY9+OCDSk9P19ChQyVJd911l8sHxPr27avp06dr7ty52rdvn5YvX65x48apb9++zlALAICn+frYdV2Das72+IVbLawGqFgsXTM7YMAAJScn69lnn1ViYqLatGmjpUuXOj8UduDAAZczsWPHjpXNZtPYsWN1+PBhhYeHq2/fvnrxxRetegkAAEiSBrWvox/2nHC21+0/qbZ/uA4tgNJnMyvY3+dTU1MVGhqqlJQUj30A7NixY4qIiGCdkJdiDr0fc+j9vGEOU85mq/Xz/3W2m0QGa9mjN1hYUdnhDfOHwnl6DouT1/iKAgCgFIQG+bncQCE1I9vCaoCKgzALAEApGdiujnM7PDjvlXQAlD7CLAAApSTAz0d22/ntXw6lKCuHO14B7kaYBQCgFBmXfBLl1unfW1cIUEEQZgEAKEVRl9ws4dfDqerzr++4FjrgRoRZAABK0bJHXK9gsPVIqj5ae9CiaoDyjzALAEApCg3y06u3t3bpe/qzLRZVA5R/hFkAAErZbbG19eH97Z3t0EA/C6sByjfCLAAAbtCh/sXb21Z2WHrDTaBcI8wCAOAGNptNEf+71uzh0+f4EBjgJoRZAADc5NK7gO1JPmNhJUD5RZgFAMBNMrIv3jRh88EUCysByi/CLAAAbnJ7bG3n9mPzN8swWGoAlDbCLAAAbtK1aYRL+7ejqRZVApRfhFkAANykZ4sol/ala2gBlA7CLAAAbmKz2TTixgZWlwGUa4RZAAAAeC3CLAAAALwWYRYAAA9Z/luS1SUA5Q5hFgAAN7LZLm5/8P1+nUzPsq4YoBwizAIA4EYd6ld3af9y6LQ1hQDlFGEWAAA3ur5RdbWJruJsc9sEoHQRZgEAcLMuTSIuPwhAiRBmAQDwoOwcw+oSgHKFMAsAgJsZ5sXFBTO/32dhJUD5Q5gFAMDNKjl8nNvbE9MsrAQofwizAAC4WdxVkc7t02ezNXM1Z2eB0kKYBQDAzaJCA1zaz3/1m0WVAOUPYRYAADcL8vfVpFtbWl0GUC4RZgEA8IC/tasjPx/b5QcCKBbCLAAAHtKiVqhz+9CpsxZWApQfhFkAADxk6+FU5/bGA6etKwQoRwizAAB4yN/aRTu3L732LICSI8wCAOAhMdUqObefWPCLhZUA5QdhFgAADwnwu3jzhKwcQ4bB2VngShFmAQDwkP5ta7u03/x6t0WVAOUHYRYAAA/x9XH9sfvZxsMWVQKUH4RZAAA8aOkjnZzb0VWDLKwEKB8IswAAeFDNKoFWlwCUK4RZAAAs8u3OZB1Ly7C6DMCrEWYBAPAgX7vrLW3bvZhgUSVA+UCYBQDAg4L8fVU7zHWpQXpmjkXVAN6PMAsAgId992QXl3Z6FmEWKCnCLAAAHmaz2RR3VYSz/d3O4xZWA3g3wiwAABbYdzzduX3qbJaFlQDejTALAIAFRtzY0Llts9kKGQmgMIRZAAAs4O/Lj2CgNPCdBACAxX7ae8LqEgCvRZgFAMACl15v9r+/Jck0TQurAbwXYRYAAAv8qX41l/bRFO4EBpQEYRYAAAuEVfJ3aecanJkFSoIwCwCARfq0quHc/u9vSRZWAngvwiwAABY5dOqcczszJ9fCSgDvRZgFAMAiw26o79y2iWvNAiVBmAUAwCI+dgIscKUIswAAAPBahFkAAAB4LcIsAABlwIkzmVaXAHglwiwAAGXAe6v3cRcwoAQIswAAWKRpVLBL++DJcwWMBFAQwiwAABapW62SSzs9K8eiSgDvRZgFAMBCt15Ty7nda+p3FlYCeCfCLAAAFrLbLl5rNqZakIWVAN6JMAsAgIUm3trSuc1NFIDiI8wCAGAhPx+7ggN8rS4D8FqEWQAAAHgtwiwAAAC8FmEWAAAAXoswCwBAGZFrcAcwoLgIswAAlBH7T5xVdq5hdRmAVyHMAgBgsbSMi3f+2pN8xsJKAO9DmAUAwGK1qgQ6tw1OzALFQpgFAMBinZuEO7dZNwsUj+Vhdtq0aYqJiVFAQIDat2+vtWvXFjr+9OnTGjlypGrUqCGHw6HGjRtr8eLFHqoWAIDSZ1wSYD/ZcMjCSgDvY+ktR+bNm6f4+HjNmDFD7du315QpU9SjRw/t2LFDERERecZnZWWpW7duioiI0IIFC1SrVi39/vvvqlKliueLBwCglGRk5zq3A/19LKwE8D6Wnpl97bXXdP/992vo0KFq1qyZZsyYoaCgIM2cOTPf8TNnztTJkyf1+eefq2PHjoqJiVHnzp3VunVrD1cOAEDp6X9ttHP74MmzFlYCeB/LzsxmZWVp/fr1GjNmjLPPbrcrLi5Oa9asyXefhQsXqkOHDho5cqS++OILhYeHa9CgQXrqqafk45P/b7KZmZnKzMx0tlNTUyVJhmHI8MAqe8MwZJqmR44F92AOvR9z6P3K/RyaF5cZfPXLUf3rb+XrdZb7+asAPD2HxTmOZWH2+PHjys3NVWRkpEt/ZGSktm/fnu8+e/fu1cqVKzV48GAtXrxYu3fv1ogRI5Sdna3x48fnu8/EiRM1YcKEPP3JycnKyMi48hdyGYZhKCUlRaZpym63fIkySoA59H7Mofcr73NYxZ7t3K4R4q9jx45ZWE3pK+/zVxF4eg7T0tKKPNbSNbPFZRiGIiIi9M4778jHx0exsbE6fPiwXn755QLD7JgxYxQfH+9sp6amKjo6WuHh4QoJCfFIzTabTeHh4XwDeynm0Psxh96vvM/h+U+J/CJJ8vHxyfdzI96svM9fReDpOQwICCjyWMvCbPXq1eXj46OkpCSX/qSkJEVFReW7T40aNeTn5+eypOCqq65SYmKisrKy5O/vn2cfh8Mhh8ORp99ut3vsG8pms3n0eCh9zKH3Yw69X3mfw+qVHTp+5vyyuPL4Gsv7/FUEnpzD4hzDsq8of39/xcbGKiEhwdlnGIYSEhLUoUOHfPfp2LGjdu/e7bKOYufOnapRo0a+QRYAAG9z6NQ5l0t1ASicpb8excfH691339Xs2bO1bds2Pfjgg0pPT9fQoUMlSXfddZfLB8QefPBBnTx5Ug8//LB27typRYsW6aWXXtLIkSOtegkAAJSKC2dlJWnEnA0WVgJ4F0vXzA4YMEDJycl69tlnlZiYqDZt2mjp0qXOD4UdOHDA5TRzdHS0li1bpkcffVStWrVSrVq19PDDD+upp56y6iUAAFDqlm5N1Mc/H3S5ZBeA/NlM06xQf8tITU1VaGioUlJSPPYBsGPHjikiIoJ1Ql6KOfR+zKH3qwhz+OvhFN38xmpnu3plh9aNjbOwotJTEeavvPP0HBYnr/EVBQBAGdCiVqie6NHE2T5+JlNf7yhfl+gC3IEwCwBAGXF/p/ou7aEf/GxRJYD3IMwCAFBG+PvaNbxzA6vLALwKYRYAgDLkqZ4XlxoE+PFjGrgcvksAAChDbDabmkYFW10G4DUIswAAAPBahFkAAMqojGxDqRnZVpcBlGmEWQAAypidSWnO7XX7T1pYCVD2legOYLm5uZo1a5YSEhJ07NgxGYbh8vjKlStLpTgAACqidvWq6se950PsPbPWac9LveVjt1lcFVA2lSjMPvzww5o1a5b69OmjFi1ayGbjGwwAgNLSq0UNZ5iVpJ/2ndB1DapbWBFQdpUozM6dO1cff/yxevfuXdr1AABQ4fVtXVPjF251tk+mZ1lYDVC2lWjNrL+/vxo2bFjatQAAAElVK/lrbJ+rrC4D8AolCrOPPfaYpk6dKtM0S7seAADwB6M+3Gh1CUCZVaJlBqtXr9bXX3+tJUuWqHnz5vLz83N5/NNPPy2V4gAAqKj8fV3PN+1ITFMTbqYA5FGiMFulShX95S9/Ke1aAADA//RvG61nv7i4bnbFtiTCLJCPEoXZDz74oLTrAAAAlwjw89HILg007es9kqQPfzqgkV34vArwR1d004Tk5GStXr1aq1evVnJycmnVBAAAJHVqFO7cbhRZ2cJKgLKrRGE2PT1d99xzj2rUqKEbbrhBN9xwg2rWrKl7771XZ8+eLe0aAQCokK6KCrG6BKDMK1GYjY+P1zfffKMvv/xSp0+f1unTp/XFF1/om2++0WOPPVbaNQIAAAD5KtGa2U8++UQLFizQjTfe6Ozr3bu3AgMD1b9/f02fPr206gMAAJJW7UhWZk6uHL4+VpcClCklOjN79uxZRUZG5umPiIhgmQEAAKXE18f1dvHLtiZZVAlQdpUozHbo0EHjx49XRkaGs+/cuXOaMGGCOnToUGrFAQBQkVVyuP4BNS0j26JKgLKrRMsMpk6dqh49eqh27dpq3bq1JGnz5s0KCAjQsmXLSrVAAAAqsn/e1kpPfvKLJOmNhN0a3L6uxRUBZUuJwmyLFi20a9cuzZkzR9u3b5ckDRw4UIMHD1ZgYGCpFggAQEUWHHDxR3ViaoZM05TNZitkD6BiKVGYlaSgoCDdf//9pVkLAAD4g65XRbi0T5/NVlglf4uqAcqeIofZhQsXqlevXvLz89PChQsLHXvLLbdccWEAAEB5rl5gmKZFlQBlU5HDbL9+/ZSYmKiIiAj169evwHE2m025ubmlURsAAJAUd1WEVmw7ZnUZQJlU5DBrGEa+2wAAAIBVSnRprvycPn26tJ4KAABc4tKVBT/sOWFdIUAZVKIwO3nyZM2bN8/Zvv3221W1alXVqlVLmzdvLrXiAACAtOvYGed2UmpGISOBiqdEYXbGjBmKjo6WJC1fvlwrVqzQ0qVL1atXLz3xxBOlWiAAABXdqC4Nndv/WLTNwkqAsqdEl+ZKTEx0htmvvvpK/fv3V/fu3RUTE6P27duXaoEAAFR0dasFubTTM3Py3B0MqKhKdGY2LCxMBw8elCQtXbpUcXFxkiTTNLmSAQAApaxdvaou7ZRz3NYWuKBEYfbWW2/VoEGD1K1bN504cUK9evWSJG3cuFENGza8zN4AAKA4bDabujQJt7oMoEwqUZh9/fXXNWrUKDVr1kzLly9X5cqVJUlHjx7ViBEjSrVAAAAgBflfXFawevdxCysBypYSLbjx8/PT448/nqf/0UcfveKCAABAXvuOpzu3n1zwi/q3jbawGqDs4Ha2AAB4gXE3N9PAd390tjOycxXg51PIHkDFwO1sAQDwAh0aVHNpH03JUL3qlSyqBig7uJ0tAABe4tqYMP28/5TVZQBlSqndzhYAALhXdNjF683OXXvAwkqAsqNEYfbvf/+7/vWvf+Xpf/PNN/XII49caU0AACAfR1Mu3sr27W/3WlgJUHaUKMx+8skn6tixY57+6667TgsWLLjiogAAQF7P9LnKud0oorKFlQBlR4nC7IkTJxQaGpqnPyQkRMePc+07AADcoUWtUPnYbVaXAZQpJQqzDRs21NKlS/P0L1myRPXr17/iogAAQP4C/3c5rl3Hzig9M8fiagDrleimCfHx8Ro1apSSk5PVtWtXSVJCQoJeffVVTZkypTTrAwAAlzhzSYBtPn6Z9k/qY2E1gPVKFGbvueceZWZm6sUXX9QLL7wgSYqJidH06dN11113lWqBAADgogA/uzKyuUQmcEGJL8314IMP6tChQ0pKSlJqaqr27t1LkAUAwM1+m9DTpZ2UmlHASKBiKHGYzcnJ0YoVK/Tpp5/KNE1J0pEjR3TmzJlSKw4AALiy/+EDYIkphFlUbCVaZvD777+rZ8+eOnDggDIzM9WtWzcFBwdr8uTJyszM1IwZM0q7TgAA8D+3x9bW/PWHrC4DKBNKdGb24YcfVtu2bXXq1CkFBgY6+//yl78oISGh1IoDAAB5Bfn7OLdTzmVbWAlgvRKdmf3uu+/0ww8/yN/f36U/JiZGhw8fLpXCAABA/s5m5Tq3F24+ohsah1tYDWCtEp2ZNQxDubm5efoPHTqk4ODgKy4KAAAULDIkwLldJdDPwkoA65UozHbv3t3lerI2m01nzpzR+PHj1bt379KqDQAA5OPGJpyJBS4o0TKDV155RT179lSzZs2UkZGhQYMGadeuXapevbo++uij0q4RAAAAyFeJwmx0dLQ2b96sefPmafPmzTpz5ozuvfdeDR482OUDYQAAwL3eW71PT/e+Ks8lu4CKothhNjs7W02bNtVXX32lwYMHa/Dgwe6oCwAAFOCPwXVbYqqa1wy1qBrAWsVeM+vn56eMDC7QDACAVZrVCHFpX3p1A6CiKdEHwEaOHKnJkycrJyentOsBAACXEeDno3s61rO6DKBMKNGa2Z9//lkJCQn673//q5YtW6pSpUouj3/66aelUhwAAMifr8/FpQaLfjmqa2OqWlgNYJ0ShdkqVarotttuK+1aAABAEaVecuevjGyWGaDiKlaYNQxDL7/8snbu3KmsrCx17dpVzz33HFcwAADAw269prbm/nxQkpSVa1hcDWCdYq2ZffHFF/X000+rcuXKqlWrlv71r39p5MiR7qoNAAAUINDPx7n96QZuJY+Kq1hh9t///rfeeustLVu2TJ9//rm+/PJLzZkzR4bBb4QAAHhSVGjA5QcBFUCxwuyBAwdcblcbFxcnm82mI0eOlHphAACgYOHBDpf2/uPpFlUCWKtYYTYnJ0cBAa6/Cfr5+Sk7O7uAPQAAgCfEf7zJ6hIASxTrA2Cmaeruu++Ww3Hxt8GMjAwNHz7c5fJcXJoLAAD3u+NPdfR/Px6QJG04cNraYgCLFCvMDhkyJE/fHXfcUWrFAACAonuie1NnmJWkXMOUzx9udQuUd8UKsx988IG76gAAAMUUGuTn0t544JTacvMEVDAlup0tAAAoG/x9L/4oTznHZ1hQ8RBmAQDwYn/v2tDqEgBLEWYBACgnvtmZbHUJgMcRZgEA8GKZORdvXLTtaKqFlQDWIMwCAODFbroq0rn98/5TFlYCWKNMhNlp06YpJiZGAQEBat++vdauXVuk/ebOnSubzaZ+/fq5t0AAAMqoBuGVLj8IKMcsD7Pz5s1TfHy8xo8frw0bNqh169bq0aOHjh07Vuh++/fv1+OPP65OnTp5qFIAAMqe4ADXy3PlGqZFlQDWsDzMvvbaa7r//vs1dOhQNWvWTDNmzFBQUJBmzpxZ4D65ubkaPHiwJkyYoPr163uwWgAAyp5Lz85+tPZAISOB8qdYN00obVlZWVq/fr3GjBnj7LPb7YqLi9OaNWsK3O/5559XRESE7r33Xn333XeFHiMzM1OZmZnOdmrq+cXxhmHIMIyCdis1hmHINE2PHAvuwRx6P+bQ+zGHhTt46pxze+7aAxrULtrCavJi/ryfp+ewOMexNMweP35cubm5ioyMdOmPjIzU9u3b891n9erVev/997Vp06YiHWPixImaMGFCnv7k5GRlZGQUu+biMgxDKSkpMk1TdrvlJ8JRAsyh92MOvR9zWLjX/txAoz7ZJUn69Uiq9h08qkoOH4uruoj5836ensO0tLQij7U0zBZXWlqa7rzzTr377ruqXr16kfYZM2aM4uPjne3U1FRFR0crPDxcISEh7irVyTAM2Ww2hYeH8w3spZhD78ccej/msHDXBoZK2uVsv/3zcU26taV1Bf0B8+f9PD2HAQEBRR5raZitXr26fHx8lJSU5NKflJSkqKioPOP37Nmj/fv3q2/fvs6+C6ehfX19tWPHDjVo0MBlH4fDIYfDkee57Ha7x76hbDabR4+H0sccej/m0PsxhwWLCHH9wb/taFqZe5+YP+/nyTkszjEs/Yry9/dXbGysEhISnH2GYSghIUEdOnTIM75p06basmWLNm3a5Px3yy23qEuXLtq0aZOio8vWGiEAADzBZrNp5WOdne2I4LwncYDyyvJlBvHx8RoyZIjatm2rdu3aacqUKUpPT9fQoUMlSXfddZdq1aqliRMnKiAgQC1atHDZv0qVKpKUpx8AgIqkSpC/1SUAlrA8zA4YMEDJycl69tlnlZiYqDZt2mjp0qXOD4UdOHCAP0kAAAAgX5aHWUkaNWqURo0ale9jq1atKnTfWbNmlX5BAAB4sYTthd94CChPOOUJAEA54Odjc2ln5uRaVAngWYRZAADKAW5ri4qKMAsAQDnRsWE1q0sAPI4wCwAAAK9FmAUAoBzKyC76ve0Bb0aYBQCgnDiVnu3cvm36DxZWAngOYRYAgHKicsDFK27uO56u9MwcC6sBPIMwCwBAOTFlQBuXdlYOSw1Q/hFmAQAoJ2pWCVSXJuFWlwF4FGEWAIByxGazXX4QUI4QZgEAAOC1CLMAAJQjpnnxzl/PLtxqYSWAZxBmAQAoRw6cPOvc3vD7KQsrATyDMAsAQDky94EOzu2wSn4WVgJ4BmEWAIByJCzoYoD99XCqMnNyLawGcD/CLAAA5Yj9D1czeCNht0WVAJ5BmAUAoByx2226NM+++fVulw+FAeUNYRYAgHJmRXxnl/ahU+csqgRwP8IsAADlTIPwyi7tjQdPW1MI4AGEWQAAyqG2dcOc27uT0iysBHAvwiwAAOXQbbG1ndv+vvy4R/nFVzcAAOVQRLDD6hIAjyDMAgBQzv12NNXqEgC3IcwCAFAOXXp5rsVbEq0rBHAzwiwAAOVQ69pVXNpjPv3FmkIANyPMAgBQDlWr7Lpm9qO1By2qBHAvwiwAAOXUyscu3jyhXvVKFlYCuA9hFgCAcqp+eGVVCfKzugzArQizAAAA8FqEWQAAKoB9x9NlmqbVZQCljjALAEA5dvpstnN7T3K6hZUA7kGYBQCggkjNyL78IMDLEGYBACjH7vxTXef2Qx9utLASwD0IswAAlGPVL7ne7OHT53Q05ZyF1QCljzALAEA5dl+nei7tSUu2W1QJ4B6EWQAAyrFKDl/1aB7pbP9yKMXCaoDSR5gFAKCce6hrI+f2vuNc0QDlC2EWAIByrlFkZZf2gRNnLaoEKH2EWQAAyjmHr49L+5tdyRZVApQ+wiwAABVA/7a1ndvf7iTMovwgzAIAUAF0ahTu3K5e2d/CSoDSRZgFAKACuHTd7EdrD1pYCVC6CLMAAFQAAX9YNwuUF4RZAAAqgLrVglzab67cZVElQOkizAIAUAHYbDb5+dic7Vf+u1NpGdkWVgSUDsIsAAAVxLN9m7u01+w5YVElQOkhzAIAUEHc+ae6al+vqrP9wH/WK5Wzs/ByhFkAACqQ/m2jXdqTl2y3qBKgdBBmAQCoQG6Lre3SnvPTAYsqAUoHYRYAgApmRXxnl/ax1AyLKgGuHGEWAIAKpkF4JZf2t7uOW1QJcOUIswAAVDA2m003t6rhbBumaWE1wJUhzAIAUAFd16C6c/vwqXMWVgJcGcIsAAAV0KVnYz9ed9DCSoArQ5gFAKACalEr1LndMKKyhZUAV4YwCwBABXTph8C2HE6xsBLgyhBmAQCo4E6fzVZWjmF1GUCJEGYBAKiAKjt8Xdpf/XLEokqAK0OYBQCgArLZbIoIdjjbs3/Yb10xwBUgzAIAUEGN79vcub35EOtm4Z0IswAAVFCdm4S7tNMzcyyqBCg5wiwAABXUH9fNEmbhjQizAABUYHFXRTq3c7mtLbwQYRYAgArs0juBDf3gZwsrAUqGMAsAQAWWY1wMs9sT02QYnJ2FdyHMAgBQgb1zZ6xLe/2BUxZVApQMYRYAgAoswM9HAX4X48DtM9bo4MmzFlYEFA9hFgCACu6O9nVd2p3++bVFlQDFR5gFAKCCG3tzszx9rJ2FtyDMAgAA7Z/Ux6W99/gZiyoBiocwCwAAJEm+dptzOzPHsLASoOgIswAAQJI04Npoq0sAio0wCwAA8th6ONXqEoAiKRNhdtq0aYqJiVFAQIDat2+vtWvXFjj23XffVadOnRQWFqawsDDFxcUVOh4AABTNqbNZzu0nP/nFwkqAorM8zM6bN0/x8fEaP368NmzYoNatW6tHjx46duxYvuNXrVqlgQMH6uuvv9aaNWsUHR2t7t276/Dhwx6uHACA8uX2theXGdSqEmhhJUDRWR5mX3vtNd1///0aOnSomjVrphkzZigoKEgzZ87Md/ycOXM0YsQItWnTRk2bNtV7770nwzCUkJDg4coBAChfujSJsLoEoNh8rTx4VlaW1q9frzFjxjj77Ha74uLitGbNmiI9x9mzZ5Wdna2qVavm+3hmZqYyMzOd7dTU82uADMOQYbj/k5qGYcg0TY8cC+7BHHo/5tD7MYeeEx7sUHLa+Z+bpfV+M3/ez9NzWJzjWBpmjx8/rtzcXEVGRrr0R0ZGavv27UV6jqeeeko1a9ZUXFxcvo9PnDhREyZMyNOfnJysjIyM4hddTIZhKCUlRaZpym63/EQ4SoA59H7MofdjDj3HyM2VJB0+fU6HjiTK3/fK32/mz/t5eg7T0tKKPNbSMHulJk2apLlz52rVqlUKCAjId8yYMWMUHx/vbKempio6Olrh4eEKCQlxe42GYchmsyk8PJxvYC/FHHo/5tD7MYeec+JsjnN7V5q9VJYeMH/ez9NzWFCuy4+lYbZ69ery8fFRUlKSS39SUpKioqIK3feVV17RpEmTtGLFCrVq1arAcQ6HQw6HI0+/3W732DeUzWbz6PFQ+phD78ccej/m0DMuXWZw7+z1ee4MVlLMn/fz5BwW5xiWfkX5+/srNjbW5cNbFz7M1aFDhwL3++c//6kXXnhBS5cuVdu2bT1RKgAAFcIjcY2sLgEoFst/PYqPj9e7776r2bNna9u2bXrwwQeVnp6uoUOHSpLuuusulw+ITZ48WePGjdPMmTMVExOjxMREJSYm6swZ7iENAMCVGtSujkt78tKifYYFsIrla2YHDBig5ORkPfvss0pMTFSbNm20dOlS54fCDhw44HKqefr06crKytJf//pXl+cZP368nnvuOU+WDgBAuWOz2Vza01ft0VM9m1pUDXB5lodZSRo1apRGjRqV72OrVq1yae/fv9/9BQEAUIF98uB1um36D5KkkIAyERWAAlm+zAAAAJQtsXXDFF31/B3AzmTmXGY0YC3CLAAAyMPP53xEMEzp6x3532IeKAsIswAAII+9yenO7Tk/HrCwEqBwhFkAAJDHszc3c25XcvhYWAlQOMIsAADI44bG4c7tLzYd0d5kLoGJsokwCwAA8qhayd+l3fXVb5x3BgPKEsIsAADI449hVpKufXGFUs5lW1ANUDDCLAAAyNe+ib1Vp2qQS99TC36xqBogf4RZAACQL5vNpq/+fr1L39HUDIuqAfJHmAUAAAUKCfDTD6O7OtsBvkQHlC18RQIAgEJVcly8pe1P+05qV1KahdUArgizAACgUIF+rteZ7fb6t2r0zGKLqgFcEWYBAECh/H3tahRR2aUvO9fUyfQsiyoCLiLMAgCAy1oe31n3d6rn0rf9aKpF1QAXEWYBAECRPNOnmdrWDXO21/9+ysJqgPMIswAAoMhubHLxNrevLt+pI6fPWVgNQJgFAADFcM0lZ2Yl6bpJK5WTa1hUDUCYBQAAxdAupmqevsfmb7agEuA8wiwAACgyXx+79k/q49L3xaYjWrXjmEUVoaIjzAIAgGJbPzbOpX33Bz9zqS5YgjALAACKrVplh/q0rOHS9/nGwxZVg4qMMAsAAEpk2uBr1LVphLO9+dBp64pBhUWYBQAAJda/bbRz+4tNRyysBBUVYRYAAJRY85ohLu1zWbkWVYKKijALAABKLLpqkEu7+filysrhurPwHMIsAAC4Itc1qObcNkxpzd4TFlaDioYwCwAArsi0Qde4tGes2mNRJaiICLMAAOCKhFXy1zO9r3K21+w9oV1JaRZWhIqEMAsAAK5Yv6trubS7vf6tYkYvUlJqhkUVoaIgzAIAgCsWHuzIt7/9SwkergQVDWEWAACUiv2T+uiNgVfn6a//9BIdOMUZWrgHYRYAAJSavq1rav+kPnn6+8/eqpte+9aCilDeEWYBAECp+/rxG/P07Tuertk/7Pd4LSjfCLMAAKDU1ateSXtf6q1nb27m0j9+4VadPptlUVUojwizAADALex2m+65vp4WDP+TS3+b55crZvQiHTp11qLKUJ4QZgEAgFtdUycs3/7rJ38twzA9XA3KG8IsAABwux8fiVWH+tXy9Nd/erEF1aA8IcwCAACPmHNfu3yvdDDu819lmpyhRckQZgEAgEft+EdPl/Z/fvxd9cYs1n+3JlpUEbwZYRYAAHiUw9dH79wZm6f/gf+s1097T1hQEbwZYRYAAHhc9+ZRmjKgTZ7+Ae/8qNYT/suyAxQZYRYAAFii39W1tH9SH43v63ot2pRz2fpkw2GLqoK3IcwCAABLDe1YT3d1qOvS9/j8zayhRZEQZgEAgOWe/3MLzbmvvUvfA/9Zr4Hv/GhRRfAWhFkAAFAmdKhfTRHBDpe+NXtPKGb0Ir22fCfraJEvwiwAACgT7Hab1j4Tp//c2y7PY/9K2KV6YxZr+qo9FlSGsowwCwAAypROjcK1fmycqlf2z/PY5KXb9UbCLp3NyrGgMpRFhFkAAFDmVKvs0Lqx3fT96K55Hnt1+U41e3aZsnIMCypDWUOYBQAAZVatKoHaP6mPXr29dZ7HGo9dopjRi/TFpsPKyM61oDqUBYRZAABQ5t0WW1srH+uc72MPz92kpuOW6tF5mzxbFMoEwiwAAPAK9cMra/+kPmoaFZzv459tPKz0TNbSVjSEWQAA4FWWPnKD9k3srfeHtFWTSNdg23z8Mu1ITLOoMliBMAsAALyOzWbTTVdFatmjN2h45wYuj/WY8q3GfLrFosrgaYRZAADg1Z7s0SRP30drDyhm9CLFjF6khG1JFlQFTyHMAgAAr2a327RvYm9N/VubfB+/d/Y6bTxwyrNFwWMIswAAwOvZbDb9uU0trX6qi4L8ffI8/pe3ftBTC37R4dPnLKgO7uRrdQEAAAClpXZYkH57vqdM09T//XRA4z7/1fnYvHUHNW/dQWd71tBr1blxuGw2mxWlopQQZgEAQLljs9l055/qasH6Q9p88HS+Y+7+4Gfn9l0d6urmVjV1bUwY4dbLEGYBAEC59cXIjkpOy9SEL7dq0ZajMs38x/17ze/695rfJUkd6lfT2JuvUvOaoR6sFCVFmAUAAOVaeLBDbw66Rm/+r/3LodO65c3vCxy/Zu8J9fnXaknS5yM7qk10FfcXiRIjzAIAgAqlVe0q2j+pjyRpV1KaFm05qikrduU7tt+072W3SVP/drX6tq7pyTJRRIRZAABQYTWKDNYjkcF6JK6xsnMNLVh/KM8NFwxTeuijjXroo40K8LPr2Zuba1D7OhZVjD/i0lwAAACS/HzsGtiujvZP6qPPRlyX75iMbENPf7ZFMaMXafYP+z1bIPJFmAUAAPiDq+uEad/E3vrkwQ4Fjhm/cKviXvtGH609oNSMbA9Wh0uxzAAAACAfNptNsXWrOtfX7j+ertum/6AT6VnOMbuPndGYT7c4lyY0iqisLx+6XgF+eW/cAPcgzAIAABRBTPVKWj+um37YfVyD3vsp3zG7jp1R03FLJZ0Ptv/o10Lt61fzZJkVDmEWAACgGK5rWF07/9FLC9Yf0urdyVq8JTHfcbuOndGAd350tqNCAjSqa0MNaldHdjs3ZigthFkAAIBi8ve1a1D7Os6rGpimqQf/b4OWbs0/2EpSYmqGxn7+q8ZecovdFfGd1SC8EncduwKEWQAAgCtks9k0485YZ3v976f08NyNOnTqXKH7xb32jXP7vuvraVTXhgoN9CPcFgNhFgAAoJTF1g3T6qe6Sjp/1vanfSc19IOfdS47t8B93lu9T++t3idJCvL3USWHr66qEaLOjcN155/qyt+Xi1DlhzALAADgRjabTX+qX03bXujp7Jv29W69vGxHgfuczcrV2axcJacl69udyXrhq98kSaO6NFS3ZpFqEhUsh6+dM7gizAIAAHjcyC4NNbJLQ0lSyrlsvf3NHs356YBSzhV+vdo3v96tN7/e7WyHBvqpTtUgVXL4qE/LGurRIkoRwQFurb2sIcwCAABYKDTQT0/2bKonezZ19qWczdZvR1M145s9+mZncoH7ppzL1pbDKZKkH/ee1Lgvtjofq1e9kmqEBiiskr9qhwWqYXhl1Q+vrIbhlRUa5Oe+F+RhZSLMTps2TS+//LISExPVunVrvfHGG2rXrl2B4+fPn69x48Zp//79atSokSZPnqzevXt7sGIAAAD3CQ3yU4cG1dShwflr1CamZGjB+oNauf2Ycg1Tmw+lXPY59h1P177j6QU+3qF+NUWFBqhniyg1jQpWVGiAHL7ed7MHy8PsvHnzFB8frxkzZqh9+/aaMmWKevTooR07digiIiLP+B9++EEDBw7UxIkTdfPNN+vDDz9Uv379tGHDBrVo0cKCVwAAAOBeUaEBGtW1kUZ1beTSf+JMprYcTtFvR1P1z6UFr8HNz5q9JyRJn208nOex4ABfTbilueqHV5av3SZfu+RfyIfXrGQzTdO0soD27dvr2muv1ZtvvilJMgxD0dHReuihhzR69Og84wcMGKD09HR99dVXzr4//elPatOmjWbMmHHZ46Wmpio0NFQpKSkKCQkpvRdSAMMwdOzYMUVERMhu51OI3og59H7MofdjDr0b8+dZhmEqM8dQyrls7T+Rrv3H07XvRLpkSm9/u7fEz1vJ366Ph3VQ81pVSq/YAhQnr1l6ZjYrK0vr16/XmDFjnH12u11xcXFas2ZNvvusWbNG8fHxLn09evTQ559/nu/4zMxMZWZmOtupqamSzn9jGYZxha/g8gzDkGmaHjkW3IM59H7MofdjDr0b8+d5Dl+bIoL9FRHsr3YxYc7+p3o2UXauod3Hzujn/ae07Wiq1v1+StUrO/TTvpOFPmd6lqGEbcd0VQ3PnAwsKkvD7PHjx5Wbm6vIyEiX/sjISG3fvj3ffRITE/Mdn5iY/x03Jk6cqAkTJuTpT05OVkZGRgkrLzrDMJSSkiLTNPlt1Esxh96POfR+zKF3Y/7Knmo+Us8GgerZIFC6/kKuqidJWnsgVZ9sTlbNUH/lGKa+3XNaSWnnr7KQduaMjh075vb60tLSijzW8jWz7jZmzBiXM7mpqamKjo5WeHi4x5YZ2Gw2hYeH8w3spZhD78ccej/m0Lsxf97l5ogI3dy2obOdkZ2rE2cydfLECdWpGanQIH+31xAQUPTLi1kaZqtXry4fHx8lJSW59CclJSkqKirffaKiooo13uFwyOFw5Om32+0e+4ay2WwePR5KH3Po/ZhD78ccejfmz3sFOewK8PORX/YZhQb5e2QOi3MMS7+i/P39FRsbq4SEBGefYRhKSEhQhw4d8t2nQ4cOLuMlafny5QWOBwAAQPll+TKD+Ph4DRkyRG3btlW7du00ZcoUpaena+jQoZKku+66S7Vq1dLEiRMlSQ8//LA6d+6sV199VX369NHcuXO1bt06vfPOO1a+DAAAAFjA8jA7YMAAJScn69lnn1ViYqLatGmjpUuXOj/kdeDAAZdTzdddd50+/PBDjR07Vk8//bQaNWqkzz//nGvMAgAAVECWX2fW07jOLIqLOfR+zKH3Yw69G/Pn/Tw9h8XJa3xFAQAAwGsRZgEAAOC1CLMAAADwWoRZAAAAeC3CLAAAALwWYRYAAABeizALAAAAr0WYBQAAgNcizAIAAMBrEWYBAADgtQizAAAA8FqEWQAAAHgtwiwAAAC8lq/VBXiaaZqSpNTUVI8czzAMpaWlKSAgQHY7vzt4I+bQ+zGH3o859G7Mn/fz9BxeyGkXclthKlyYTUtLkyRFR0dbXAkAAAAKk5aWptDQ0ELH2MyiRN5yxDAMHTlyRMHBwbLZbG4/XmpqqqKjo3Xw4EGFhIS4/Xgofcyh92MOvR9z6N2YP+/n6Tk0TVNpaWmqWbPmZc8EV7gzs3a7XbVr1/b4cUNCQvgG9nLMofdjDr0fc+jdmD/v58k5vNwZ2QtYuAIAAACvRZgFAACA1yLMupnD4dD48ePlcDisLgUlxBx6P+bQ+zGH3o35835leQ4r3AfAAAAAUH5wZhYAAABeizALAAAAr0WYBQAAgNcizAIAAMBrEWZLwbRp0xQTE6OAgAC1b99ea9euLXT8/Pnz1bRpUwUEBKhly5ZavHixhypFQYozh++++646deqksLAwhYWFKS4u7rJzDvcr7vfhBXPnzpXNZlO/fv3cWyAuq7hzePr0aY0cOVI1atSQw+FQ48aN+e+phYo7f1OmTFGTJk0UGBio6OhoPfroo8rIyPBQtfijb7/9Vn379lXNmjVls9n0+eefX3afVatW6ZprrpHD4VDDhg01a9Yst9eZLxNXZO7cuaa/v785c+ZMc+vWreb9999vVqlSxUxKSsp3/Pfff2/6+PiY//znP83ffvvNHDt2rOnn52du2bLFw5XjguLO4aBBg8xp06aZGzduNLdt22befffdZmhoqHno0CEPV44LijuHF+zbt8+sVauW2alTJ/PPf/6zZ4pFvoo7h5mZmWbbtm3N3r17m6tXrzb37dtnrlq1yty0aZOHK4dpFn/+5syZYzocDnPOnDnmvn37zGXLlpk1atQwH330UQ9XjgsWL15sPvPMM+ann35qSjI/++yzQsfv3bvXDAoKMuPj483ffvvNfOONN0wfHx9z6dKlnin4EoTZK9SuXTtz5MiRznZubq5Zs2ZNc+LEifmO79+/v9mnTx+Xvvbt25vDhg1za50oWHHn8I9ycnLM4OBgc/bs2e4qEZdRkjnMyckxr7vuOvO9994zhwwZQpi1WHHncPr06Wb9+vXNrKwsT5WIQhR3/kaOHGl27drVpS8+Pt7s2LGjW+tE0RQlzD755JNm8+bNXfoGDBhg9ujRw42V5Y9lBlcgKytL69evV1xcnLPPbrcrLi5Oa9asyXefNWvWuIyXpB49ehQ4Hu5Vkjn8o7Nnzyo7O1tVq1Z1V5koREnn8Pnnn1dERITuvfdeT5SJQpRkDhcuXKgOHTpo5MiRioyMVIsWLfTSSy8pNzfXU2Xjf0oyf9ddd53Wr1/vXIqwd+9eLV68WL179/ZIzbhyZSnP+Hr8iOXI8ePHlZubq8jISJf+yMhIbd++Pd99EhMT8x2fmJjotjpRsJLM4R899dRTqlmzZp5vanhGSeZw9erVev/997Vp0yYPVIjLKckc7t27VytXrtTgwYO1ePFi7d69WyNGjFB2drbGjx/vibLxPyWZv0GDBun48eO6/vrrZZqmcnJyNHz4cD399NOeKBmloKA8k5qaqnPnzikwMNBjtXBmFrgCkyZN0ty5c/XZZ58pICDA6nJQBGlpabrzzjv17rvvqnr16laXgxIyDEMRERF65513FBsbqwEDBuiZZ57RjBkzrC4NRbBq1Sq99NJLeuutt7RhwwZ9+umnWrRokV544QWrS4MX4szsFahevbp8fHyUlJTk0p+UlKSoqKh894mKiirWeLhXSebwgldeeUWTJk3SihUr1KpVK3eWiUIUdw737Nmj/fv3q2/fvs4+wzAkSb6+vtqxY4caNGjg3qLhoiTfhzVq1JCfn598fHycfVdddZUSExOVlZUlf39/t9aMi0oyf+PGjdOdd96p++67T5LUsmVLpaen64EHHtAzzzwju51zbWVdQXkmJCTEo2dlJc7MXhF/f3/FxsYqISHB2WcYhhISEtShQ4d89+nQoYPLeElavnx5gePhXiWZQ0n65z//qRdeeEFLly5V27ZtPVEqClDcOWzatKm2bNmiTZs2Of/dcsst6tKlizZt2qTo6GhPlg+V7PuwY8eO2r17t/MXEUnauXOnatSoQZD1sJLM39mzZ/ME1gu/mJim6b5iUWrKVJ7x+EfOypm5c+eaDofDnDVrlvnbb7+ZDzzwgFmlShUzMTHRNE3TvPPOO83Ro0c7x3///femr6+v+corr5jbtm0zx48fz6W5LFbcOZw0aZLp7+9vLliwwDx69KjzX1pamlUvocIr7hz+EVczsF5x5/DAgQNmcHCwOWrUKHPHjh3mV199ZUZERJj/+Mc/rHoJFVpx52/8+PFmcHCw+dFHH5l79+41//vf/5oNGjQw+/fvb9VLqPDS0tLMjRs3mhs3bjQlma+99pq5ceNG8/fffzdN0zRHjx5t3nnnnc7xFy7N9cQTT5jbtm0zp02bxqW5vNkbb7xh1qlTx/T39zfbtWtn/vjjj87HOnfubA4ZMsRl/Mcff2w2btzY9Pf3N5s3b24uWrTIwxXjj4ozh3Xr1jUl5fk3fvx4zxcOp+J+H16KMFs2FHcOf/jhB7N9+/amw+Ew69evb7744otmTk6Oh6vGBcWZv+zsbPO5554zGzRoYAYEBJjR0dHmiBEjzFOnTnm+cJimaZpff/11vj/bLszbkCFDzM6dO+fZp02bNqa/v79Zv35984MPPvB43aZpmjbT5Hw+AAAAvBNrZgEAAOC1CLMAAADwWoRZAAAAeC3CLAAAALwWYRYAAABeizALAAAAr0WYBQAAgNcizAIAAMBrEWYBoAKz2Wz6/PPPJUn79++XzWbTpk2bLK0JAIqDMAsAFrn77rtls9lks9nk5+enevXq6cknn1RGRobVpQGA1/C1ugAAqMh69uypDz74QNnZ2Vq/fr2GDBkim82myZMnW10aAHgFzswCgIUcDoeioqIUHR2tfv36KS4uTsuXL5ckGYahiRMnql69egoMDFTr1q21YMECl/23bt2qm2++WSEhIQoODlanTp20Z88eSdLPP/+sbt26qXr16goNDVXnzp21YcMGj79GAHAnwiwAlBG//vqrfvjhB/n7+0uSJk6cqH//+9+aMWOGtm7dqkcffVR33HGHvvnmG0nS4cOHdcMNN8jhcGjlypVav3697rnnHuXk5EiS0tLSNGTIEK1evVo//vijGjVqpN69eystLc2y1wgApY1lBgBgoa+++kqVK1dWTk6OMjMzZbfb9eabbyozM1MvvfSSVqxYoQ4dOkiS6tevr9WrV+vtt99W586dNW3aNIWGhmru3Lny8/OTJDVu3Nj53F27dnU51jvvvKMqVarom2++0c033+y5FwkAbkSYBQALdenSRdOnT1d6erpef/11+fr66rbbbtPWrVt19uxZdevWzWV8VlaWrr76aknSpk2b1KlTJ2eQ/aOkpCSNHTtWq1at0rFjx5Sbm6uzZ8/qwIEDbn9dAOAphFkAsFClSpXUsGFDSdLMmTPVunVrvf/++2rRooUkadGiRapVq5bLPg6HQ5IUGBhY6HMPGTJEJ06c0NSpU1W3bl05HA516NBBWVlZbnglAGANwiwAlBF2u11PP/204uPjtXPnTjkcDh04cECdO3fOd3yrVq00e/ZsZWdn53t29vvvv9dbb72l3r17S5IOHjyo48ePu/U1AICn8QEwAChDbr/9dvn4+Ojtt9/W448/rkcffVSzZ8/Wnj17tGHDBr3xxhuaPXu2JGnUqFFKTU3V3/72N61bt067du3Sf/7zH+3YsUOS1KhRI/3nP//Rtm3b9NNPP2nw4MGXPZsLAN6GM7MAUIb4+vpq1KhR+uc//6l9+/YpPDxcEydO1N69e1WlShVdc801evrppyVJ1apV08qVK/XEE0+oc+fO8vHxUZs2bdSxY0dJ0vvvv68HHnhA11xzjaKjo/XSSy/p8ccft/LlAUCps5mmaVpdBAAAAFASLDMAAACA1yLMAgAAwGsRZgEAAOC1CLMAAADwWoRZAAAAeC3CLAAAALwWYRYAAABeizALAAAAr0WYBQAAgNcizAIAAMBrEWYBAADgtf4fOkl9450rs/UAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC Score: 0.7174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate PR curve data\n",
    "precision, recall, thresholds = precision_recall_curve(test_labels, test_probs)\n",
    "pr_auc = average_precision_score(test_labels, test_probs)\n",
    "\n",
    "# Plot PR curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, linewidth=2, label=f'PR AUC = {pr_auc:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"PR AUC Score: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5373b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae20c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-backup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
