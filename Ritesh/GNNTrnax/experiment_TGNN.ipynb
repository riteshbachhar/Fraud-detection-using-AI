{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf4fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, GRU\n",
    "from torch_geometric.data import TemporalData\n",
    "from torch_geometric.loader import TemporalDataLoader\n",
    "from torch_geometric.nn import TGNMemory, TransformerConv\n",
    "from torch_geometric.nn.models.tgn import IdentityMessage, LastAggregator\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f924ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent.parent))  # Adjust as needed\n",
    "from config import DATAPATH, SAMPLE_DATAPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f6a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGNTimeEncoding(torch.nn.Module):\n",
    "    \"\"\"Time encoding module for TGN\"\"\"\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.lin = Linear(1, out_channels)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # t has shape [num_events] and values are timestamps\n",
    "        return self.lin(t.view(-1, 1))\n",
    "    \n",
    "class GraphAttentionEmbedding(torch.nn.Module):\n",
    "    \"\"\"Graph attention embedding module for TGN\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, msg_dim, time_enc):\n",
    "        super().__init__()\n",
    "        self.time_enc = time_enc\n",
    "        edge_dim = msg_dim + time_enc.out_channels\n",
    "        self.conv = TransformerConv(\n",
    "            in_channels, out_channels // 2, \n",
    "            heads=2, dropout=0.1, edge_dim=edge_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, x, last_update, edge_index, t, msg):\n",
    "        # Calculate relative time - ensure proper indexing\n",
    "        src_nodes = edge_index[0]\n",
    "        rel_t = last_update[src_nodes] - t\n",
    "        \n",
    "        # Ensure rel_t is on the same device and dtype as x\n",
    "        rel_t = rel_t.to(x.device).to(x.dtype)\n",
    "        rel_t_enc = self.time_enc(rel_t)\n",
    "        \n",
    "        # Concatenate edge attributes\n",
    "        edge_attr = torch.cat([rel_t_enc, msg], dim=-1)\n",
    "        \n",
    "        return self.conv(x, edge_index, edge_attr)\n",
    "\n",
    "\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    \"\"\"Link prediction module for binary classification\"\"\"\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.lin_src = Linear(in_channels, in_channels)\n",
    "        self.lin_dst = Linear(in_channels, in_channels)\n",
    "        self.lin_final = Linear(in_channels, 1)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, z_src, z_dst):\n",
    "        h = self.lin_src(z_src) + self.lin_dst(z_dst)\n",
    "        h = F.relu(h)\n",
    "        h = self.dropout(h)\n",
    "        return torch.sigmoid(self.lin_final(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "937611d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGNAMLModel(torch.nn.Module):\n",
    "    \"\"\"Complete TGN model for AML detection\"\"\"\n",
    "\n",
    "    def __init__(self, num_nodes, edge_dim, memory_dim=100, time_dim=100, \n",
    "                 embedding_dim=100, num_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.memory_dim = memory_dim\n",
    "        self.time_dim = time_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Time encoding\n",
    "        self.time_enc = TGNTimeEncoding(time_dim)\n",
    "\n",
    "        # Memory module\n",
    "        self.memory = TGNMemory(\n",
    "            num_nodes=num_nodes,\n",
    "            raw_msg_dim=edge_dim,\n",
    "            memory_dim=memory_dim,\n",
    "            time_dim=time_dim,\n",
    "            message_module=IdentityMessage(edge_dim, memory_dim, time_dim),\n",
    "            aggregator_module=LastAggregator(),\n",
    "        )\n",
    "\n",
    "        # Graph neural network\n",
    "        self.gnn = GraphAttentionEmbedding(\n",
    "            in_channels=memory_dim,\n",
    "            out_channels=embedding_dim,\n",
    "            msg_dim=edge_dim,\n",
    "            time_enc=self.time_enc\n",
    "        )\n",
    "\n",
    "        # Link predictor for classification\n",
    "        self.link_pred = LinkPredictor(embedding_dim)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Get unique nodes in the batch\n",
    "        unique_nodes = torch.cat([batch.src, batch.dst]).unique()\n",
    "        \n",
    "        # Get memory for all unique nodes\n",
    "        z_all, last_update = self.memory(unique_nodes)\n",
    "        \n",
    "        # Create mapping from node IDs to indices in z_all\n",
    "        node_to_idx = {node.item(): idx for idx, node in enumerate(unique_nodes)}\n",
    "        \n",
    "        # Map batch nodes to indices\n",
    "        src_indices = torch.tensor([node_to_idx[node.item()] for node in batch.src], \n",
    "                                dtype=torch.long, device=batch.src.device)\n",
    "        dst_indices = torch.tensor([node_to_idx[node.item()] for node in batch.dst], \n",
    "                                dtype=torch.long, device=batch.dst.device)\n",
    "        \n",
    "        # Create edge index for GNN (using mapped indices)\n",
    "        edge_index = torch.stack([src_indices, dst_indices], dim=0)\n",
    "        \n",
    "        # Apply GNN\n",
    "        node_embeddings = self.gnn(z_all, last_update, edge_index, batch.t.float(), batch.msg)\n",
    "        \n",
    "        # Get embeddings for source and destination nodes\n",
    "        z_src = node_embeddings[src_indices]\n",
    "        z_dst = node_embeddings[dst_indices]\n",
    "\n",
    "        # Predict\n",
    "        return self.link_pred(z_src, z_dst)\n",
    "    \n",
    "    def update_memory(self, batch):\n",
    "        \"\"\"Update memory after each batch\"\"\"\n",
    "        with torch.no_grad():\n",
    "            self.memory.update_state(batch.src, batch.dst, batch.t, batch.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9f1a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGNTrainer:\n",
    "    \"\"\"Trainer class for TGN AML detection\"\"\"\n",
    "\n",
    "    def __init__(self, model, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "        # self.criterion = torch.nn.BCELoss()\n",
    "        fraud_weight = 1000  # Heavy penalty for missing fraud\n",
    "        pos_weight = torch.tensor([fraud_weight]).to(device)\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    def train_epoch(self, data_loader):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        self.model.memory.train()\n",
    "        self.model.memory.reset_state()  # Reset at start of epoch\n",
    "\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        # Add progress bar\n",
    "        pbar = tqdm(data_loader, desc=\"Training\")\n",
    "\n",
    "        for batch in pbar:\n",
    "            batch = batch.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            out = self.model(batch)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = self.criterion(out.squeeze(), batch.y)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # CRITICAL: Update memory with detached tensors to break computation graph\n",
    "            self.model.update_memory(batch)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        return total_loss / num_batches\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, data_loader):\n",
    "        \"\"\"Evaluate model\"\"\"\n",
    "        self.model.eval()\n",
    "        self.model.memory.eval()\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        # Add progress bar\n",
    "        pbar = tqdm(data_loader, desc=\"Evaluation\")\n",
    "\n",
    "        for batch in pbar:\n",
    "            batch = batch.to(self.device)\n",
    "\n",
    "            out = self.model(batch)\n",
    "\n",
    "            all_preds.append(out.cpu().numpy())\n",
    "            all_labels.append(batch.y.cpu().numpy())\n",
    "\n",
    "        y_pred = np.concatenate(all_preds)\n",
    "        y_true = np.concatenate(all_labels)\n",
    "\n",
    "        # Calculate metrics\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        ap = average_precision_score(y_true, y_pred)\n",
    "\n",
    "        # Binary predictions for F1, precision, recall\n",
    "        y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred_binary)\n",
    "        precision = precision_score(y_true, y_pred_binary, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred_binary)\n",
    "\n",
    "        return {\n",
    "            'auc': auc,\n",
    "            'ap': ap,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'predictions': y_pred,\n",
    "            'labels': y_true\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51636f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAMLDataProcessor:\n",
    "    \"\"\"Data processor for SAML-D dataset\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def load_and_preprocess(self, df, first_n=None):\n",
    "        \"\"\"Load and preprocess SAML-D dataset\"\"\"\n",
    "        print(\"Loading SAML-D dataset...\")\n",
    "        if first_n is not None:\n",
    "            df = df.head(first_n)\n",
    "\n",
    "        # Basic info about dataset\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "        print(f\"Laundering transactions: {df['Is_laundering'].sum()}\")\n",
    "        print(f\"Percentage of laundering: {df['Is_laundering'].mean()*100:.3f}%\")\n",
    "        \n",
    "        # Feature engineering\n",
    "        df = self._engineer_features(df)\n",
    "\n",
    "        # Clear unnecessary columns\n",
    "        df = self._clean_columns(df)\n",
    "\n",
    "        # Create temporal graph data\n",
    "        temporal_data = self._create_temporal_data(df)\n",
    "        \n",
    "        return temporal_data, df\n",
    "    \n",
    "    def _engineer_features(self, df):\n",
    "        \"\"\"Engineer features from raw data\"\"\"\n",
    "        print(\"Engineering features...\")\n",
    "        \n",
    "        # Combine date and time into datetime\n",
    "        df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "        df['timestamp'] = df['DateTime'].astype('int64') // 10**9  # Convert to unix timestamp\n",
    "\n",
    "        # Drop columns = ['Date', 'Time', 'Laundering_type]\n",
    "        df = df.drop(columns=['Date', 'Time', 'Laundering_type'])\n",
    "        \n",
    "        # Extract temporal features\n",
    "        df['hour'] = df['DateTime'].dt.hour.astype('int8')\n",
    "        df['day_of_week'] = df['DateTime'].dt.dayofweek.astype('int8')\n",
    "        df['weekend'] = (df['day_of_week'] >= 5).astype('int8')\n",
    "        \n",
    "        # Amount features\n",
    "        df['log_amount'] = np.log1p(df['Amount']).astype('float32')\n",
    "        \n",
    "        # Cross-border indicator\n",
    "        df['is_cross_border'] = (df['Payment_type'] == 'Cross-border').astype('int8')\n",
    "        \n",
    "        # Currency mismatch\n",
    "        df['currency_mismatch'] = (df['Payment_currency'] != df['Received_currency']).astype('int8')\n",
    "\n",
    "        # Is laundering datatype\n",
    "        df['Is_laundering'] = df['Is_laundering'].astype('int8')\n",
    "\n",
    "        # Encode categorical features\n",
    "        categorical_features = [\n",
    "            'Payment_type', 'Sender_bank_location', 'Receiver_bank_location',\n",
    "            'Payment_currency', 'Received_currency'\n",
    "        ]\n",
    "        \n",
    "        for feature in categorical_features:\n",
    "            if feature not in self.label_encoders:\n",
    "                self.label_encoders[feature] = LabelEncoder()\n",
    "                encoded_values = self.label_encoders[feature].fit_transform(df[feature].astype(str))\n",
    "            else:\n",
    "                encoded_values = self.label_encoders[feature].transform(df[feature].astype(str))\n",
    "            df[f'{feature}_encoded'] = encoded_values\n",
    "\n",
    "        # Check if values fit in int8 range (0-127 for positive values)\n",
    "            max_encoded = encoded_values.max()\n",
    "            if max_encoded <= 127:\n",
    "                df[f'{feature}_encoded'] = encoded_values.astype('int8')\n",
    "            elif max_encoded <= 32767:\n",
    "                df[f'{feature}_encoded'] = encoded_values.astype('int16')\n",
    "                print(f\"Warning: {feature} has {max_encoded} unique values, using int16\")\n",
    "            else:\n",
    "                df[f'{feature}_encoded'] = encoded_values.astype('int32')\n",
    "                print(f\"Warning: {feature} has {max_encoded} unique values, using int32\")\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def _clean_columns(self, df):\n",
    "        \"\"\"Remove unnecessary features\"\"\"\n",
    "        print(\"Cleaning unnecessary columns...\")\n",
    "        unwanted_cols = ['Payment_type', 'Sender_bank_location', 'Receiver_bank_location',\n",
    "                         'Payment_currency', 'Received_currency', 'Amount']\n",
    "        df = df.drop(columns=unwanted_cols)\n",
    "        return df\n",
    "    \n",
    "    def _create_temporal_data(self, df):\n",
    "        \"\"\"Create temporal graph data structure\"\"\"\n",
    "        print(\"Creating temporal graph structure...\")\n",
    "        \n",
    "        # Create node mapping\n",
    "        senders = df['Sender_account'].unique()\n",
    "        receivers = df['Receiver_account'].unique()\n",
    "        all_nodes = np.unique(np.concatenate([senders, receivers]))\n",
    "        \n",
    "        node_to_idx = {node: idx for idx, node in enumerate(all_nodes)}\n",
    "        num_nodes = len(all_nodes)\n",
    "        \n",
    "        print(f\"Number of unique accounts (nodes): {num_nodes}\")\n",
    "        \n",
    "        # Map accounts to indices\n",
    "        src_nodes = df['Sender_account'].map(node_to_idx).values\n",
    "        dst_nodes = df['Receiver_account'].map(node_to_idx).values\n",
    "\n",
    "        # Edge features (transaction features)\n",
    "        edge_features = [\n",
    "            'log_amount', 'Payment_type_encoded', 'hour', 'day_of_week',\n",
    "            'weekend', 'is_cross_border', 'currency_mismatch'\n",
    "        ]\n",
    "        \n",
    "        edge_attr = df[edge_features].values.astype(np.float32)\n",
    "        \n",
    "        # Normalize edge features\n",
    "        edge_attr = self.scaler.fit_transform(edge_attr)\n",
    "        \n",
    "        # Sort by timestamp\n",
    "        sort_idx = np.argsort(df['timestamp'].values)\n",
    "        \n",
    "        temporal_data = TemporalData(\n",
    "            src=torch.tensor(src_nodes[sort_idx], dtype=torch.long),\n",
    "            dst=torch.tensor(dst_nodes[sort_idx], dtype=torch.long),\n",
    "            t=torch.tensor(df['timestamp'].values[sort_idx], dtype=torch.long),\n",
    "            msg=torch.tensor(edge_attr[sort_idx], dtype=torch.float),\n",
    "            y=torch.tensor(df['Is_laundering'].values[sort_idx], dtype=torch.float)\n",
    "        )\n",
    "        \n",
    "        # Add number of nodes\n",
    "        temporal_data.num_nodes = num_nodes\n",
    "        \n",
    "        return temporal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08ce9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset\n",
    "df = pd.read_csv(DATAPATH)\n",
    "\n",
    "# Filter by data range\n",
    "df = df[df['Date'] < '2023-03-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70676078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAML-D dataset...\n",
      "Dataset shape: (5198135, 12)\n",
      "Laundering transactions: 5193\n",
      "Percentage of laundering: 0.100%\n",
      "Engineering features...\n",
      "Cleaning unnecessary columns...\n",
      "Creating temporal graph structure...\n",
      "Number of unique accounts (nodes): 642216\n"
     ]
    }
   ],
   "source": [
    "# Pre-process data\n",
    "data_processor = SAMLDataProcessor()\n",
    "\n",
    "temporal_data, df = data_processor.load_and_preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34665f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batches: 16245\n",
      "Test batches: 4062\n"
     ]
    }
   ],
   "source": [
    "# Split data temporally (80% train, 20% test)\n",
    "split_idx = int(0.8 * len(temporal_data.t))\n",
    "\n",
    "train_data = TemporalData(\n",
    "    src=temporal_data.src[:split_idx],\n",
    "    dst=temporal_data.dst[:split_idx],\n",
    "    t=temporal_data.t[:split_idx],\n",
    "    msg=temporal_data.msg[:split_idx],\n",
    "    y=temporal_data.y[:split_idx]\n",
    ")\n",
    "\n",
    "test_data = TemporalData(\n",
    "    src=temporal_data.src[split_idx:],\n",
    "    dst=temporal_data.dst[split_idx:],\n",
    "    t=temporal_data.t[split_idx:],\n",
    "    msg=temporal_data.msg[split_idx:],\n",
    "    y=temporal_data.y[split_idx:]\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = TemporalDataLoader(train_data, batch_size=256, num_workers=4)\n",
    "test_loader = TemporalDataLoader(test_data, batch_size=256, num_workers=4)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac8e2432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e44404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def clear_cuda_memory():\n",
    "    \"\"\"Clear CUDA memory completely\"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    gc.collect()\n",
    "    print(f\"CUDA memory allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    print(f\"CUDA memory cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b039f772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA memory allocated: 657.43 MB\n",
      "CUDA memory cached: 674.00 MB\n",
      "Model parameters: 20897\n"
     ]
    }
   ],
   "source": [
    "clear_cuda_memory()\n",
    "\n",
    "# Initialize model\n",
    "model = TGNAMLModel(\n",
    "    num_nodes=temporal_data.num_nodes,\n",
    "    edge_dim=temporal_data.msg.size(1),\n",
    "    memory_dim=32,\n",
    "    time_dim=32,\n",
    "    embedding_dim=32\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a73a6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16245/16245 [13:22<00:00, 20.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1: Loss: 1.3867\n",
      "Saving model checkpoint at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 4062/4062 [01:02<00:00, 65.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1: Loss: 1.3867, AUC: 0.5000, Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 1607/16245 [01:19<12:04, 20.20it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStarting training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     train_loss = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     train_losses.append(train_loss)\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Print training progress without evaluation\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mTGNTrainer.train_epoch\u001b[39m\u001b[34m(self, data_loader)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Add progress bar\u001b[39;00m\n\u001b[32m     23\u001b[39m pbar = tqdm(data_loader, desc=\u001b[33m\"\u001b[39m\u001b[33mTraining\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1448\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1445\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data)\n\u001b[32m   1447\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1449\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1451\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1412\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1408\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1409\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1411\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1412\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1413\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1414\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1243\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1230\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1231\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1232\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1240\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1241\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1242\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1244\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1245\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1246\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1247\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1248\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/multiprocessing/queues.py:122\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    120\u001b[39m         \u001b[38;5;28mself\u001b[39m._rlock.release()\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler.loads(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:541\u001b[39m, in \u001b[36mrebuild_storage_fd\u001b[39m\u001b[34m(cls, df, size)\u001b[39m\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrebuild_storage_fd\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, size):\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m     fd = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    542\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    543\u001b[39m         storage = storage_from_cache(\u001b[38;5;28mcls\u001b[39m, fd_id(fd))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/multiprocessing/resource_sharer.py:57\u001b[39m, in \u001b[36mDupFd.detach\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetach\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     56\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_resource_sharer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m     58\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction.recv_handle(conn)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/multiprocessing/resource_sharer.py:86\u001b[39m, in \u001b[36m_ResourceSharer.get_connection\u001b[39m\u001b[34m(ident)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[32m     85\u001b[39m address, key = ident\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m c = \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m c.send((key, os.getpid()))\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/multiprocessing/connection.py:525\u001b[39m, in \u001b[36mClient\u001b[39m\u001b[34m(address, family, authkey)\u001b[39m\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mauthkey should be a byte string\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m authkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     \u001b[43manswer_challenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m     deliver_challenge(c, authkey)\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/multiprocessing/connection.py:774\u001b[39m, in \u001b[36manswer_challenge\u001b[39m\u001b[34m(connection, authkey)\u001b[39m\n\u001b[32m    772\u001b[39m digest = hmac.new(authkey, message, \u001b[33m'\u001b[39m\u001b[33mmd5\u001b[39m\u001b[33m'\u001b[39m).digest()\n\u001b[32m    773\u001b[39m connection.send_bytes(digest)\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m)\u001b[49m        \u001b[38;5;66;03m# reject large message\u001b[39;00m\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response != WELCOME:\n\u001b[32m    776\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationError(\u001b[33m'\u001b[39m\u001b[33mdigest sent was rejected\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/multiprocessing/connection.py:216\u001b[39m, in \u001b[36m_ConnectionBase.recv_bytes\u001b[39m\u001b[34m(self, maxlength)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength < \u001b[32m0\u001b[39m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mnegative maxlength\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mself\u001b[39m._bad_message_length()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/multiprocessing/connection.py:430\u001b[39m, in \u001b[36mConnection._recv_bytes\u001b[39m\u001b[34m(self, maxsize)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m     size, = struct.unpack(\u001b[33m\"\u001b[39m\u001b[33m!i\u001b[39m\u001b[33m\"\u001b[39m, buf.getvalue())\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m size == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/riteshbachhar_uri_edu/.conda/envs/fastai-backup/lib/python3.11/multiprocessing/connection.py:395\u001b[39m, in \u001b[36mConnection._recv\u001b[39m\u001b[34m(self, size, read)\u001b[39m\n\u001b[32m    393\u001b[39m remaining = size\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     chunk = read(handle, remaining)\n\u001b[32m    396\u001b[39m     n = \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Initialize trainer\n",
    "trainer = TGNTrainer(model, device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "best_auc = 0\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss = trainer.train_epoch(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Print training progress without evaluation\n",
    "    print(f\"Epoch {epoch+1:2d}: Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Only evaluate every 10 epochs to save memory\n",
    "    # if (epoch + 1) % 5 == 0:\n",
    "    print(f\"Saving model checkpoint at epoch {epoch+1}\")\n",
    "    torch.save(model.state_dict(), f'tgn_aml_model_epoch_{epoch+1}.pth')\n",
    "    \n",
    "    # Evaluate every 5 epochs\n",
    "    # if (epoch + 1) % 5 == 0:\n",
    "    test_metrics = trainer.evaluate(test_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:2d}: \"\n",
    "            f\"Loss: {train_loss:.4f}, \"\n",
    "            f\"AUC: {test_metrics['auc']:.4f}, \"\n",
    "            f\"Precision: {test_metrics['precision']:.4f}, \"\n",
    "            f\"Recall: {test_metrics['recall']:.4f}, \"\n",
    "            f\"F1: {test_metrics['f1']:.4f}\")\n",
    "    \n",
    "    if test_metrics['auc'] > best_auc:\n",
    "        best_auc = test_metrics['auc']\n",
    "        torch.save(model.state_dict(), 'best_tgn_aml_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e4e0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e312299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac63d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ff32cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating tgn_aml_model_epoch_10.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 7426/7426 [01:48<00:00, 68.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5000\n",
      "Recall: 0.0000\n",
      "Precision: 0.0000\n"
     ]
    }
   ],
   "source": [
    "def evaluate_saved_model(checkpoint_path, test_loader, num_nodes, edge_dim, device):\n",
    "    \"\"\"Load and evaluate a saved model checkpoint\"\"\"\n",
    "    \n",
    "    # 1. Create model with same architecture as training\n",
    "    model = TGNAMLModel(\n",
    "        num_nodes=num_nodes,\n",
    "        edge_dim=edge_dim,\n",
    "        memory_dim=32,    # Match your training config\n",
    "        time_dim=32,\n",
    "        embedding_dim=32\n",
    "    )\n",
    "    \n",
    "    # 2. Load saved weights\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 3. Create trainer with loaded model\n",
    "    trainer = TGNTrainer(model, device)\n",
    "    \n",
    "    # 4. Standard evaluation\n",
    "    print(f\"Evaluating {checkpoint_path}...\")\n",
    "    metrics = trainer.evaluate(test_loader)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Usage example:\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Evaluate specific checkpoint\n",
    "results = evaluate_saved_model(\n",
    "    checkpoint_path='tgn_aml_model_epoch_10.pth',\n",
    "    test_loader=test_loader,\n",
    "    num_nodes=temporal_data.num_nodes,\n",
    "    edge_dim=temporal_data.msg.size(1),\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"AUC: {results['auc']:.4f}\")\n",
    "print(f\"Recall: {results['recall']:.4f}\")\n",
    "print(f\"Precision: {results['precision']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd9b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fcc9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data_processor = SAMLDataProcessor()\n",
    "\n",
    "temporal_data, df = data_processor.load_and_preprocess(filepath)\n",
    "\n",
    "\n",
    "# Split data temporally (80% train, 20% test)\n",
    "split_idx = int(0.8 * len(temporal_data.t))\n",
    "\n",
    "train_data = TemporalData(\n",
    "    src=temporal_data.src[:split_idx],\n",
    "    dst=temporal_data.dst[:split_idx],\n",
    "    t=temporal_data.t[:split_idx],\n",
    "    msg=temporal_data.msg[:split_idx],\n",
    "    y=temporal_data.y[:split_idx]\n",
    ")\n",
    "\n",
    "test_data = TemporalData(\n",
    "    src=temporal_data.src[split_idx:],\n",
    "    dst=temporal_data.dst[split_idx:],\n",
    "    t=temporal_data.t[split_idx:],\n",
    "    msg=temporal_data.msg[split_idx:],\n",
    "    y=temporal_data.y[split_idx:]\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = TemporalDataLoader(train_data, batch_size=200)\n",
    "test_loader = TemporalDataLoader(test_data, batch_size=200)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Initialize model\n",
    "model = TGNAMLModel(\n",
    "    num_nodes=temporal_data.num_nodes,\n",
    "    edge_dim=temporal_data.msg.size(1),\n",
    "    memory_dim=100,\n",
    "    time_dim=100,\n",
    "    embedding_dim=100\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = TGNTrainer(model, device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "best_auc = 0\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss = trainer.train_epoch(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluate every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        test_metrics = trainer.evaluate(test_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d}: \"\n",
    "                f\"Loss: {train_loss:.4f}, \"\n",
    "                f\"AUC: {test_metrics['auc']:.4f}, \"\n",
    "                f\"AP: {test_metrics['ap']:.4f}, \"\n",
    "                f\"F1: {test_metrics['f1']:.4f}, \"\n",
    "                f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "        \n",
    "        if test_metrics['auc'] > best_auc:\n",
    "            best_auc = test_metrics['auc']\n",
    "            torch.save(model.state_dict(), 'best_tgn_aml_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76311e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "print(\"\\nFinal evaluation...\")\n",
    "final_metrics = trainer.evaluate(test_loader)\n",
    "\n",
    "print(f\"\\nFinal Test Results:\")\n",
    "print(f\"AUC-ROC: {final_metrics['auc']:.4f}\")\n",
    "print(f\"Average Precision: {final_metrics['ap']:.4f}\")\n",
    "print(f\"F1 Score: {final_metrics['f1']:.4f}\")\n",
    "print(f\"Precision: {final_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {final_metrics['recall']:.4f}\")\n",
    "\n",
    "# Plotting results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Training loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# ROC Curve\n",
    "from sklearn.metrics import roc_curve\n",
    "plt.subplot(1, 3, 2)\n",
    "fpr, tpr, _ = roc_curve(final_metrics['labels'], final_metrics['predictions'])\n",
    "plt.plot(fpr, tpr, label=f'AUC = {final_metrics[\"auc\"]:.3f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "plt.subplot(1, 3, 3)\n",
    "precision, recall, _ = precision_recall_curve(final_metrics['labels'], final_metrics['predictions'])\n",
    "plt.plot(recall, precision, label=f'AP = {final_metrics[\"ap\"]:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tgn_aml_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-backup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
