{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83228cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Improved Temporal Graph Neural Network for Anti-Money Laundering Detection\n",
    "==========================================================================\n",
    "Optimized for F2 Score with structured code organization\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (precision_recall_curve, roc_auc_score, f1_score, \n",
    "                           precision_score, recall_score, fbeta_score, \n",
    "                           confusion_matrix, average_precision_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74ecce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent.parent))  # Adjust as needed\n",
    "from config import DATAPATH, SAMPLE_DATAPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ddba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f457192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration class for hyperparameters and settings\"\"\"\n",
    "    # Model architecture\n",
    "    HIDDEN_DIM = 256  # Increased from 128\n",
    "    NODE_DIM = 15\n",
    "    EDGE_DIM = 9\n",
    "    DROPOUT_RATE = 0.3\n",
    "    \n",
    "    # Training parameters\n",
    "    LEARNING_RATE = 0.0005  \n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    EPOCHS = 50\n",
    "    PATIENCE = 10\n",
    "    \n",
    "    # F2 score optimization\n",
    "    BETA = 2  # For F2 score (emphasizes recall)\n",
    "    CLASS_WEIGHT_MULTIPLIER = 10  # Strong emphasis on minority class\n",
    "\n",
    "    # Criterion parameters\n",
    "    FOCAL_LOSS_ALPHA = 0.25\n",
    "    FOCAL_LOSS_GAMMA = 2.0\n",
    "    \n",
    "    # Data processing\n",
    "    TIME_WINDOW = '7D'\n",
    "    VALIDATION_SPLIT = 0.17\n",
    "    TEST_SPLIT = 0.13\n",
    "    \n",
    "    # Threshold optimization\n",
    "    THRESHOLD_SEARCH_RANGE = np.arange(0.05, 0.95, 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc23495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "\n",
    "def detailed_memory_profile():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "        \n",
    "        # Show memory summary\n",
    "        # print(torch.cuda.memory_summary())\n",
    "        return allocated, cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0671bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for addressing class imbalance - better than BCE for F2 optimization\"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08365f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGraphDataProcessor:\n",
    "    \"\"\"Enhanced data processor with better feature engineering for F2 optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, time_window='7D'):\n",
    "        self.time_window = time_window\n",
    "        self.scalers = {}\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_and_preprocess(self, df):\n",
    "        \"\"\"Load SAML-D dataset and perform initial preprocessing\"\"\"\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        \n",
    "        # Combine date and time into datetime\n",
    "        df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "        df = df.sort_values('datetime').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Loaded {len(df)} transactions\")\n",
    "        print(f\"Suspicious transactions: {df['Is_laundering'].sum()} ({df['Is_laundering'].mean()*100:.3f}%)\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def engineer_features(self, df):\n",
    "        \"\"\"Enhanced feature engineering for better detection\"\"\"\n",
    "        print(\"Engineering enhanced features...\")\n",
    "        \n",
    "        # Time-based features (more granular)\n",
    "        df['hour'] = df['datetime'].dt.hour.astype('int8')\n",
    "        df['month'] = df['datetime'].dt.month.astype('int8')\n",
    "        df['day_of_week'] = df['datetime'].dt.dayofweek.astype('int8')\n",
    "        df['day_of_month'] = df['datetime'].dt.day.astype('int8')\n",
    "        df['is_weekend'] = (df['day_of_week'] >= 5).astype('int8')\n",
    "        df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 5)).astype('int8')  # Night transactions\n",
    "        \n",
    "        # Amount-based features\n",
    "        df['log_amount'] = np.log1p(df['Amount']).astype('float32')\n",
    "        \n",
    "        # Calculate amount percentiles for anomaly detection\n",
    "        # amount_percentiles = df['Amount'].quantile([0.95, 0.99]).values\n",
    "        # df['high_amount'] = (df['Amount'] > amount_percentiles[0]).astype('int8')\n",
    "        # df['very_high_amount'] = (df['Amount'] > amount_percentiles[1]).astype('int8')\n",
    "        \n",
    "        # Geographic risk features\n",
    "        df['cross_border'] = (df['Payment_type'] == 'Cross-border').astype('int8')\n",
    "        risky_countries = {'Mexico', 'Turkey', 'Morocco', 'UAE'}\n",
    "        df['high_risk_sender'] = df['Sender_bank_location'].isin(risky_countries).astype('int8')\n",
    "        df['high_risk_receiver'] = df['Receiver_bank_location'].isin(risky_countries).astype('int8')\n",
    "        # df['both_high_risk'] = (df['high_risk_sender'] & df['high_risk_receiver']).astype('int8')\n",
    "        \n",
    "        # Currency features\n",
    "        df['currency_mismatch'] = (df['Payment_currency'] != df['Received_currency']).astype('int8')\n",
    "        \n",
    "        # Convert target\n",
    "        df['Is_laundering'] = df['Is_laundering'].astype('int8')\n",
    "        \n",
    "        # Clean up\n",
    "        columns_to_drop = ['Date', 'Time', 'Amount', 'Sender_bank_location', \n",
    "                          'Receiver_bank_location', 'Payment_currency', 'Received_currency', \n",
    "                          'Laundering_type']\n",
    "        df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_temporal_snapshots(self, df, account_features):\n",
    "        \"\"\"Create temporal graph snapshots with enhanced features\"\"\"\n",
    "        print(\"Creating temporal graph snapshots...\")\n",
    "        \n",
    "        # Global account mapping\n",
    "        all_accounts = list(set(df['Sender_account'].unique()) | set(df['Receiver_account'].unique()))\n",
    "        global_account_to_idx = {acc: idx for idx, acc in enumerate(all_accounts)}\n",
    "        global_num_nodes = len(all_accounts)\n",
    "        \n",
    "        # Time windows\n",
    "        start_date = df['datetime'].min().normalize().date()\n",
    "        end_date = df['datetime'].max().normalize().date()\n",
    "        \n",
    "        snapshots = []\n",
    "        print(f\"Processing time range: {start_date} to {end_date}\")\n",
    "\n",
    "        for window_start in pd.date_range(start=start_date, end=end_date, freq=self.time_window, inclusive='left'):\n",
    "            window_end = window_start + pd.Timedelta(days=7)\n",
    "            window_start_str = pd.to_datetime(window_start).strftime('%Y-%m-%d')\n",
    "            window_end_str = pd.to_datetime(window_end).strftime('%Y-%m-%d')\n",
    "            print(f\"Processing window: {window_start_str} to {window_end_str}\")\n",
    "            \n",
    "            # Get transactions in current window\n",
    "            window_mask = (df['datetime'] >= window_start_str) & (df['datetime'] < window_end_str)\n",
    "            window_trnx_data = df[window_mask].copy()\n",
    "            \n",
    "            # Account features for this window\n",
    "            window_accounts_features = account_features[account_features['window_start'] == window_start_str]\n",
    "            \n",
    "            if len(window_trnx_data) > 0:\n",
    "                graph_data = self._create_graph_snapshot(\n",
    "                    window_trnx_data, window_accounts_features,\n",
    "                    window_start_str, global_account_to_idx, global_num_nodes\n",
    "                )\n",
    "                if graph_data is not None:\n",
    "                    snapshots.append(graph_data)\n",
    "\n",
    "        print(f\"Created {len(snapshots)} temporal snapshots\")\n",
    "        return snapshots, global_num_nodes\n",
    "\n",
    "    def _create_graph_snapshot(self, window_trnx_data, window_accounts_features, \n",
    "                              timestamp, global_account_to_idx, global_num_nodes):\n",
    "        \"\"\"Create enhanced graph snapshot\"\"\"\n",
    "        if len(window_trnx_data) == 0:\n",
    "            return None\n",
    "\n",
    "        # Enhanced edge features\n",
    "        edge_feature_columns = [\n",
    "            'Payment_type_encoded', 'log_amount', 'month', 'day_of_week', 'hour', \n",
    "            'currency_mismatch', 'cross_border', 'high_risk_sender', 'high_risk_receiver',\n",
    "        ]\n",
    "        \n",
    "        # Filter available columns\n",
    "        edge_feature_columns = [col for col in edge_feature_columns if col in window_trnx_data.columns]\n",
    "\n",
    "        # Node features\n",
    "        node_feature_columns = ['sent_txns_count', 'fan_out', 'recv_txns_count', 'fan_in', \n",
    "                               'max_sent_txn_count', 'max_recv_txn_count', 'sent_recv_ratio', \n",
    "                               'fanout_fanin_ratio', 'log_med_sent_amt', 'log_std_sent_amt', \n",
    "                               'log_med_recv_amt', 'log_std_recv_amt', 'log_max_sent_txn_amt', \n",
    "                               'log_max_recv_txn_amt', 'log_total_txns_amt']\n",
    "\n",
    "        # Create mappings and features\n",
    "        sender_mapped = window_trnx_data['Sender_account'].map(global_account_to_idx)\n",
    "        receiver_mapped = window_trnx_data['Receiver_account'].map(global_account_to_idx)\n",
    "        edge_index = np.column_stack((sender_mapped, receiver_mapped))\n",
    "        edge_features = window_trnx_data[edge_feature_columns].values\n",
    "        transaction_labels = window_trnx_data['Is_laundering'].values\n",
    "\n",
    "        # Node features\n",
    "        node_features = np.zeros((global_num_nodes, len(node_feature_columns)))\n",
    "        try:\n",
    "            window_accounts_features['global_idx'] = window_accounts_features['account'].map(global_account_to_idx)\n",
    "            node_features[window_accounts_features['global_idx'].values] = window_accounts_features[node_feature_columns].values\n",
    "        except: \n",
    "            raise ValueError(\"Error in mapping account features to global indices.\")\n",
    "\n",
    "        # Convert to tensors\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "        edge_features = torch.tensor(edge_features, dtype=torch.float)\n",
    "        transaction_labels = torch.tensor(transaction_labels, dtype=torch.float)\n",
    "\n",
    "        return Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_features,\n",
    "            y=transaction_labels,\n",
    "            timestamp=timestamp,\n",
    "            num_nodes=global_num_nodes\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e55e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal GNN Model for Edge Classification\n",
    "class TemporalEdgeClassifier(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, dropout_rate):\n",
    "        super(TemporalEdgeClassifier, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.GRUCell(node_dim, hidden_dim)\n",
    "        self.gnn1 = SAGEConv(hidden_dim, hidden_dim, aggr='mean')\n",
    "        self.gnn2 = SAGEConv(hidden_dim, hidden_dim, aggr='mean')\n",
    "        self.gnn3 = SAGEConv(hidden_dim, hidden_dim, aggr='mean')\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.classifier = nn.Linear(hidden_dim * 2 + edge_dim, 1)  # Binary classification\n",
    "\n",
    "    def forward(self, data, h):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        \n",
    "        # Update node hidden states with RNN (using current x)\n",
    "        h = self.rnn(x, h)\n",
    "        \n",
    "        # Apply GNN layers\n",
    "        h = F.relu(self.gnn1(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.gnn2(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.gnn3(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        # Edge features: concat sender h, receiver h, edge_attr\n",
    "        h_i = h[edge_index[0]]\n",
    "        h_j = h[edge_index[1]]\n",
    "        edge_input = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
    "        \n",
    "        # Prediction\n",
    "        out = self.classifier(edge_input)\n",
    "        \n",
    "        return out, h  # Return logits and updated h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"Enhanced trainer class optimized for F2 score\"\"\"\n",
    "    \n",
    "    def __init__(self, config=Config(), mem_profile=False):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        self.mem_profile = mem_profile\n",
    "\n",
    "    def find_optimal_threshold(self, probs, labels):\n",
    "        \"\"\"Find optimal threshold for F2 score\"\"\"\n",
    "        best_f2 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in self.config.THRESHOLD_SEARCH_RANGE:\n",
    "            preds = (probs >= threshold).astype(int)\n",
    "            f2 = fbeta_score(labels, preds, beta=self.config.BETA, average='binary', zero_division=0)\n",
    "            if f2 > best_f2:\n",
    "                best_f2 = f2\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        return best_threshold, best_f2\n",
    "    \n",
    "    def compute_class_weights(self, snapshots):\n",
    "        \"\"\"Compute class weights for focal loss\"\"\"\n",
    "        all_labels = []\n",
    "        for snap in snapshots:\n",
    "            all_labels.extend(snap.y.cpu().numpy())\n",
    "        \n",
    "        all_labels = np.array(all_labels)\n",
    "        pos_weight = len(all_labels) / (2 * np.sum(all_labels))\n",
    "        return torch.tensor(pos_weight, dtype=torch.float).to(self.device)\n",
    "    \n",
    "    def train_model(self, snapshots, global_num_nodes):\n",
    "        \"\"\"Enhanced training with F2 optimization\"\"\"\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(len(snapshots) * (1 - self.config.VALIDATION_SPLIT - self.config.TEST_SPLIT))\n",
    "        val_size = int(len(snapshots) * self.config.VALIDATION_SPLIT)\n",
    "        \n",
    "        train_snaps = snapshots[:train_size]\n",
    "        val_snaps = snapshots[train_size:train_size + val_size]\n",
    "        test_snaps = snapshots[train_size + val_size:]\n",
    "        \n",
    "        print(f\"Data split - Train: {len(train_snaps)}, Val: {len(val_snaps)}, Test: {len(test_snaps)}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = TemporalEdgeClassifier(\n",
    "            self.config.NODE_DIM, \n",
    "            self.config.EDGE_DIM, \n",
    "            self.config.HIDDEN_DIM,\n",
    "            self.config.DROPOUT_RATE\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Compute class weights for focal loss\n",
    "        pos_weight = self.compute_class_weights(train_snaps)\n",
    "        criterion = FocalLoss(alpha=self.config.FOCAL_LOSS_ALPHA, gamma=self.config.FOCAL_LOSS_GAMMA)\n",
    "        \n",
    "        # Optimizer with different learning rates for different components\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': model.rnn.parameters(), 'lr': self.config.LEARNING_RATE * 0.5},\n",
    "            {'params': model.gnn1.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.gnn2.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.gnn3.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.classifier.parameters(), 'lr': self.config.LEARNING_RATE * 1.5}\n",
    "        ], weight_decay=self.config.WEIGHT_DECAY)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
    "        )\n",
    "        \n",
    "        # Training loop\n",
    "        best_f2_score = 0\n",
    "        patience_counter = 0\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "        f2_history = []\n",
    "        \n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "\n",
    "            if self.mem_profile:\n",
    "                print(f\"=== EPOCH {epoch} START ===\")\n",
    "                epoch_start_mem = detailed_memory_profile()\n",
    "\n",
    "            for i, snap in enumerate(train_snaps):\n",
    "                if (i < 5) and self.mem_profile:\n",
    "                    print(f\"--- Snapshot {i} ---\")\n",
    "                    pre_snap = detailed_memory_profile()\n",
    "                \n",
    "                snap = snap.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                out, h = model(snap, h.detach())  # Detach to prevent gradient explosion\n",
    "                loss = criterion(out.squeeze(), snap.y)\n",
    "\n",
    "                if (i < 5) and self.mem_profile:\n",
    "                    post_forward = detailed_memory_profile()\n",
    "                    print(f\"Forward pass added: {post_forward[1] - pre_snap[1]:.3f}GB cached\")\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "                optimizer.step()\n",
    "\n",
    "                if (i < 5) and self.mem_profile:\n",
    "                    post_backward = detailed_memory_profile()\n",
    "                    print(f\"Backward pass added: {post_backward[1] - post_forward[1]:.3f}GB cached\")\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_snaps)\n",
    "            train_loss_history.append(avg_train_loss)\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_probs_list, val_labels_list = [], []\n",
    "            val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "                for snap in val_snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, h = model(snap, h)\n",
    "                    loss = criterion(out.squeeze(), snap.y)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    preds = torch.sigmoid(out).squeeze()\n",
    "                    val_probs_list.append(preds.cpu())\n",
    "                    val_labels_list.append(snap.y.cpu())\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_snaps)\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "            \n",
    "            # Scale\n",
    "            avg_train_loss *= 1000\n",
    "            avg_val_loss *= 1000\n",
    "            \n",
    "            # Calculate F2 score with optimal threshold\n",
    "            val_probs = torch.cat(val_probs_list).numpy()\n",
    "            val_labels = torch.cat(val_labels_list).numpy()\n",
    "            \n",
    "            optimal_threshold, f2_score = self.find_optimal_threshold(val_probs, val_labels)\n",
    "            f2_history.append(f2_score)\n",
    "            recall = recall_score(val_labels, (val_probs >= optimal_threshold).astype(int), zero_division=0)\n",
    "            \n",
    "            # Update scheduler with F2 score\n",
    "            scheduler.step(f2_score)\n",
    "            \n",
    "            # Early stopping based on F2 score\n",
    "            if f2_score > best_f2_score:\n",
    "                best_f2_score = f2_score\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                # torch.save(model.state_dict(), './outputs/best_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}: Train Loss(x1e3): {avg_train_loss:.4f}, Val Loss(x1e3): {avg_val_loss:.4f}, \"\n",
    "                        f\"F2: {f2_score:.4f}, Threshold: {optimal_threshold:.3f}, Recall: {recall:.4f}\")\n",
    "            \n",
    "            if patience_counter >= self.config.PATIENCE:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # Load best model and evaluate\n",
    "        # model.load_state_dict(torch.load('./outputs/best_model.pth'))\n",
    "        \n",
    "        # Final evaluation\n",
    "        results = self._evaluate_model(model, train_snaps, val_snaps, test_snaps, global_num_nodes)\n",
    "        results.update({\n",
    "            'train_loss_history': train_loss_history,\n",
    "            'val_loss_history': val_loss_history,\n",
    "            'f2_history': f2_history,\n",
    "            'model': model\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_model(self, model, train_snaps, val_snaps, test_snaps, global_num_nodes):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        model.eval()\n",
    "        results = {}\n",
    "        \n",
    "        for split_name, snaps in [('val', val_snaps), ('test', test_snaps)]:\n",
    "            probs_list, labels_list = [], []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "                for snap in snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, h = model(snap, h)\n",
    "                    preds = torch.sigmoid(out).squeeze().cpu().numpy()\n",
    "                    probs_list.extend(preds)\n",
    "                    labels_list.extend(snap.y.cpu().numpy())\n",
    "            \n",
    "            probs = np.array(probs_list)\n",
    "            labels = np.array(labels_list)\n",
    "            \n",
    "            # Find optimal threshold\n",
    "            optimal_threshold, best_f2 = self.find_optimal_threshold(probs, labels)\n",
    "            binary_preds = (probs >= optimal_threshold).astype(int)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            precision = precision_score(labels, binary_preds, zero_division=0)\n",
    "            recall = recall_score(labels, binary_preds, zero_division=0)\n",
    "            f1 = f1_score(labels, binary_preds, zero_division=0)\n",
    "            roc_auc = roc_auc_score(labels, probs)\n",
    "            pr_auc = average_precision_score(labels, probs)\n",
    "            \n",
    "            results[f'{split_name}_probs'] = probs\n",
    "            results[f'{split_name}_labels'] = labels\n",
    "            results[f'{split_name}_threshold'] = optimal_threshold\n",
    "            results[f'{split_name}_precision'] = precision\n",
    "            results[f'{split_name}_recall'] = recall\n",
    "            results[f'{split_name}_f1'] = f1\n",
    "            results[f'{split_name}_f2'] = best_f2\n",
    "            results[f'{split_name}_roc_auc'] = roc_auc\n",
    "            results[f'{split_name}_pr_auc'] = pr_auc\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2124555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset\n",
    "df = pd.read_csv(DATAPATH)\n",
    "\n",
    "# Filter by data range\n",
    "# df = df[df['Date'] < '2023-08-18']\n",
    "# df = df.head(300000).copy()\n",
    "\n",
    "# run feature engg.ipynb to get the account_stats_7D.csv\n",
    "account_stats = pd.read_csv('../account_stats_7D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9178de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Loaded 9504852 transactions\n",
      "Suspicious transactions: 9873 (0.104%)\n",
      "Engineering enhanced features...\n"
     ]
    }
   ],
   "source": [
    "graph_processor = TemporalGraphDataProcessor()\n",
    "df = graph_processor.load_and_preprocess(df)\n",
    "df = graph_processor.engineer_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8bfb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For each categorical column\n",
    "# categorical_cols = ['Payment_currency', 'Received_currency', 'Sender_bank_location', \n",
    "#                    'Receiver_bank_location', 'Payment_type']\n",
    "categorical_cols = ['Payment_type']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "# Drop original object columns\n",
    "df = df.drop(categorical_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43c740f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process accont_stats\n",
    "columns = ['med_sent_amt', 'std_sent_amt', 'med_recv_amt', 'std_recv_amt', \n",
    "           'max_sent_txn_amt', 'max_recv_txn_amt', 'total_txns_amt']\n",
    "\n",
    "for col in columns:\n",
    "    account_stats['log_' + col] = np.log1p(account_stats[col]).astype('float32')\n",
    "\n",
    "account_stats = account_stats.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "094d1677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data types to optimize memory\n",
    "account_stats = account_stats.astype({\n",
    "    'sent_txns_count': 'int32',\n",
    "    'recv_txns_count': 'int32',\n",
    "    'fan_out': 'int32',\n",
    "    'fan_in': 'int32',\n",
    "    'max_sent_txn_count': 'int32',\n",
    "    'max_recv_txn_count': 'int32',\n",
    "    'sent_recv_ratio': 'float32',\n",
    "    'fanout_fanin_ratio': 'float32'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79bf8e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporal graph snapshots...\n",
      "Processing time range: 2022-10-07 to 2023-08-23\n",
      "Processing window: 2022-10-07 to 2022-10-14\n",
      "Processing window: 2022-10-14 to 2022-10-21\n",
      "Processing window: 2022-10-21 to 2022-10-28\n",
      "Processing window: 2022-10-28 to 2022-11-04\n",
      "Processing window: 2022-11-04 to 2022-11-11\n",
      "Processing window: 2022-11-11 to 2022-11-18\n",
      "Processing window: 2022-11-18 to 2022-11-25\n",
      "Processing window: 2022-11-25 to 2022-12-02\n",
      "Processing window: 2022-12-02 to 2022-12-09\n",
      "Processing window: 2022-12-09 to 2022-12-16\n",
      "Processing window: 2022-12-16 to 2022-12-23\n",
      "Processing window: 2022-12-23 to 2022-12-30\n",
      "Processing window: 2022-12-30 to 2023-01-06\n",
      "Processing window: 2023-01-06 to 2023-01-13\n",
      "Processing window: 2023-01-13 to 2023-01-20\n",
      "Processing window: 2023-01-20 to 2023-01-27\n",
      "Processing window: 2023-01-27 to 2023-02-03\n",
      "Processing window: 2023-02-03 to 2023-02-10\n",
      "Processing window: 2023-02-10 to 2023-02-17\n",
      "Processing window: 2023-02-17 to 2023-02-24\n",
      "Processing window: 2023-02-24 to 2023-03-03\n",
      "Processing window: 2023-03-03 to 2023-03-10\n",
      "Processing window: 2023-03-10 to 2023-03-17\n",
      "Processing window: 2023-03-17 to 2023-03-24\n",
      "Processing window: 2023-03-24 to 2023-03-31\n",
      "Processing window: 2023-03-31 to 2023-04-07\n",
      "Processing window: 2023-04-07 to 2023-04-14\n",
      "Processing window: 2023-04-14 to 2023-04-21\n",
      "Processing window: 2023-04-21 to 2023-04-28\n",
      "Processing window: 2023-04-28 to 2023-05-05\n",
      "Processing window: 2023-05-05 to 2023-05-12\n",
      "Processing window: 2023-05-12 to 2023-05-19\n",
      "Processing window: 2023-05-19 to 2023-05-26\n",
      "Processing window: 2023-05-26 to 2023-06-02\n",
      "Processing window: 2023-06-02 to 2023-06-09\n",
      "Processing window: 2023-06-09 to 2023-06-16\n",
      "Processing window: 2023-06-16 to 2023-06-23\n",
      "Processing window: 2023-06-23 to 2023-06-30\n",
      "Processing window: 2023-06-30 to 2023-07-07\n",
      "Processing window: 2023-07-07 to 2023-07-14\n",
      "Processing window: 2023-07-14 to 2023-07-21\n",
      "Processing window: 2023-07-21 to 2023-07-28\n",
      "Processing window: 2023-07-28 to 2023-08-04\n",
      "Processing window: 2023-08-04 to 2023-08-11\n",
      "Processing window: 2023-08-11 to 2023-08-18\n",
      "Processing window: 2023-08-18 to 2023-08-25\n",
      "Created 46 temporal snapshots\n"
     ]
    }
   ],
   "source": [
    "snapshots, global_num_nodes = graph_processor.create_temporal_snapshots(df, account_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a083f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory - Allocated: 0.00GB, Cached: 0.00GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89fc6783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Data split - Train: 32, Val: 7, Test: 7\n",
      "Epoch 1: Train Loss(x1e3): 5.6792, Val Loss(x1e3): 1.1193, F2: 0.0071, Threshold: 0.050, Recall: 0.0384\n",
      "Epoch 2: Train Loss(x1e3): 0.7580, Val Loss(x1e3): 0.6571, F2: 0.0119, Threshold: 0.100, Recall: 0.4822\n",
      "Epoch 3: Train Loss(x1e3): 0.6503, Val Loss(x1e3): 0.6205, F2: 0.0162, Threshold: 0.100, Recall: 0.5096\n",
      "Epoch 4: Train Loss(x1e3): 0.6245, Val Loss(x1e3): 0.6015, F2: 0.0196, Threshold: 0.100, Recall: 0.6063\n",
      "Epoch 5: Train Loss(x1e3): 0.6019, Val Loss(x1e3): 0.5785, F2: 0.0241, Threshold: 0.150, Recall: 0.1948\n",
      "Epoch 6: Train Loss(x1e3): 0.5698, Val Loss(x1e3): 0.5418, F2: 0.0425, Threshold: 0.150, Recall: 0.3210\n",
      "Epoch 7: Train Loss(x1e3): 0.5362, Val Loss(x1e3): 0.5022, F2: 0.0779, Threshold: 0.200, Recall: 0.0919\n",
      "Epoch 8: Train Loss(x1e3): 0.4976, Val Loss(x1e3): 0.4597, F2: 0.1536, Threshold: 0.200, Recall: 0.2414\n",
      "Epoch 9: Train Loss(x1e3): 0.4594, Val Loss(x1e3): 0.4148, F2: 0.2303, Threshold: 0.200, Recall: 0.4088\n",
      "Epoch 10: Train Loss(x1e3): 0.4218, Val Loss(x1e3): 0.3650, F2: 0.3470, Threshold: 0.250, Recall: 0.3731\n",
      "Epoch 11: Train Loss(x1e3): 0.3820, Val Loss(x1e3): 0.3179, F2: 0.4506, Threshold: 0.250, Recall: 0.5199\n",
      "Epoch 12: Train Loss(x1e3): 0.3543, Val Loss(x1e3): 0.2944, F2: 0.4947, Threshold: 0.250, Recall: 0.5967\n",
      "Epoch 13: Train Loss(x1e3): 0.3291, Val Loss(x1e3): 0.2944, F2: 0.5288, Threshold: 0.300, Recall: 0.5494\n",
      "Epoch 14: Train Loss(x1e3): 0.3399, Val Loss(x1e3): 0.2642, F2: 0.5682, Threshold: 0.250, Recall: 0.6262\n",
      "Epoch 15: Train Loss(x1e3): 0.3019, Val Loss(x1e3): 0.2485, F2: 0.6007, Threshold: 0.250, Recall: 0.6591\n",
      "Epoch 16: Train Loss(x1e3): 0.2860, Val Loss(x1e3): 0.2410, F2: 0.6218, Threshold: 0.300, Recall: 0.6509\n",
      "Epoch 17: Train Loss(x1e3): 0.2931, Val Loss(x1e3): 0.2157, F2: 0.6396, Threshold: 0.300, Recall: 0.6461\n",
      "Epoch 18: Train Loss(x1e3): 0.2453, Val Loss(x1e3): 0.2082, F2: 0.6597, Threshold: 0.300, Recall: 0.6886\n",
      "Epoch 19: Train Loss(x1e3): 0.2569, Val Loss(x1e3): 0.1962, F2: 0.6668, Threshold: 0.300, Recall: 0.6694\n",
      "Epoch 20: Train Loss(x1e3): 0.2153, Val Loss(x1e3): 0.2012, F2: 0.6718, Threshold: 0.350, Recall: 0.6920\n",
      "Epoch 21: Train Loss(x1e3): 0.2710, Val Loss(x1e3): 0.1874, F2: 0.6788, Threshold: 0.300, Recall: 0.7167\n",
      "Epoch 22: Train Loss(x1e3): 0.1961, Val Loss(x1e3): 0.1908, F2: 0.7036, Threshold: 0.350, Recall: 0.7373\n",
      "Epoch 23: Train Loss(x1e3): 0.2437, Val Loss(x1e3): 0.1875, F2: 0.6861, Threshold: 0.350, Recall: 0.7126\n",
      "Epoch 24: Train Loss(x1e3): 0.1980, Val Loss(x1e3): 0.2322, F2: 0.6976, Threshold: 0.400, Recall: 0.7318\n",
      "Epoch 25: Train Loss(x1e3): 0.2592, Val Loss(x1e3): 0.1843, F2: 0.6857, Threshold: 0.350, Recall: 0.7003\n",
      "Epoch 26: Train Loss(x1e3): 0.1799, Val Loss(x1e3): 0.1663, F2: 0.7134, Threshold: 0.350, Recall: 0.7270\n",
      "Epoch 27: Train Loss(x1e3): 0.2028, Val Loss(x1e3): 0.1708, F2: 0.7048, Threshold: 0.400, Recall: 0.7099\n",
      "Epoch 28: Train Loss(x1e3): 0.1750, Val Loss(x1e3): 0.1904, F2: 0.7105, Threshold: 0.400, Recall: 0.7250\n",
      "Epoch 29: Train Loss(x1e3): 0.2432, Val Loss(x1e3): 0.1694, F2: 0.7103, Threshold: 0.350, Recall: 0.7209\n",
      "Epoch 30: Train Loss(x1e3): 0.1661, Val Loss(x1e3): 0.1553, F2: 0.7375, Threshold: 0.400, Recall: 0.7291\n",
      "Epoch 31: Train Loss(x1e3): 0.1796, Val Loss(x1e3): 0.1559, F2: 0.7334, Threshold: 0.400, Recall: 0.7318\n",
      "Epoch 32: Train Loss(x1e3): 0.1731, Val Loss(x1e3): 0.1453, F2: 0.7472, Threshold: 0.350, Recall: 0.7620\n",
      "Epoch 33: Train Loss(x1e3): 0.1654, Val Loss(x1e3): 0.1470, F2: 0.7465, Threshold: 0.400, Recall: 0.7483\n",
      "Epoch 34: Train Loss(x1e3): 0.1651, Val Loss(x1e3): 0.1416, F2: 0.7475, Threshold: 0.400, Recall: 0.7414\n",
      "Epoch 35: Train Loss(x1e3): 0.1569, Val Loss(x1e3): 0.1425, F2: 0.7534, Threshold: 0.350, Recall: 0.7798\n",
      "Epoch 36: Train Loss(x1e3): 0.1712, Val Loss(x1e3): 0.1401, F2: 0.7554, Threshold: 0.400, Recall: 0.7524\n",
      "Epoch 37: Train Loss(x1e3): 0.1446, Val Loss(x1e3): 0.1439, F2: 0.7634, Threshold: 0.400, Recall: 0.7675\n",
      "Epoch 38: Train Loss(x1e3): 0.1667, Val Loss(x1e3): 0.1383, F2: 0.7594, Threshold: 0.350, Recall: 0.7654\n",
      "Epoch 39: Train Loss(x1e3): 0.1438, Val Loss(x1e3): 0.1395, F2: 0.7611, Threshold: 0.400, Recall: 0.7586\n",
      "Epoch 40: Train Loss(x1e3): 0.1637, Val Loss(x1e3): 0.1373, F2: 0.7664, Threshold: 0.350, Recall: 0.7853\n",
      "Epoch 41: Train Loss(x1e3): 0.1361, Val Loss(x1e3): 0.1400, F2: 0.7684, Threshold: 0.400, Recall: 0.7785\n",
      "Epoch 42: Train Loss(x1e3): 0.1722, Val Loss(x1e3): 0.1339, F2: 0.7701, Threshold: 0.350, Recall: 0.7689\n",
      "Epoch 43: Train Loss(x1e3): 0.1335, Val Loss(x1e3): 0.1432, F2: 0.7769, Threshold: 0.400, Recall: 0.7874\n",
      "Epoch 44: Train Loss(x1e3): 0.1695, Val Loss(x1e3): 0.1376, F2: 0.7692, Threshold: 0.350, Recall: 0.7805\n",
      "Epoch 45: Train Loss(x1e3): 0.1328, Val Loss(x1e3): 0.1357, F2: 0.7723, Threshold: 0.400, Recall: 0.7716\n",
      "Epoch 46: Train Loss(x1e3): 0.1667, Val Loss(x1e3): 0.1353, F2: 0.7856, Threshold: 0.350, Recall: 0.7963\n",
      "Epoch 47: Train Loss(x1e3): 0.1286, Val Loss(x1e3): 0.1332, F2: 0.7752, Threshold: 0.350, Recall: 0.7977\n",
      "Epoch 48: Train Loss(x1e3): 0.1567, Val Loss(x1e3): 0.1344, F2: 0.7857, Threshold: 0.350, Recall: 0.7901\n",
      "Epoch 49: Train Loss(x1e3): 0.1248, Val Loss(x1e3): 0.1313, F2: 0.7875, Threshold: 0.350, Recall: 0.8052\n",
      "Epoch 50: Train Loss(x1e3): 0.1468, Val Loss(x1e3): 0.1277, F2: 0.7932, Threshold: 0.350, Recall: 0.8045\n"
     ]
    }
   ],
   "source": [
    "trainer = ModelTrainer(config=Config(), mem_profile=False)\n",
    "results = trainer.train_model(snapshots, global_num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb0d7038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_probs': array([0.04681701, 0.03109491, 0.01014125, ..., 0.01056083, 0.00474101,\n",
       "        0.00888106], shape=(1458820,), dtype=float32),\n",
       " 'val_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1458820,), dtype=float32),\n",
       " 'val_threshold': np.float64(0.35000000000000003),\n",
       " 'val_precision': 0.7509603072983355,\n",
       " 'val_recall': 0.8045267489711934,\n",
       " 'val_f1': 0.7768211920529802,\n",
       " 'val_f2': 0.7932107113876116,\n",
       " 'val_roc_auc': 0.994370371686238,\n",
       " 'val_pr_auc': 0.8255945313318027,\n",
       " 'test_probs': array([0.00041653, 0.01103526, 0.00231781, ..., 0.01122224, 0.19453473,\n",
       "        0.04254321], shape=(1384809,), dtype=float32),\n",
       " 'test_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1384809,), dtype=float32),\n",
       " 'test_threshold': np.float64(0.35000000000000003),\n",
       " 'test_precision': 0.7698179682912507,\n",
       " 'test_recall': 0.7989031078610603,\n",
       " 'test_f1': 0.7840909090909091,\n",
       " 'test_f2': 0.7929115761461232,\n",
       " 'test_roc_auc': 0.994174045659204,\n",
       " 'test_pr_auc': 0.8357184284124562,\n",
       " 'train_loss_history': [0.005679233297996689,\n",
       "  0.0007579987322969828,\n",
       "  0.0006503059794340516,\n",
       "  0.0006244922897167271,\n",
       "  0.0006019128531988827,\n",
       "  0.0005698351478713448,\n",
       "  0.0005362099436752032,\n",
       "  0.0004975713709427509,\n",
       "  0.00045942447741254,\n",
       "  0.0004217714740661904,\n",
       "  0.0003820091424131533,\n",
       "  0.0003542807862686459,\n",
       "  0.0003290631229901919,\n",
       "  0.0003398870949240518,\n",
       "  0.00030189894505383563,\n",
       "  0.00028598799917745055,\n",
       "  0.0002930889772869705,\n",
       "  0.00024532760562578915,\n",
       "  0.000256944371813006,\n",
       "  0.0002152799247596704,\n",
       "  0.0002709897794375138,\n",
       "  0.00019606783735071076,\n",
       "  0.00024373723135795444,\n",
       "  0.00019804901103270822,\n",
       "  0.0002591988213680452,\n",
       "  0.00017987712317335536,\n",
       "  0.00020279668592593225,\n",
       "  0.00017498385500402946,\n",
       "  0.00024323626485056593,\n",
       "  0.0001660552975408791,\n",
       "  0.00017957099680643296,\n",
       "  0.00017312501950073056,\n",
       "  0.0001654060622513498,\n",
       "  0.00016511856119905133,\n",
       "  0.00015693023510721105,\n",
       "  0.0001711669833639462,\n",
       "  0.00014461916794061835,\n",
       "  0.00016670718628120085,\n",
       "  0.00014380831703419972,\n",
       "  0.00016367529246963386,\n",
       "  0.00013607853793473623,\n",
       "  0.00017220206382262404,\n",
       "  0.00013347069284463942,\n",
       "  0.00016954177226580214,\n",
       "  0.00013278847632136603,\n",
       "  0.0001666562181981135,\n",
       "  0.0001285599307720986,\n",
       "  0.00015665579530832474,\n",
       "  0.00012477750965445011,\n",
       "  0.0001467665402969942],\n",
       " 'val_loss_history': [0.0011193023445749922,\n",
       "  0.0006571156679586108,\n",
       "  0.0006204823605782751,\n",
       "  0.0006014609908951181,\n",
       "  0.0005785284489060619,\n",
       "  0.0005417776327314121,\n",
       "  0.000502192515081593,\n",
       "  0.00045967124918076607,\n",
       "  0.00041475589802887825,\n",
       "  0.00036495023440303545,\n",
       "  0.0003179274665723954,\n",
       "  0.0002944177540484816,\n",
       "  0.00029436581410534145,\n",
       "  0.00026419441980708925,\n",
       "  0.00024847280915959606,\n",
       "  0.00024100545436210399,\n",
       "  0.00021569500885172083,\n",
       "  0.0002081583910954318,\n",
       "  0.00019622941077354232,\n",
       "  0.00020121637291075395,\n",
       "  0.00018743416876532137,\n",
       "  0.00019077750766882673,\n",
       "  0.00018751450781045214,\n",
       "  0.00023224995987090682,\n",
       "  0.0001843147848766031,\n",
       "  0.00016631598867076849,\n",
       "  0.00017083142301999032,\n",
       "  0.00019037290621781722,\n",
       "  0.00016936332602719112,\n",
       "  0.00015529165622345836,\n",
       "  0.0001559355140281176,\n",
       "  0.00014530162401829978,\n",
       "  0.00014702041205185066,\n",
       "  0.0001415896206578639,\n",
       "  0.00014249989596594657,\n",
       "  0.00014012876220346828,\n",
       "  0.0001438681096520408,\n",
       "  0.00013830922190598876,\n",
       "  0.00013945366143681376,\n",
       "  0.00013731467749624114,\n",
       "  0.00014001212444522286,\n",
       "  0.00013386381656995842,\n",
       "  0.00014321874706573517,\n",
       "  0.0001375810315948911,\n",
       "  0.0001356893584930471,\n",
       "  0.0001353071233357436,\n",
       "  0.00013323977847384022,\n",
       "  0.00013439773465506732,\n",
       "  0.0001312631762370334,\n",
       "  0.00012767859880113974],\n",
       " 'f2_history': [0.007093276587120637,\n",
       "  0.011865379422090197,\n",
       "  0.016174748235580964,\n",
       "  0.01956167681631497,\n",
       "  0.02411234314241565,\n",
       "  0.04250758415230068,\n",
       "  0.07789791884664574,\n",
       "  0.15364469663902225,\n",
       "  0.23032926263719278,\n",
       "  0.3470273028833886,\n",
       "  0.4506004042325526,\n",
       "  0.4947117024906175,\n",
       "  0.5287826775811988,\n",
       "  0.5682101070450585,\n",
       "  0.6007000875109388,\n",
       "  0.6218057921635435,\n",
       "  0.6395980445410103,\n",
       "  0.6597450387698778,\n",
       "  0.6668488658103306,\n",
       "  0.6717709720372836,\n",
       "  0.6788359100948421,\n",
       "  0.7036261290744862,\n",
       "  0.68608029582673,\n",
       "  0.6975679916317992,\n",
       "  0.6856950973807925,\n",
       "  0.713420379593485,\n",
       "  0.7048488150367748,\n",
       "  0.7105404678677064,\n",
       "  0.7103271154366045,\n",
       "  0.7374774524767587,\n",
       "  0.7334341490239208,\n",
       "  0.7472423997847727,\n",
       "  0.7465444094703709,\n",
       "  0.747476144378371,\n",
       "  0.7533792737874371,\n",
       "  0.75540559151632,\n",
       "  0.7634056487924683,\n",
       "  0.7593903102885139,\n",
       "  0.7610789980732178,\n",
       "  0.7663989290495314,\n",
       "  0.7684495599187542,\n",
       "  0.7701291563616378,\n",
       "  0.7769355711965349,\n",
       "  0.7692307692307693,\n",
       "  0.7723465604833173,\n",
       "  0.7856272838002436,\n",
       "  0.7752299693374217,\n",
       "  0.7857045423543855,\n",
       "  0.7874966460960559,\n",
       "  0.7932107113876116],\n",
       " 'model': TemporalEdgeClassifier(\n",
       "   (rnn): GRUCell(15, 256)\n",
       "   (gnn1): SAGEConv(256, 256, aggr=mean)\n",
       "   (gnn2): SAGEConv(256, 256, aggr=mean)\n",
       "   (gnn3): SAGEConv(256, 256, aggr=mean)\n",
       "   (dropout): Dropout(p=0.3, inplace=False)\n",
       "   (classifier): Linear(in_features=521, out_features=1, bias=True)\n",
       " )}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82e25fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Function to compute and print confusion matrix\n",
    "def compute_confusion_matrix(labels, preds, threshold=0.5):\n",
    "\n",
    "    # Convert probabilities to binary predictions using the threshold\n",
    "    binary_preds = (preds >= threshold).astype(int)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(labels, binary_preds)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Optional: Extract and print TP, TN, FP, FN\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"False Negatives (FN): {fn}\")\n",
    "    print(f\"True Positives (TP): {tp}\")\n",
    "    print(f\"Precision: {tp / (tp + fp + 1e-8):.4f}\")\n",
    "    print(f\"Recall: {tp / (tp + fn + 1e-8):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51d19dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = results['test_probs']\n",
    "test_labels = results['test_labels']\n",
    "val_probs = results['val_probs']\n",
    "val_labels = results['val_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f1f36ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1456973     389]\n",
      " [    285    1173]]\n",
      "True Negatives (TN): 1456973\n",
      "False Positives (FP): 389\n",
      "False Negatives (FN): 285\n",
      "True Positives (TP): 1173\n",
      "Precision: 0.7510\n",
      "Recall: 0.8045\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(val_labels, val_probs, threshold=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c31c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1382776     392]\n",
      " [    330    1311]]\n",
      "True Negatives (TN): 1382776\n",
      "False Positives (FP): 392\n",
      "False Negatives (FN): 330\n",
      "True Positives (TP): 1311\n",
      "Precision: 0.7698\n",
      "Recall: 0.7989\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(test_labels, test_probs, threshold=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b1255f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC Score: 0.8357\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate PR curve data\n",
    "precision, recall, thresholds = precision_recall_curve(test_labels, test_probs)\n",
    "pr_auc = average_precision_score(test_labels, test_probs)\n",
    "\n",
    "# Plot PR curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, linewidth=2, label=f'PR AUC = {pr_auc:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"PR AUC Score: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5373b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae20c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-backup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
