{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83228cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Improved Temporal Graph Neural Network for Anti-Money Laundering Detection\n",
    "==========================================================================\n",
    "Optimized for F2 Score with structured code organization\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (precision_recall_curve, roc_auc_score, f1_score, \n",
    "                           precision_score, recall_score, fbeta_score, \n",
    "                           confusion_matrix, average_precision_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74ecce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent.parent))  # Adjust as needed\n",
    "from config import DATAPATH, SAMPLE_DATAPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ddba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f457192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration class for hyperparameters and settings\"\"\"\n",
    "    # Model architecture\n",
    "    HIDDEN_DIM = 128  # Increased from 128\n",
    "    NODE_DIM = 15\n",
    "    EDGE_DIM = 9\n",
    "    DROPOUT_RATE = 0.3\n",
    "    \n",
    "    # Training parameters\n",
    "    LEARNING_RATE = 0.0005  \n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    EPOCHS = 100\n",
    "    PATIENCE = 10  # Early stopping patience\n",
    "    \n",
    "    # F2 score optimization\n",
    "    BETA = 2  # For F2 score (emphasizes recall)\n",
    "    CLASS_WEIGHT_MULTIPLIER = 10  # Strong emphasis on minority class\n",
    "\n",
    "    # Criterion parameters\n",
    "    FOCAL_LOSS_ALPHA = 0.25\n",
    "    FOCAL_LOSS_GAMMA = 2.0\n",
    "    \n",
    "    # Data processing\n",
    "    TIME_WINDOW = '7D'\n",
    "    VALIDATION_SPLIT = 0.17\n",
    "    TEST_SPLIT = 0.13\n",
    "    \n",
    "    # Threshold optimization\n",
    "    THRESHOLD_SEARCH_RANGE = np.arange(0.05, 0.95, 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bc23495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "\n",
    "def detailed_memory_profile():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        # print(f\"Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "        \n",
    "        # Show memory summary\n",
    "        # print(torch.cuda.memory_summary())\n",
    "        return allocated, cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0671bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for addressing class imbalance - better than BCE for F2 optimization\"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08365f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGraphDataProcessor:\n",
    "    \"\"\"Enhanced data processor with better feature engineering for F2 optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, time_window='7D'):\n",
    "        self.time_window = time_window\n",
    "        self.scalers = {}\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_and_preprocess(self, df):\n",
    "        \"\"\"Load SAML-D dataset and perform initial preprocessing\"\"\"\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        \n",
    "        # Combine date and time into datetime\n",
    "        df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "        df = df.sort_values('datetime').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Loaded {len(df)} transactions\")\n",
    "        print(f\"Suspicious transactions: {df['Is_laundering'].sum()} ({df['Is_laundering'].mean()*100:.3f}%)\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def engineer_features(self, df):\n",
    "        \"\"\"Enhanced feature engineering for better detection\"\"\"\n",
    "        print(\"Engineering enhanced features...\")\n",
    "        \n",
    "        # Time-based features (more granular)\n",
    "        df['hour'] = df['datetime'].dt.hour.astype('int8')\n",
    "        df['month'] = df['datetime'].dt.month.astype('int8')\n",
    "        df['day_of_week'] = df['datetime'].dt.dayofweek.astype('int8')\n",
    "        df['day_of_month'] = df['datetime'].dt.day.astype('int8')\n",
    "        df['is_weekend'] = (df['day_of_week'] >= 5).astype('int8')\n",
    "        df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 5)).astype('int8')  # Night transactions\n",
    "        \n",
    "        # Amount-based features\n",
    "        df['log_amount'] = np.log1p(df['Amount']).astype('float32')\n",
    "        \n",
    "        # Calculate amount percentiles for anomaly detection\n",
    "        # amount_percentiles = df['Amount'].quantile([0.95, 0.99]).values\n",
    "        # df['high_amount'] = (df['Amount'] > amount_percentiles[0]).astype('int8')\n",
    "        # df['very_high_amount'] = (df['Amount'] > amount_percentiles[1]).astype('int8')\n",
    "        \n",
    "        # Geographic risk features\n",
    "        df['cross_border'] = (df['Payment_type'] == 'Cross-border').astype('int8')\n",
    "        risky_countries = {'Mexico', 'Turkey', 'Morocco', 'UAE'}\n",
    "        df['high_risk_sender'] = df['Sender_bank_location'].isin(risky_countries).astype('int8')\n",
    "        df['high_risk_receiver'] = df['Receiver_bank_location'].isin(risky_countries).astype('int8')\n",
    "        # df['both_high_risk'] = (df['high_risk_sender'] & df['high_risk_receiver']).astype('int8')\n",
    "        \n",
    "        # Currency features\n",
    "        df['currency_mismatch'] = (df['Payment_currency'] != df['Received_currency']).astype('int8')\n",
    "        \n",
    "        # Convert target\n",
    "        df['Is_laundering'] = df['Is_laundering'].astype('int8')\n",
    "        \n",
    "        # Clean up\n",
    "        columns_to_drop = ['Date', 'Time', 'Amount', 'Sender_bank_location', \n",
    "                          'Receiver_bank_location', 'Payment_currency', 'Received_currency', \n",
    "                          'Laundering_type']\n",
    "        df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_temporal_snapshots(self, df, account_features):\n",
    "        \"\"\"Create temporal graph snapshots with enhanced features\"\"\"\n",
    "        print(\"Creating temporal graph snapshots...\")\n",
    "        \n",
    "        # Global account mapping\n",
    "        all_accounts = list(set(df['Sender_account'].unique()) | set(df['Receiver_account'].unique()))\n",
    "        global_account_to_idx = {acc: idx for idx, acc in enumerate(all_accounts)}\n",
    "        global_num_nodes = len(all_accounts)\n",
    "        \n",
    "        # Time windows\n",
    "        start_date = df['datetime'].min().normalize().date()\n",
    "        end_date = df['datetime'].max().normalize().date()\n",
    "        \n",
    "        snapshots = []\n",
    "        print(f\"Processing time range: {start_date} to {end_date}\")\n",
    "\n",
    "        for window_start in pd.date_range(start=start_date, end=end_date, freq=self.time_window, inclusive='left'):\n",
    "            window_end = window_start + pd.Timedelta(days=7)\n",
    "            window_start_str = pd.to_datetime(window_start).strftime('%Y-%m-%d')\n",
    "            window_end_str = pd.to_datetime(window_end).strftime('%Y-%m-%d')\n",
    "            print(f\"Processing window: {window_start_str} to {window_end_str}\")\n",
    "            \n",
    "            # Get transactions in current window\n",
    "            window_mask = (df['datetime'] >= window_start_str) & (df['datetime'] < window_end_str)\n",
    "            window_trnx_data = df[window_mask].copy()\n",
    "            \n",
    "            # Account features for this window\n",
    "            window_accounts_features = account_features[account_features['window_start'] == window_start_str]\n",
    "            \n",
    "            if len(window_trnx_data) > 0:\n",
    "                graph_data = self._create_graph_snapshot(\n",
    "                    window_trnx_data, window_accounts_features,\n",
    "                    window_start_str, global_account_to_idx, global_num_nodes\n",
    "                )\n",
    "                if graph_data is not None:\n",
    "                    snapshots.append(graph_data)\n",
    "\n",
    "        print(f\"Created {len(snapshots)} temporal snapshots\")\n",
    "        return snapshots, global_num_nodes\n",
    "\n",
    "    def _create_graph_snapshot(self, window_trnx_data, window_accounts_features, \n",
    "                              timestamp, global_account_to_idx, global_num_nodes):\n",
    "        \"\"\"Create enhanced graph snapshot\"\"\"\n",
    "        if len(window_trnx_data) == 0:\n",
    "            return None\n",
    "\n",
    "        # Enhanced edge features\n",
    "        edge_feature_columns = [\n",
    "            'Payment_type_encoded', 'log_amount', 'month', 'day_of_week', 'hour', \n",
    "            'currency_mismatch', 'cross_border', 'high_risk_sender', 'high_risk_receiver',\n",
    "        ]\n",
    "        \n",
    "        # Filter available columns\n",
    "        edge_feature_columns = [col for col in edge_feature_columns if col in window_trnx_data.columns]\n",
    "\n",
    "        # Node features\n",
    "        node_feature_columns = ['sent_txns_count', 'fan_out', 'recv_txns_count', 'fan_in', \n",
    "                               'max_sent_txn_count', 'max_recv_txn_count', 'sent_recv_ratio', \n",
    "                               'fanout_fanin_ratio', 'log_med_sent_amt', 'log_std_sent_amt', \n",
    "                               'log_med_recv_amt', 'log_std_recv_amt', 'log_max_sent_txn_amt', \n",
    "                               'log_max_recv_txn_amt', 'log_total_txns_amt']\n",
    "\n",
    "        # Create mappings and features\n",
    "        sender_mapped = window_trnx_data['Sender_account'].map(global_account_to_idx)\n",
    "        receiver_mapped = window_trnx_data['Receiver_account'].map(global_account_to_idx)\n",
    "        edge_index = np.column_stack((sender_mapped, receiver_mapped))\n",
    "        edge_features = window_trnx_data[edge_feature_columns].values\n",
    "        transaction_labels = window_trnx_data['Is_laundering'].values\n",
    "\n",
    "        # Node features\n",
    "        node_features = np.zeros((global_num_nodes, len(node_feature_columns)))\n",
    "        try:\n",
    "            window_accounts_features['global_idx'] = window_accounts_features['account'].map(global_account_to_idx)\n",
    "            node_features[window_accounts_features['global_idx'].values] = window_accounts_features[node_feature_columns].values\n",
    "        except: \n",
    "            raise ValueError(\"Error in mapping account features to global indices.\")\n",
    "\n",
    "        # Convert to tensors\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "        edge_features = torch.tensor(edge_features, dtype=torch.float)\n",
    "        transaction_labels = torch.tensor(transaction_labels, dtype=torch.float)\n",
    "\n",
    "        return Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_features,\n",
    "            y=transaction_labels,\n",
    "            timestamp=timestamp,\n",
    "            num_nodes=global_num_nodes\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e55e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal GNN Model for Edge Classification\n",
    "class TemporalEdgeClassifier(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, dropout_rate):\n",
    "        super(TemporalEdgeClassifier, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.GRUCell(node_dim, hidden_dim)\n",
    "        self.gnn1 = SAGEConv(hidden_dim, hidden_dim, aggr='mean')\n",
    "        self.gnn2 = SAGEConv(hidden_dim, hidden_dim, aggr='mean')\n",
    "        self.gnn3 = SAGEConv(hidden_dim, hidden_dim, aggr='mean')\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        # self.classifier = nn.Linear(hidden_dim * 2 + edge_dim, 1)  # Binary classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 + edge_dim, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim * 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data, h):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        \n",
    "        # Update node hidden states with RNN (using current x)\n",
    "        h = self.rnn(x, h)\n",
    "        \n",
    "        # Apply GNN layers\n",
    "        h = F.relu(self.gnn1(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.gnn2(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.gnn3(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        # Edge features: concat sender h, receiver h, edge_attr\n",
    "        h_i = h[edge_index[0]]\n",
    "        h_j = h[edge_index[1]]\n",
    "        edge_input = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
    "        \n",
    "        # Prediction\n",
    "        out = self.classifier(edge_input)\n",
    "        \n",
    "        return out, h  # Return logits and updated h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59dd2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"Enhanced trainer class optimized for F2 score\"\"\"\n",
    "    \n",
    "    def __init__(self, config=Config(), mem_profile=False):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        self.mem_profile = mem_profile\n",
    "\n",
    "    def find_optimal_threshold(self, probs, labels):\n",
    "        \"\"\"Find optimal threshold for F2 score\"\"\"\n",
    "        best_f2 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in self.config.THRESHOLD_SEARCH_RANGE:\n",
    "            preds = (probs >= threshold).astype(int)\n",
    "            f2 = fbeta_score(labels, preds, beta=self.config.BETA, average='binary', zero_division=0)\n",
    "            if f2 > best_f2:\n",
    "                best_f2 = f2\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        return best_threshold, best_f2\n",
    "    \n",
    "    def compute_class_weights(self, snapshots):\n",
    "        \"\"\"Compute class weights for focal loss\"\"\"\n",
    "        all_labels = []\n",
    "        for snap in snapshots:\n",
    "            all_labels.extend(snap.y.cpu().numpy())\n",
    "        \n",
    "        all_labels = np.array(all_labels)\n",
    "        pos_weight = len(all_labels) / (2 * np.sum(all_labels))\n",
    "        return torch.tensor(pos_weight, dtype=torch.float).to(self.device)\n",
    "    \n",
    "    def train_model(self, snapshots, global_num_nodes):\n",
    "        \"\"\"Enhanced training with F2 optimization\"\"\"\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(len(snapshots) * (1 - self.config.VALIDATION_SPLIT - self.config.TEST_SPLIT))\n",
    "        val_size = int(len(snapshots) * self.config.VALIDATION_SPLIT)\n",
    "        \n",
    "        train_snaps = snapshots[:train_size]\n",
    "        val_snaps = snapshots[train_size:train_size + val_size]\n",
    "        test_snaps = snapshots[train_size + val_size:]\n",
    "        \n",
    "        print(f\"Data split - Train: {len(train_snaps)}, Val: {len(val_snaps)}, Test: {len(test_snaps)}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = TemporalEdgeClassifier(\n",
    "            self.config.NODE_DIM, \n",
    "            self.config.EDGE_DIM, \n",
    "            self.config.HIDDEN_DIM,\n",
    "            self.config.DROPOUT_RATE\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Compute class weights for focal loss\n",
    "        pos_weight = self.compute_class_weights(train_snaps)\n",
    "        criterion = FocalLoss(alpha=self.config.FOCAL_LOSS_ALPHA, gamma=self.config.FOCAL_LOSS_GAMMA)\n",
    "        \n",
    "        # Optimizer with different learning rates for different components\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': model.rnn.parameters(), 'lr': self.config.LEARNING_RATE * 0.5},\n",
    "            {'params': model.gnn1.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.gnn2.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.gnn3.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.classifier.parameters(), 'lr': self.config.LEARNING_RATE * 1.5}\n",
    "        ], weight_decay=self.config.WEIGHT_DECAY)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
    "        )\n",
    "        \n",
    "        # Training loop\n",
    "        best_f2_score = 0\n",
    "        patience_counter = 0\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "        f2_history = []\n",
    "        \n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "\n",
    "            if self.mem_profile:\n",
    "                print(f\"=== EPOCH {epoch} START ===\")\n",
    "                epoch_start_mem = detailed_memory_profile()\n",
    "                print(f\"Epoch Mem Allocated: {epoch_start_mem[0]:.3f} GB, Cached: {epoch_start_mem[0]:.3f} GB\")\n",
    "\n",
    "            for i, snap in enumerate(train_snaps):\n",
    "                if (i < 5) and self.mem_profile:\n",
    "                    print(f\"--- Snapshot {i} ---\")\n",
    "                    pre_snap = detailed_memory_profile()\n",
    "                    print(f\"Pre snap Allocated: {pre_snap[0]:.3f} GB, Cached: {pre_snap[0]:.3f} GB\")\n",
    "                \n",
    "                snap = snap.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                out, h = model(snap, h.detach())  # Detach to prevent gradient explosion\n",
    "                loss = criterion(out.squeeze(), snap.y)\n",
    "\n",
    "                if (i < 5) and self.mem_profile:\n",
    "                    post_forward = detailed_memory_profile()\n",
    "                    print(f\"Forward Mem Allocated: {post_forward[0]}, Cached: {post_forward[1]:.3f}GB cached\")\n",
    "                    print(f\"Forward pass added: {post_forward[1] - pre_snap[1]:.3f}GB cached\")\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "                optimizer.step()\n",
    "\n",
    "                if (i < 5) and self.mem_profile:\n",
    "                    post_backward = detailed_memory_profile()\n",
    "                    print(f\"Forward Mem Allocated: {post_backward[0]}, Cached: {post_backward[1]:.3f}GB cached\")\n",
    "                    print(f\"Backward pass added: {post_backward[1] - post_forward[1]:.3f}GB cached\")\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_snaps)\n",
    "            train_loss_history.append(avg_train_loss)\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_probs_list, val_labels_list = [], []\n",
    "            val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "                for snap in val_snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, h = model(snap, h)\n",
    "                    loss = criterion(out.squeeze(), snap.y)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    preds = torch.sigmoid(out).squeeze()\n",
    "                    val_probs_list.append(preds.cpu())\n",
    "                    val_labels_list.append(snap.y.cpu())\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_snaps)\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "            \n",
    "            # Calculate F2 score with optimal threshold\n",
    "            val_probs = torch.cat(val_probs_list).numpy()\n",
    "            val_labels = torch.cat(val_labels_list).numpy()\n",
    "            \n",
    "            optimal_threshold, f2_score = self.find_optimal_threshold(val_probs, val_labels)\n",
    "            f2_history.append(f2_score)\n",
    "            recall = recall_score(val_labels, (val_probs >= optimal_threshold).astype(int), zero_division=0)\n",
    "            \n",
    "            # Update scheduler with F2 score\n",
    "            # scheduler.step(f2_score)\n",
    "            scheduler.step(avg_val_loss)\n",
    "            \n",
    "            # Early stopping based on F2 score\n",
    "            if f2_score > best_f2_score:\n",
    "                best_f2_score = f2_score\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                # torch.save(model.state_dict(), './outputs/best_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # if (epoch + 1) % 10 == 0:\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"Epoch {epoch+1}: Train Loss(x1e3): {1000*avg_train_loss:.4f}, Val Loss(x1e3): {1000*avg_val_loss:.4f}, \"\n",
    "                        f\"F2: {f2_score:.4f}, Threshold: {optimal_threshold:.3f}, Recall: {recall:.4f}, \"\n",
    "                        f\"LR: {current_lr:.6f}\")\n",
    "\n",
    "            if patience_counter >= self.config.PATIENCE:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # Load best model and evaluate\n",
    "        # model.load_state_dict(torch.load('./outputs/best_model.pth'))\n",
    "        \n",
    "        # Final evaluation\n",
    "        results = self._evaluate_model(model, train_snaps, val_snaps, test_snaps, global_num_nodes)\n",
    "        results.update({\n",
    "            'train_loss_history': train_loss_history,\n",
    "            'val_loss_history': val_loss_history,\n",
    "            'f2_history': f2_history,\n",
    "            'model': model\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_model(self, model, train_snaps, val_snaps, test_snaps, global_num_nodes):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        model.eval()\n",
    "        results = {}\n",
    "        \n",
    "        for split_name, snaps in [('val', val_snaps), ('test', test_snaps)]:\n",
    "            probs_list, labels_list = [], []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "                for snap in snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, h = model(snap, h)\n",
    "                    preds = torch.sigmoid(out).squeeze().cpu().numpy()\n",
    "                    probs_list.extend(preds)\n",
    "                    labels_list.extend(snap.y.cpu().numpy())\n",
    "            \n",
    "            probs = np.array(probs_list)\n",
    "            labels = np.array(labels_list)\n",
    "            \n",
    "            # Find optimal threshold\n",
    "            optimal_threshold, best_f2 = self.find_optimal_threshold(probs, labels)\n",
    "            binary_preds = (probs >= optimal_threshold).astype(int)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            precision = precision_score(labels, binary_preds, zero_division=0)\n",
    "            recall = recall_score(labels, binary_preds, zero_division=0)\n",
    "            f1 = f1_score(labels, binary_preds, zero_division=0)\n",
    "            roc_auc = roc_auc_score(labels, probs)\n",
    "            pr_auc = average_precision_score(labels, probs)\n",
    "            \n",
    "            results[f'{split_name}_probs'] = probs\n",
    "            results[f'{split_name}_labels'] = labels\n",
    "            results[f'{split_name}_threshold'] = optimal_threshold\n",
    "            results[f'{split_name}_precision'] = precision\n",
    "            results[f'{split_name}_recall'] = recall\n",
    "            results[f'{split_name}_f1'] = f1\n",
    "            results[f'{split_name}_f2'] = best_f2\n",
    "            results[f'{split_name}_roc_auc'] = roc_auc\n",
    "            results[f'{split_name}_pr_auc'] = pr_auc\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2124555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset\n",
    "df = pd.read_csv(DATAPATH)\n",
    "\n",
    "# Filter by data range\n",
    "# df = df[df['Date'] < '2023-08-18']\n",
    "# df = df.head(300000).copy()\n",
    "\n",
    "# run feature engg.ipynb to get the account_stats_7D.csv\n",
    "account_stats = pd.read_csv('../account_stats_7D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9178de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Loaded 9504852 transactions\n",
      "Suspicious transactions: 9873 (0.104%)\n",
      "Engineering enhanced features...\n"
     ]
    }
   ],
   "source": [
    "graph_processor = TemporalGraphDataProcessor()\n",
    "df = graph_processor.load_and_preprocess(df)\n",
    "df = graph_processor.engineer_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8bfb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For each categorical column\n",
    "# categorical_cols = ['Payment_currency', 'Received_currency', 'Sender_bank_location', \n",
    "#                    'Receiver_bank_location', 'Payment_type']\n",
    "categorical_cols = ['Payment_type']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "# Drop original object columns\n",
    "df = df.drop(categorical_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43c740f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process accont_stats\n",
    "columns = ['med_sent_amt', 'std_sent_amt', 'med_recv_amt', 'std_recv_amt', \n",
    "           'max_sent_txn_amt', 'max_recv_txn_amt', 'total_txns_amt']\n",
    "\n",
    "for col in columns:\n",
    "    account_stats['log_' + col] = np.log1p(account_stats[col]).astype('float32')\n",
    "\n",
    "account_stats = account_stats.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "094d1677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data types to optimize memory\n",
    "account_stats = account_stats.astype({\n",
    "    'sent_txns_count': 'int32',\n",
    "    'recv_txns_count': 'int32',\n",
    "    'fan_out': 'int32',\n",
    "    'fan_in': 'int32',\n",
    "    'max_sent_txn_count': 'int32',\n",
    "    'max_recv_txn_count': 'int32',\n",
    "    'sent_recv_ratio': 'float32',\n",
    "    'fanout_fanin_ratio': 'float32'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79bf8e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporal graph snapshots...\n",
      "Processing time range: 2022-10-07 to 2023-08-23\n",
      "Processing window: 2022-10-07 to 2022-10-14\n",
      "Processing window: 2022-10-14 to 2022-10-21\n",
      "Processing window: 2022-10-21 to 2022-10-28\n",
      "Processing window: 2022-10-28 to 2022-11-04\n",
      "Processing window: 2022-11-04 to 2022-11-11\n",
      "Processing window: 2022-11-11 to 2022-11-18\n",
      "Processing window: 2022-11-18 to 2022-11-25\n",
      "Processing window: 2022-11-25 to 2022-12-02\n",
      "Processing window: 2022-12-02 to 2022-12-09\n",
      "Processing window: 2022-12-09 to 2022-12-16\n",
      "Processing window: 2022-12-16 to 2022-12-23\n",
      "Processing window: 2022-12-23 to 2022-12-30\n",
      "Processing window: 2022-12-30 to 2023-01-06\n",
      "Processing window: 2023-01-06 to 2023-01-13\n",
      "Processing window: 2023-01-13 to 2023-01-20\n",
      "Processing window: 2023-01-20 to 2023-01-27\n",
      "Processing window: 2023-01-27 to 2023-02-03\n",
      "Processing window: 2023-02-03 to 2023-02-10\n",
      "Processing window: 2023-02-10 to 2023-02-17\n",
      "Processing window: 2023-02-17 to 2023-02-24\n",
      "Processing window: 2023-02-24 to 2023-03-03\n",
      "Processing window: 2023-03-03 to 2023-03-10\n",
      "Processing window: 2023-03-10 to 2023-03-17\n",
      "Processing window: 2023-03-17 to 2023-03-24\n",
      "Processing window: 2023-03-24 to 2023-03-31\n",
      "Processing window: 2023-03-31 to 2023-04-07\n",
      "Processing window: 2023-04-07 to 2023-04-14\n",
      "Processing window: 2023-04-14 to 2023-04-21\n",
      "Processing window: 2023-04-21 to 2023-04-28\n",
      "Processing window: 2023-04-28 to 2023-05-05\n",
      "Processing window: 2023-05-05 to 2023-05-12\n",
      "Processing window: 2023-05-12 to 2023-05-19\n",
      "Processing window: 2023-05-19 to 2023-05-26\n",
      "Processing window: 2023-05-26 to 2023-06-02\n",
      "Processing window: 2023-06-02 to 2023-06-09\n",
      "Processing window: 2023-06-09 to 2023-06-16\n",
      "Processing window: 2023-06-16 to 2023-06-23\n",
      "Processing window: 2023-06-23 to 2023-06-30\n",
      "Processing window: 2023-06-30 to 2023-07-07\n",
      "Processing window: 2023-07-07 to 2023-07-14\n",
      "Processing window: 2023-07-14 to 2023-07-21\n",
      "Processing window: 2023-07-21 to 2023-07-28\n",
      "Processing window: 2023-07-28 to 2023-08-04\n",
      "Processing window: 2023-08-04 to 2023-08-11\n",
      "Processing window: 2023-08-11 to 2023-08-18\n",
      "Processing window: 2023-08-18 to 2023-08-25\n",
      "Created 46 temporal snapshots\n"
     ]
    }
   ],
   "source": [
    "snapshots, global_num_nodes = graph_processor.create_temporal_snapshots(df, account_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a083f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory - Allocated: 14.26GB, Cached: 27.08GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89fc6783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Data split - Train: 32, Val: 7, Test: 7\n",
      "Epoch 1: Train Loss(x1e3): 2.2532, Val Loss(x1e3): 0.7271, F2: 0.0084, Threshold: 0.100, Recall: 0.0542, LR: 0.000250\n",
      "Epoch 2: Train Loss(x1e3): 0.7823, Val Loss(x1e3): 0.7097, F2: 0.0111, Threshold: 0.050, Recall: 0.4739, LR: 0.000250\n",
      "Epoch 3: Train Loss(x1e3): 0.7093, Val Loss(x1e3): 0.6290, F2: 0.0159, Threshold: 0.100, Recall: 0.1591, LR: 0.000250\n",
      "Epoch 4: Train Loss(x1e3): 0.6503, Val Loss(x1e3): 0.5794, F2: 0.0247, Threshold: 0.100, Recall: 0.3532, LR: 0.000250\n",
      "Epoch 5: Train Loss(x1e3): 0.6043, Val Loss(x1e3): 0.5392, F2: 0.0339, Threshold: 0.150, Recall: 0.1619, LR: 0.000250\n",
      "Epoch 6: Train Loss(x1e3): 0.5560, Val Loss(x1e3): 0.4962, F2: 0.0556, Threshold: 0.150, Recall: 0.3210, LR: 0.000250\n",
      "Epoch 7: Train Loss(x1e3): 0.5084, Val Loss(x1e3): 0.4324, F2: 0.1611, Threshold: 0.150, Recall: 0.5501, LR: 0.000250\n",
      "Epoch 8: Train Loss(x1e3): 0.4500, Val Loss(x1e3): 0.3705, F2: 0.3536, Threshold: 0.200, Recall: 0.4938, LR: 0.000250\n",
      "Epoch 9: Train Loss(x1e3): 0.3978, Val Loss(x1e3): 0.3190, F2: 0.4376, Threshold: 0.250, Recall: 0.5487, LR: 0.000250\n",
      "Epoch 10: Train Loss(x1e3): 0.3568, Val Loss(x1e3): 0.2741, F2: 0.5313, Threshold: 0.300, Recall: 0.5549, LR: 0.000250\n",
      "Epoch 11: Train Loss(x1e3): 0.3194, Val Loss(x1e3): 0.2443, F2: 0.5917, Threshold: 0.300, Recall: 0.6488, LR: 0.000250\n",
      "Epoch 12: Train Loss(x1e3): 0.3123, Val Loss(x1e3): 0.2328, F2: 0.6239, Threshold: 0.300, Recall: 0.6468, LR: 0.000250\n",
      "Epoch 13: Train Loss(x1e3): 0.2658, Val Loss(x1e3): 0.2590, F2: 0.5998, Threshold: 0.400, Recall: 0.6043, LR: 0.000250\n",
      "Epoch 14: Train Loss(x1e3): 0.3174, Val Loss(x1e3): 0.2166, F2: 0.6468, Threshold: 0.350, Recall: 0.6598, LR: 0.000250\n",
      "Epoch 15: Train Loss(x1e3): 0.2416, Val Loss(x1e3): 0.2090, F2: 0.6742, Threshold: 0.400, Recall: 0.6790, LR: 0.000250\n",
      "Epoch 16: Train Loss(x1e3): 0.2850, Val Loss(x1e3): 0.2083, F2: 0.6648, Threshold: 0.450, Recall: 0.6564, LR: 0.000250\n",
      "Epoch 17: Train Loss(x1e3): 0.2097, Val Loss(x1e3): 0.2188, F2: 0.7036, Threshold: 0.450, Recall: 0.7016, LR: 0.000250\n",
      "Epoch 18: Train Loss(x1e3): 0.3156, Val Loss(x1e3): 0.2014, F2: 0.6800, Threshold: 0.400, Recall: 0.6612, LR: 0.000250\n",
      "Epoch 19: Train Loss(x1e3): 0.2073, Val Loss(x1e3): 0.1734, F2: 0.7069, Threshold: 0.400, Recall: 0.7030, LR: 0.000250\n",
      "Epoch 20: Train Loss(x1e3): 0.1918, Val Loss(x1e3): 0.2200, F2: 0.7272, Threshold: 0.500, Recall: 0.7174, LR: 0.000250\n",
      "Epoch 21: Train Loss(x1e3): 0.2510, Val Loss(x1e3): 0.1695, F2: 0.7137, Threshold: 0.400, Recall: 0.6968, LR: 0.000250\n",
      "Epoch 22: Train Loss(x1e3): 0.1790, Val Loss(x1e3): 0.1697, F2: 0.7346, Threshold: 0.400, Recall: 0.7510, LR: 0.000250\n",
      "Epoch 23: Train Loss(x1e3): 0.1976, Val Loss(x1e3): 0.1562, F2: 0.7517, Threshold: 0.450, Recall: 0.7407, LR: 0.000250\n",
      "Epoch 24: Train Loss(x1e3): 0.1718, Val Loss(x1e3): 0.1666, F2: 0.7556, Threshold: 0.450, Recall: 0.7586, LR: 0.000250\n",
      "Epoch 25: Train Loss(x1e3): 0.2001, Val Loss(x1e3): 0.1511, F2: 0.7467, Threshold: 0.350, Recall: 0.7613, LR: 0.000250\n",
      "Epoch 26: Train Loss(x1e3): 0.1565, Val Loss(x1e3): 0.1688, F2: 0.7530, Threshold: 0.450, Recall: 0.7565, LR: 0.000250\n",
      "Epoch 27: Train Loss(x1e3): 0.1910, Val Loss(x1e3): 0.1459, F2: 0.7592, Threshold: 0.400, Recall: 0.7695, LR: 0.000250\n",
      "Epoch 28: Train Loss(x1e3): 0.1547, Val Loss(x1e3): 0.1541, F2: 0.7693, Threshold: 0.450, Recall: 0.7757, LR: 0.000250\n",
      "Epoch 29: Train Loss(x1e3): 0.1874, Val Loss(x1e3): 0.1448, F2: 0.7639, Threshold: 0.450, Recall: 0.7634, LR: 0.000250\n",
      "Epoch 30: Train Loss(x1e3): 0.1518, Val Loss(x1e3): 0.1497, F2: 0.7714, Threshold: 0.450, Recall: 0.7750, LR: 0.000250\n",
      "Epoch 31: Train Loss(x1e3): 0.1885, Val Loss(x1e3): 0.1371, F2: 0.7664, Threshold: 0.450, Recall: 0.7579, LR: 0.000250\n",
      "Epoch 32: Train Loss(x1e3): 0.1440, Val Loss(x1e3): 0.1496, F2: 0.7709, Threshold: 0.450, Recall: 0.7716, LR: 0.000250\n",
      "Epoch 33: Train Loss(x1e3): 0.1713, Val Loss(x1e3): 0.1312, F2: 0.7804, Threshold: 0.450, Recall: 0.7750, LR: 0.000250\n",
      "Epoch 34: Train Loss(x1e3): 0.1589, Val Loss(x1e3): 0.1290, F2: 0.7848, Threshold: 0.400, Recall: 0.7874, LR: 0.000250\n",
      "Epoch 35: Train Loss(x1e3): 0.1479, Val Loss(x1e3): 0.1406, F2: 0.7764, Threshold: 0.450, Recall: 0.7689, LR: 0.000250\n",
      "Epoch 36: Train Loss(x1e3): 0.1662, Val Loss(x1e3): 0.1370, F2: 0.7794, Threshold: 0.450, Recall: 0.7764, LR: 0.000250\n",
      "Epoch 37: Train Loss(x1e3): 0.1511, Val Loss(x1e3): 0.1310, F2: 0.7869, Threshold: 0.450, Recall: 0.7963, LR: 0.000125\n",
      "Epoch 38: Train Loss(x1e3): 0.1801, Val Loss(x1e3): 0.1354, F2: 0.7708, Threshold: 0.350, Recall: 0.7757, LR: 0.000125\n",
      "Epoch 39: Train Loss(x1e3): 0.1459, Val Loss(x1e3): 0.1363, F2: 0.7689, Threshold: 0.400, Recall: 0.7737, LR: 0.000125\n",
      "Epoch 40: Train Loss(x1e3): 0.1501, Val Loss(x1e3): 0.1314, F2: 0.7768, Threshold: 0.350, Recall: 0.7929, LR: 0.000063\n",
      "Epoch 41: Train Loss(x1e3): 0.1425, Val Loss(x1e3): 0.1381, F2: 0.7921, Threshold: 0.450, Recall: 0.8018, LR: 0.000063\n",
      "Epoch 42: Train Loss(x1e3): 0.1491, Val Loss(x1e3): 0.1288, F2: 0.7927, Threshold: 0.400, Recall: 0.7984, LR: 0.000063\n",
      "Epoch 43: Train Loss(x1e3): 0.1324, Val Loss(x1e3): 0.1275, F2: 0.7925, Threshold: 0.450, Recall: 0.7915, LR: 0.000063\n",
      "Epoch 44: Train Loss(x1e3): 0.1378, Val Loss(x1e3): 0.1293, F2: 0.7897, Threshold: 0.450, Recall: 0.7853, LR: 0.000063\n",
      "Epoch 45: Train Loss(x1e3): 0.1347, Val Loss(x1e3): 0.1298, F2: 0.7914, Threshold: 0.450, Recall: 0.7908, LR: 0.000063\n",
      "Epoch 46: Train Loss(x1e3): 0.1359, Val Loss(x1e3): 0.1284, F2: 0.7925, Threshold: 0.400, Recall: 0.8025, LR: 0.000031\n",
      "Epoch 47: Train Loss(x1e3): 0.1323, Val Loss(x1e3): 0.1239, F2: 0.7915, Threshold: 0.400, Recall: 0.7956, LR: 0.000031\n",
      "Epoch 48: Train Loss(x1e3): 0.1283, Val Loss(x1e3): 0.1247, F2: 0.7927, Threshold: 0.450, Recall: 0.7846, LR: 0.000031\n",
      "Epoch 49: Train Loss(x1e3): 0.1312, Val Loss(x1e3): 0.1259, F2: 0.7909, Threshold: 0.400, Recall: 0.7977, LR: 0.000031\n",
      "Epoch 50: Train Loss(x1e3): 0.1284, Val Loss(x1e3): 0.1274, F2: 0.7899, Threshold: 0.400, Recall: 0.8004, LR: 0.000016\n",
      "Epoch 51: Train Loss(x1e3): 0.1292, Val Loss(x1e3): 0.1242, F2: 0.7927, Threshold: 0.400, Recall: 0.7984, LR: 0.000016\n",
      "Epoch 52: Train Loss(x1e3): 0.1266, Val Loss(x1e3): 0.1244, F2: 0.7922, Threshold: 0.400, Recall: 0.7984, LR: 0.000016\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "trainer = ModelTrainer(config=Config(), mem_profile=False)\n",
    "results = trainer.train_model(snapshots, global_num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb0d7038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_probs': array([0.07599173, 0.05114054, 0.008664  , ..., 0.01349115, 0.00639494,\n",
       "        0.0211135 ], shape=(1458820,), dtype=float32),\n",
       " 'val_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1458820,), dtype=float32),\n",
       " 'val_threshold': np.float64(0.4),\n",
       " 'val_precision': 0.7683168316831683,\n",
       " 'val_recall': 0.7983539094650206,\n",
       " 'val_f1': 0.7830474268415741,\n",
       " 'val_f2': 0.7921600653327889,\n",
       " 'val_roc_auc': 0.9946448952753761,\n",
       " 'val_pr_auc': 0.8292650270783197,\n",
       " 'test_probs': array([0.0016545 , 0.00589785, 0.00312315, ..., 0.02162667, 0.31536555,\n",
       "        0.02201993], shape=(1384809,), dtype=float32),\n",
       " 'test_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1384809,), dtype=float32),\n",
       " 'test_threshold': np.float64(0.4),\n",
       " 'test_precision': 0.7329960652051715,\n",
       " 'test_recall': 0.7946374162096282,\n",
       " 'test_f1': 0.7625730994152047,\n",
       " 'test_f2': 0.78149346757761,\n",
       " 'test_roc_auc': 0.9936347573988676,\n",
       " 'test_pr_auc': 0.8295613547781632,\n",
       " 'train_loss_history': [0.002253224502055673,\n",
       "  0.0007822524112270912,\n",
       "  0.0007092962314345641,\n",
       "  0.0006503399154098588,\n",
       "  0.0006043471712473547,\n",
       "  0.0005559621804422932,\n",
       "  0.0005084318972876645,\n",
       "  0.00044997644545219373,\n",
       "  0.00039784122145647416,\n",
       "  0.0003568417823771597,\n",
       "  0.00031941697034199024,\n",
       "  0.0003123119136034802,\n",
       "  0.0002657572954376519,\n",
       "  0.0003173522031829634,\n",
       "  0.00024158376891136868,\n",
       "  0.0002849590096047905,\n",
       "  0.0002096791463372938,\n",
       "  0.0003155698136652063,\n",
       "  0.00020725519743791665,\n",
       "  0.00019180854087608168,\n",
       "  0.00025104440146606066,\n",
       "  0.0001790036772035819,\n",
       "  0.0001976427561203309,\n",
       "  0.00017178971256726072,\n",
       "  0.000200099606445292,\n",
       "  0.00015651639205316314,\n",
       "  0.00019098218194812944,\n",
       "  0.00015471070901185158,\n",
       "  0.00018740583368526131,\n",
       "  0.00015184180142568948,\n",
       "  0.00018852309403882828,\n",
       "  0.00014396814458450535,\n",
       "  0.0001713233102691447,\n",
       "  0.00015887030895100906,\n",
       "  0.00014786184897275234,\n",
       "  0.00016616930088275694,\n",
       "  0.00015108995580703777,\n",
       "  0.0001801066625830572,\n",
       "  0.00014588007775273582,\n",
       "  0.00015009040771474247,\n",
       "  0.00014247482863538607,\n",
       "  0.00014911769562786503,\n",
       "  0.00013243146190689004,\n",
       "  0.00013777353933619452,\n",
       "  0.00013470171461449354,\n",
       "  0.00013588493084171205,\n",
       "  0.0001322504217569076,\n",
       "  0.00012827824957639677,\n",
       "  0.0001312284730374813,\n",
       "  0.00012840713179684826,\n",
       "  0.0001292450201617612,\n",
       "  0.00012660053653235082],\n",
       " 'val_loss_history': [0.0007270873175002635,\n",
       "  0.0007096900454988438,\n",
       "  0.000628955038597009,\n",
       "  0.0005793584153122668,\n",
       "  0.0005391758667039019,\n",
       "  0.0004962159187666007,\n",
       "  0.0004324327497410455,\n",
       "  0.00037048339644180875,\n",
       "  0.0003189689596183598,\n",
       "  0.00027412600008704303,\n",
       "  0.0002443225239403546,\n",
       "  0.00023278254541634982,\n",
       "  0.0002590412914287299,\n",
       "  0.00021655668803889836,\n",
       "  0.00020904571907262186,\n",
       "  0.00020832709976405437,\n",
       "  0.00021884861572678865,\n",
       "  0.00020144823897031268,\n",
       "  0.0001734375858047445,\n",
       "  0.00022000707602793618,\n",
       "  0.00016945573276773627,\n",
       "  0.00016968142777581567,\n",
       "  0.0001561616819734419,\n",
       "  0.00016655120686794232,\n",
       "  0.0001511232985649258,\n",
       "  0.0001688112804133977,\n",
       "  0.00014589007852399454,\n",
       "  0.00015414265882489936,\n",
       "  0.00014480329160245934,\n",
       "  0.00014969914939553876,\n",
       "  0.00013712263275270483,\n",
       "  0.0001495795014696861,\n",
       "  0.00013122975776371147,\n",
       "  0.00012902426117632006,\n",
       "  0.00014057140340030725,\n",
       "  0.00013695842478357787,\n",
       "  0.0001309587397762308,\n",
       "  0.0001353905349138326,\n",
       "  0.00013634206905927776,\n",
       "  0.00013142649134221886,\n",
       "  0.00013806833261956593,\n",
       "  0.00012884983672328026,\n",
       "  0.0001275292639287987,\n",
       "  0.00012927148886124736,\n",
       "  0.00012983041025498615,\n",
       "  0.00012839855792533074,\n",
       "  0.00012391151644156447,\n",
       "  0.00012471036253763096,\n",
       "  0.00012588059221993068,\n",
       "  0.00012744422669389417,\n",
       "  0.0001242355626475598,\n",
       "  0.00012438927660696208],\n",
       " 'f2_history': [0.008402646301772001,\n",
       "  0.011050306881894447,\n",
       "  0.015934284811604554,\n",
       "  0.024690766132898646,\n",
       "  0.03389343673703863,\n",
       "  0.05556347057985468,\n",
       "  0.16110240649230645,\n",
       "  0.35363457760314343,\n",
       "  0.4375888852423148,\n",
       "  0.5312582085631731,\n",
       "  0.5916937703277458,\n",
       "  0.6239248378986371,\n",
       "  0.5998093681917211,\n",
       "  0.6467661691542289,\n",
       "  0.6742032143830019,\n",
       "  0.6647679911086413,\n",
       "  0.703576341127923,\n",
       "  0.6800225733634312,\n",
       "  0.7068965517241379,\n",
       "  0.7271968854282537,\n",
       "  0.7136836189940995,\n",
       "  0.7346035153629411,\n",
       "  0.7516703786191536,\n",
       "  0.7555677005055336,\n",
       "  0.746670254271492,\n",
       "  0.753003823047515,\n",
       "  0.7592367032074706,\n",
       "  0.7692830907359542,\n",
       "  0.7638984214138641,\n",
       "  0.7714363735663572,\n",
       "  0.7664031072270773,\n",
       "  0.7708647389338085,\n",
       "  0.7803867403314917,\n",
       "  0.7847962811047307,\n",
       "  0.7764233273306552,\n",
       "  0.7793996144312861,\n",
       "  0.7869052460349736,\n",
       "  0.7707509881422925,\n",
       "  0.7689161554192229,\n",
       "  0.7767773148770326,\n",
       "  0.792112752405475,\n",
       "  0.7926995369109234,\n",
       "  0.7924735613239939,\n",
       "  0.7896551724137931,\n",
       "  0.7913520933424846,\n",
       "  0.7924681658087239,\n",
       "  0.7914847161572053,\n",
       "  0.7926829268292683,\n",
       "  0.7909412404787813,\n",
       "  0.7899011777446866,\n",
       "  0.7926995369109234,\n",
       "  0.7921600653327889],\n",
       " 'model': TemporalEdgeClassifier(\n",
       "   (rnn): GRUCell(15, 128)\n",
       "   (gnn1): SAGEConv(128, 128, aggr=mean)\n",
       "   (gnn2): SAGEConv(128, 128, aggr=mean)\n",
       "   (gnn3): SAGEConv(128, 128, aggr=mean)\n",
       "   (dropout): Dropout(p=0.3, inplace=False)\n",
       "   (classifier): Sequential(\n",
       "     (0): Linear(in_features=265, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Dropout(p=0.3, inplace=False)\n",
       "     (3): Linear(in_features=256, out_features=1, bias=True)\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82e25fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Function to compute and print confusion matrix\n",
    "def compute_confusion_matrix(labels, preds, threshold=0.5):\n",
    "\n",
    "    # Convert probabilities to binary predictions using the threshold\n",
    "    binary_preds = (preds >= threshold).astype(int)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(labels, binary_preds)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Optional: Extract and print TP, TN, FP, FN\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"False Negatives (FN): {fn}\")\n",
    "    print(f\"True Positives (TP): {tp}\")\n",
    "    print(f\"Precision: {tp / (tp + fp + 1e-8):.4f}\")\n",
    "    print(f\"Recall: {tp / (tp + fn + 1e-8):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "51d19dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = results['test_probs']\n",
    "test_labels = results['test_labels']\n",
    "val_probs = results['val_probs']\n",
    "val_labels = results['val_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f1f36ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1456048    1314]\n",
      " [    234    1224]]\n",
      "True Negatives (TN): 1456048\n",
      "False Positives (FP): 1314\n",
      "False Negatives (FN): 234\n",
      "True Positives (TP): 1224\n",
      "Precision: 0.4823\n",
      "Recall: 0.8395\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(val_labels, val_probs, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c31c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1380784    2384]\n",
      " [    244    1397]]\n",
      "True Negatives (TN): 1380784\n",
      "False Positives (FP): 2384\n",
      "False Negatives (FN): 244\n",
      "True Positives (TP): 1397\n",
      "Precision: 0.3695\n",
      "Recall: 0.8513\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(test_labels, test_probs, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b1255f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC Score: 0.8296\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate PR curve data\n",
    "precision, recall, thresholds = precision_recall_curve(test_labels, test_probs)\n",
    "pr_auc = average_precision_score(test_labels, test_probs)\n",
    "\n",
    "# Plot PR curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, linewidth=2, label=f'PR AUC = {pr_auc:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"PR AUC Score: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5373b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae20c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fastai-backup]",
   "language": "python",
   "name": "conda-env-.conda-fastai-backup-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
