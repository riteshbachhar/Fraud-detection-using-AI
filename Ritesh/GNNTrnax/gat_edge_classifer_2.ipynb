{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83228cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Improved Temporal Graph Neural Network for Anti-Money Laundering Detection\n",
    "==========================================================================\n",
    "Optimized for F2 Score with structured code organization\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (precision_recall_curve, roc_auc_score, f1_score, \n",
    "                           precision_score, recall_score, fbeta_score, \n",
    "                           confusion_matrix, average_precision_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74ecce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent.parent))  # Adjust as needed\n",
    "from config import DATAPATH, SAMPLE_DATAPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ddba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f457192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration class for hyperparameters and settings\"\"\"\n",
    "    # Model architecture\n",
    "    HIDDEN_DIM = 256  # Increased from 128\n",
    "    NODE_DIM = 15\n",
    "    EDGE_DIM = 9\n",
    "    DROPOUT_RATE = 0.3\n",
    "    \n",
    "    # Training parameters\n",
    "    LEARNING_RATE = 0.0005  # Reduced for better convergence\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    EPOCHS = 75\n",
    "    PATIENCE = 10\n",
    "    \n",
    "    # F2 score optimization\n",
    "    BETA = 2  # For F2 score (emphasizes recall)\n",
    "    CLASS_WEIGHT_MULTIPLIER = 10  # Strong emphasis on minority class\n",
    "\n",
    "    # Criterion parameters\n",
    "    FOCAL_LOSS_ALPHA = 0.25\n",
    "    FOCAL_LOSS_GAMMA = 2\n",
    "    \n",
    "    # Data processing\n",
    "    TIME_WINDOW = '7D'\n",
    "    VALIDATION_SPLIT = 0.17\n",
    "    TEST_SPLIT = 0.13\n",
    "    \n",
    "    # Threshold optimization\n",
    "    THRESHOLD_SEARCH_RANGE = np.arange(0.05, 0.95, 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0671bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for addressing class imbalance - better than BCE for F2 optimization\"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08365f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGraphDataProcessor:\n",
    "    \"\"\"Enhanced data processor with better feature engineering for F2 optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, time_window='7D'):\n",
    "        self.time_window = time_window\n",
    "        self.scalers = {}\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_and_preprocess(self, df):\n",
    "        \"\"\"Load SAML-D dataset and perform initial preprocessing\"\"\"\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        \n",
    "        # Combine date and time into datetime\n",
    "        df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "        df = df.sort_values('datetime').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Loaded {len(df)} transactions\")\n",
    "        print(f\"Suspicious transactions: {df['Is_laundering'].sum()} ({df['Is_laundering'].mean()*100:.3f}%)\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def engineer_features(self, df):\n",
    "        \"\"\"Enhanced feature engineering for better detection\"\"\"\n",
    "        print(\"Engineering enhanced features...\")\n",
    "        \n",
    "        # Time-based features (more granular)\n",
    "        df['hour'] = df['datetime'].dt.hour.astype('int8')\n",
    "        df['month'] = df['datetime'].dt.month.astype('int8')\n",
    "        df['day_of_week'] = df['datetime'].dt.dayofweek.astype('int8')\n",
    "        df['day_of_month'] = df['datetime'].dt.day.astype('int8')\n",
    "        df['is_weekend'] = (df['day_of_week'] >= 5).astype('int8')\n",
    "        df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 5)).astype('int8')  # Night transactions\n",
    "        \n",
    "        # Amount-based features\n",
    "        df['log_amount'] = np.log1p(df['Amount']).astype('float32')\n",
    "        \n",
    "        # Calculate amount percentiles for anomaly detection\n",
    "        # amount_percentiles = df['Amount'].quantile([0.95, 0.99]).values\n",
    "        # df['high_amount'] = (df['Amount'] > amount_percentiles[0]).astype('int8')\n",
    "        # df['very_high_amount'] = (df['Amount'] > amount_percentiles[1]).astype('int8')\n",
    "        \n",
    "        # Geographic risk features\n",
    "        df['cross_border'] = (df['Payment_type'] == 'Cross-border').astype('int8')\n",
    "        risky_countries = {'Mexico', 'Turkey', 'Morocco', 'UAE'}\n",
    "        df['high_risk_sender'] = df['Sender_bank_location'].isin(risky_countries).astype('int8')\n",
    "        df['high_risk_receiver'] = df['Receiver_bank_location'].isin(risky_countries).astype('int8')\n",
    "        # df['both_high_risk'] = (df['high_risk_sender'] & df['high_risk_receiver']).astype('int8')\n",
    "        \n",
    "        # Currency features\n",
    "        df['currency_mismatch'] = (df['Payment_currency'] != df['Received_currency']).astype('int8')\n",
    "        \n",
    "        # Convert target\n",
    "        df['Is_laundering'] = df['Is_laundering'].astype('int8')\n",
    "        \n",
    "        # Clean up\n",
    "        columns_to_drop = ['Date', 'Time', 'Amount', 'Sender_bank_location', \n",
    "                          'Receiver_bank_location', 'Payment_currency', 'Received_currency', \n",
    "                          'Laundering_type']\n",
    "        df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_temporal_snapshots(self, df, account_features):\n",
    "        \"\"\"Create temporal graph snapshots with enhanced features\"\"\"\n",
    "        print(\"Creating temporal graph snapshots...\")\n",
    "        \n",
    "        # Global account mapping\n",
    "        all_accounts = list(set(df['Sender_account'].unique()) | set(df['Receiver_account'].unique()))\n",
    "        global_account_to_idx = {acc: idx for idx, acc in enumerate(all_accounts)}\n",
    "        global_num_nodes = len(all_accounts)\n",
    "        \n",
    "        # Time windows\n",
    "        start_date = df['datetime'].min().normalize().date()\n",
    "        end_date = df['datetime'].max().normalize().date()\n",
    "        \n",
    "        snapshots = []\n",
    "        print(f\"Processing time range: {start_date} to {end_date}\")\n",
    "\n",
    "        for window_start in pd.date_range(start=start_date, end=end_date, freq=self.time_window, inclusive='left'):\n",
    "            window_end = window_start + pd.Timedelta(days=7)\n",
    "            window_start_str = pd.to_datetime(window_start).strftime('%Y-%m-%d')\n",
    "            window_end_str = pd.to_datetime(window_end).strftime('%Y-%m-%d')\n",
    "            print(f\"Processing window: {window_start_str} to {window_end_str}\")\n",
    "            \n",
    "            # Get transactions in current window\n",
    "            window_mask = (df['datetime'] >= window_start_str) & (df['datetime'] < window_end_str)\n",
    "            window_trnx_data = df[window_mask].copy()\n",
    "            \n",
    "            # Account features for this window\n",
    "            window_accounts_features = account_features[account_features['window_start'] == window_start_str]\n",
    "            \n",
    "            if len(window_trnx_data) > 0:\n",
    "                graph_data = self._create_graph_snapshot(\n",
    "                    window_trnx_data, window_accounts_features,\n",
    "                    window_start_str, global_account_to_idx, global_num_nodes\n",
    "                )\n",
    "                if graph_data is not None:\n",
    "                    snapshots.append(graph_data)\n",
    "\n",
    "        print(f\"Created {len(snapshots)} temporal snapshots\")\n",
    "        return snapshots, global_num_nodes\n",
    "\n",
    "    def _create_graph_snapshot(self, window_trnx_data, window_accounts_features, \n",
    "                              timestamp, global_account_to_idx, global_num_nodes):\n",
    "        \"\"\"Create enhanced graph snapshot\"\"\"\n",
    "        if len(window_trnx_data) == 0:\n",
    "            return None\n",
    "\n",
    "        # Enhanced edge features\n",
    "        edge_feature_columns = [\n",
    "            'Payment_type_encoded', 'log_amount', 'month', 'day_of_week', 'hour', \n",
    "            'currency_mismatch', 'cross_border', 'high_risk_sender', 'high_risk_receiver',\n",
    "        ]\n",
    "        \n",
    "        # Filter available columns\n",
    "        edge_feature_columns = [col for col in edge_feature_columns if col in window_trnx_data.columns]\n",
    "\n",
    "        # Node features\n",
    "        node_feature_columns = ['sent_txns_count', 'fan_out', 'recv_txns_count', 'fan_in', \n",
    "                               'max_sent_txn_count', 'max_recv_txn_count', 'sent_recv_ratio', \n",
    "                               'fanout_fanin_ratio', 'log_med_sent_amt', 'log_std_sent_amt', \n",
    "                               'log_med_recv_amt', 'log_std_recv_amt', 'log_max_sent_txn_amt', \n",
    "                               'log_max_recv_txn_amt', 'log_total_txns_amt']\n",
    "\n",
    "        # Create mappings and features\n",
    "        sender_mapped = window_trnx_data['Sender_account'].map(global_account_to_idx)\n",
    "        receiver_mapped = window_trnx_data['Receiver_account'].map(global_account_to_idx)\n",
    "        edge_index = np.column_stack((sender_mapped, receiver_mapped))\n",
    "        edge_features = window_trnx_data[edge_feature_columns].values\n",
    "        transaction_labels = window_trnx_data['Is_laundering'].values\n",
    "\n",
    "        # Node features\n",
    "        node_features = np.zeros((global_num_nodes, len(node_feature_columns)))\n",
    "        try:\n",
    "            window_accounts_features['global_idx'] = window_accounts_features['account'].map(global_account_to_idx)\n",
    "            node_features[window_accounts_features['global_idx'].values] = window_accounts_features[node_feature_columns].values\n",
    "        except: \n",
    "            raise ValueError(\"Error in mapping account features to global indices.\")\n",
    "\n",
    "        # Convert to tensors\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "        edge_features = torch.tensor(edge_features, dtype=torch.float)\n",
    "        transaction_labels = torch.tensor(transaction_labels, dtype=torch.float)\n",
    "\n",
    "        return Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_features,\n",
    "            y=transaction_labels,\n",
    "            timestamp=timestamp,\n",
    "            num_nodes=global_num_nodes\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fbfa562",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalEdgeClassifier(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, dropout_rate):\n",
    "        super(TemporalEdgeClassifier, self).__init__()\n",
    "        \n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(node_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Change 2: Multi-head attention in GNN layers\n",
    "        self.gnn1 = GATConv(hidden_dim, hidden_dim, heads=4, concat=False)\n",
    "        self.gnn2 = GATConv(hidden_dim, hidden_dim, heads=2, concat=False)\n",
    "        self.gnn3 = GATConv(hidden_dim, hidden_dim, heads=2, concat=False)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        # Change 3: Larger classifier with residual connection\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        \n",
    "        h = self.node_encoder(x)\n",
    "        \n",
    "        # Apply GNN layers\n",
    "        h = F.relu(self.gnn1(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.gnn2(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.gnn3(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        \n",
    "        # Edge features\n",
    "        h_i = h[edge_index[0]]\n",
    "        h_j = h[edge_index[1]]\n",
    "        edge_input = torch.cat([h_i + h_j, edge_attr], dim=-1)\n",
    "        \n",
    "        # Prediction\n",
    "        out = self.classifier(edge_input)\n",
    "        \n",
    "        return out, h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59dd2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"Enhanced trainer class optimized for F2 score\"\"\"\n",
    "    \n",
    "    def __init__(self, config=Config()):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "    \n",
    "    def find_optimal_threshold(self, probs, labels):\n",
    "        \"\"\"Find optimal threshold for F2 score\"\"\"\n",
    "        best_f2 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in self.config.THRESHOLD_SEARCH_RANGE:\n",
    "            preds = (probs >= threshold).astype(int)\n",
    "            f2 = fbeta_score(labels, preds, beta=self.config.BETA, average='binary', zero_division=0)\n",
    "            if f2 > best_f2:\n",
    "                best_f2 = f2\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        return best_threshold, best_f2\n",
    "    \n",
    "    def compute_class_weights(self, snapshots):\n",
    "        \"\"\"Compute class weights for focal loss\"\"\"\n",
    "        all_labels = []\n",
    "        for snap in snapshots:\n",
    "            all_labels.extend(snap.y.cpu().numpy())\n",
    "        \n",
    "        all_labels = np.array(all_labels)\n",
    "        pos_weight = len(all_labels) / (2 * np.sum(all_labels))\n",
    "        return torch.tensor(pos_weight, dtype=torch.float).to(self.device)\n",
    "    \n",
    "    def train_model(self, snapshots, global_num_nodes):\n",
    "        \"\"\"Enhanced training with F2 optimization\"\"\"\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(len(snapshots) * (1 - self.config.VALIDATION_SPLIT - self.config.TEST_SPLIT))\n",
    "        val_size = int(len(snapshots) * self.config.VALIDATION_SPLIT)\n",
    "        \n",
    "        train_snaps = snapshots[:train_size]\n",
    "        val_snaps = snapshots[train_size:train_size + val_size]\n",
    "        test_snaps = snapshots[train_size + val_size:]\n",
    "        \n",
    "        print(f\"Data split - Train: {len(train_snaps)}, Val: {len(val_snaps)}, Test: {len(test_snaps)}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = TemporalEdgeClassifier(\n",
    "            self.config.NODE_DIM, \n",
    "            self.config.EDGE_DIM, \n",
    "            self.config.HIDDEN_DIM,\n",
    "            self.config.DROPOUT_RATE\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Compute class weights for focal loss\n",
    "        pos_weight = self.compute_class_weights(train_snaps)\n",
    "        criterion = FocalLoss(alpha=self.config.FOCAL_LOSS_ALPHA, gamma=self.config.FOCAL_LOSS_GAMMA)\n",
    "        \n",
    "        # Optimizer with different learning rates for different components\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': model.node_encoder.parameters(), 'lr': self.config.LEARNING_RATE * 0.5},\n",
    "            {'params': model.gnn1.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.gnn2.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.gnn3.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.classifier.parameters(), 'lr': self.config.LEARNING_RATE * 1.5}\n",
    "        ], weight_decay=self.config.WEIGHT_DECAY)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.7, patience=5, verbose=True\n",
    "        )\n",
    "        \n",
    "        # Training loop\n",
    "        best_f2_score = 0\n",
    "        patience_counter = 0\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "        f2_history = []\n",
    "        \n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            \n",
    "            for snap in train_snaps:\n",
    "                snap = snap.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                out, _ = model(snap)\n",
    "                loss = criterion(out.squeeze(), snap.y)\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_snaps)\n",
    "            train_loss_history.append(avg_train_loss)\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_probs_list, val_labels_list = [], []\n",
    "            val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for snap in val_snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, _ = model(snap)\n",
    "                    loss = criterion(out.squeeze(), snap.y)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    preds = torch.sigmoid(out).squeeze()\n",
    "                    val_probs_list.append(preds.cpu())\n",
    "                    val_labels_list.append(snap.y.cpu())\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_snaps)\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "            \n",
    "            # Scale\n",
    "            avg_train_loss *= 1000\n",
    "            avg_val_loss *= 1000\n",
    "            \n",
    "            # Calculate F2 score with optimal threshold\n",
    "            val_probs = torch.cat(val_probs_list).numpy()\n",
    "            val_labels = torch.cat(val_labels_list).numpy()\n",
    "            \n",
    "            optimal_threshold, f2_score = self.find_optimal_threshold(val_probs, val_labels)\n",
    "            f2_history.append(f2_score)\n",
    "            recall = recall_score(val_labels, (val_probs >= optimal_threshold).astype(int), zero_division=0)\n",
    "            \n",
    "            scheduler.step(f2_score)\n",
    "            \n",
    "            # Early stopping based on F2 score\n",
    "            if f2_score > best_f2_score:\n",
    "                best_f2_score = f2_score\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                # torch.save(model.state_dict(), './outputs/best_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}: Train Loss(x1e3): {avg_train_loss:.4f}, Val Loss(x1e3): {avg_val_loss:.4f}, \"\n",
    "                        f\"F2: {f2_score:.4f}, Threshold: {optimal_threshold:.3f}, Recall: {recall:.4f}\")\n",
    "            \n",
    "            if patience_counter >= self.config.PATIENCE:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # Load best model and evaluate\n",
    "        # model.load_state_dict(torch.load('./outputs/best_model.pth'))\n",
    "        \n",
    "        # Final evaluation\n",
    "        results = self._evaluate_model(model, train_snaps, val_snaps, test_snaps, global_num_nodes)\n",
    "        results.update({\n",
    "            'train_loss_history': train_loss_history,\n",
    "            'val_loss_history': val_loss_history,\n",
    "            'f2_history': f2_history,\n",
    "            'model': model\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_model(self, model, train_snaps, val_snaps, test_snaps, global_num_nodes):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        model.eval()\n",
    "        results = {}\n",
    "        \n",
    "        for split_name, snaps in [('val', val_snaps), ('test', test_snaps)]:\n",
    "            probs_list, labels_list = [], []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for snap in snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, _ = model(snap)\n",
    "                    preds = torch.sigmoid(out).squeeze().cpu().numpy()\n",
    "                    probs_list.extend(preds)\n",
    "                    labels_list.extend(snap.y.cpu().numpy())\n",
    "            \n",
    "            probs = np.array(probs_list)\n",
    "            labels = np.array(labels_list)\n",
    "            \n",
    "            # Find optimal threshold\n",
    "            optimal_threshold, best_f2 = self.find_optimal_threshold(probs, labels)\n",
    "            binary_preds = (probs >= optimal_threshold).astype(int)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            precision = precision_score(labels, binary_preds, zero_division=0)\n",
    "            recall = recall_score(labels, binary_preds, zero_division=0)\n",
    "            f1 = f1_score(labels, binary_preds, zero_division=0)\n",
    "            roc_auc = roc_auc_score(labels, probs)\n",
    "            pr_auc = average_precision_score(labels, probs)\n",
    "            \n",
    "            results[f'{split_name}_probs'] = probs\n",
    "            results[f'{split_name}_labels'] = labels\n",
    "            results[f'{split_name}_threshold'] = optimal_threshold\n",
    "            results[f'{split_name}_precision'] = precision\n",
    "            results[f'{split_name}_recall'] = recall\n",
    "            results[f'{split_name}_f1'] = f1\n",
    "            results[f'{split_name}_f2'] = best_f2\n",
    "            results[f'{split_name}_roc_auc'] = roc_auc\n",
    "            results[f'{split_name}_pr_auc'] = pr_auc\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2124555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset\n",
    "df = pd.read_csv(DATAPATH)\n",
    "\n",
    "# Filter by data range\n",
    "# df = df[df['Date'] < '2023-08-18']\n",
    "# df = df.head(300000).copy()\n",
    "\n",
    "# run feature engg.ipynb to get the account_stats_7D.csv\n",
    "account_stats = pd.read_csv('../account_stats_7D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9178de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Loaded 9504852 transactions\n",
      "Suspicious transactions: 9873 (0.104%)\n",
      "Engineering enhanced features...\n"
     ]
    }
   ],
   "source": [
    "graph_processor = TemporalGraphDataProcessor()\n",
    "df = graph_processor.load_and_preprocess(df)\n",
    "df = graph_processor.engineer_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8bfb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For each categorical column\n",
    "# categorical_cols = ['Payment_currency', 'Received_currency', 'Sender_bank_location', \n",
    "#                    'Receiver_bank_location', 'Payment_type']\n",
    "categorical_cols = ['Payment_type']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "# Drop original object columns\n",
    "df = df.drop(categorical_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43c740f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process accont_stats\n",
    "columns = ['med_sent_amt', 'std_sent_amt', 'med_recv_amt', 'std_recv_amt', \n",
    "           'max_sent_txn_amt', 'max_recv_txn_amt', 'total_txns_amt']\n",
    "\n",
    "for col in columns:\n",
    "    account_stats['log_' + col] = np.log1p(account_stats[col]).astype('float32')\n",
    "\n",
    "account_stats = account_stats.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "094d1677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data types to optimize memory\n",
    "account_stats = account_stats.astype({\n",
    "    'sent_txns_count': 'int32',\n",
    "    'recv_txns_count': 'int32',\n",
    "    'fan_out': 'int32',\n",
    "    'fan_in': 'int32',\n",
    "    'max_sent_txn_count': 'int32',\n",
    "    'max_recv_txn_count': 'int32',\n",
    "    'sent_recv_ratio': 'float32',\n",
    "    'fanout_fanin_ratio': 'float32'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79bf8e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporal graph snapshots...\n",
      "Processing time range: 2022-10-07 to 2023-08-23\n",
      "Processing window: 2022-10-07 to 2022-10-14\n",
      "Processing window: 2022-10-14 to 2022-10-21\n",
      "Processing window: 2022-10-21 to 2022-10-28\n",
      "Processing window: 2022-10-28 to 2022-11-04\n",
      "Processing window: 2022-11-04 to 2022-11-11\n",
      "Processing window: 2022-11-11 to 2022-11-18\n",
      "Processing window: 2022-11-18 to 2022-11-25\n",
      "Processing window: 2022-11-25 to 2022-12-02\n",
      "Processing window: 2022-12-02 to 2022-12-09\n",
      "Processing window: 2022-12-09 to 2022-12-16\n",
      "Processing window: 2022-12-16 to 2022-12-23\n",
      "Processing window: 2022-12-23 to 2022-12-30\n",
      "Processing window: 2022-12-30 to 2023-01-06\n",
      "Processing window: 2023-01-06 to 2023-01-13\n",
      "Processing window: 2023-01-13 to 2023-01-20\n",
      "Processing window: 2023-01-20 to 2023-01-27\n",
      "Processing window: 2023-01-27 to 2023-02-03\n",
      "Processing window: 2023-02-03 to 2023-02-10\n",
      "Processing window: 2023-02-10 to 2023-02-17\n",
      "Processing window: 2023-02-17 to 2023-02-24\n",
      "Processing window: 2023-02-24 to 2023-03-03\n",
      "Processing window: 2023-03-03 to 2023-03-10\n",
      "Processing window: 2023-03-10 to 2023-03-17\n",
      "Processing window: 2023-03-17 to 2023-03-24\n",
      "Processing window: 2023-03-24 to 2023-03-31\n",
      "Processing window: 2023-03-31 to 2023-04-07\n",
      "Processing window: 2023-04-07 to 2023-04-14\n",
      "Processing window: 2023-04-14 to 2023-04-21\n",
      "Processing window: 2023-04-21 to 2023-04-28\n",
      "Processing window: 2023-04-28 to 2023-05-05\n",
      "Processing window: 2023-05-05 to 2023-05-12\n",
      "Processing window: 2023-05-12 to 2023-05-19\n",
      "Processing window: 2023-05-19 to 2023-05-26\n",
      "Processing window: 2023-05-26 to 2023-06-02\n",
      "Processing window: 2023-06-02 to 2023-06-09\n",
      "Processing window: 2023-06-09 to 2023-06-16\n",
      "Processing window: 2023-06-16 to 2023-06-23\n",
      "Processing window: 2023-06-23 to 2023-06-30\n",
      "Processing window: 2023-06-30 to 2023-07-07\n",
      "Processing window: 2023-07-07 to 2023-07-14\n",
      "Processing window: 2023-07-14 to 2023-07-21\n",
      "Processing window: 2023-07-21 to 2023-07-28\n",
      "Processing window: 2023-07-28 to 2023-08-04\n",
      "Processing window: 2023-08-04 to 2023-08-11\n",
      "Processing window: 2023-08-11 to 2023-08-18\n",
      "Processing window: 2023-08-18 to 2023-08-25\n",
      "Created 46 temporal snapshots\n"
     ]
    }
   ],
   "source": [
    "snapshots, global_num_nodes = graph_processor.create_temporal_snapshots(df, account_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89fc6783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Data split - Train: 32, Val: 7, Test: 7\n",
      "Epoch 1: Train Loss(x1e3): 4.4093, Val Loss(x1e3): 0.7009, F2: 0.0095, Threshold: 0.100, Recall: 0.2119\n",
      "Epoch 2: Train Loss(x1e3): 0.7657, Val Loss(x1e3): 0.7221, F2: 0.0105, Threshold: 0.100, Recall: 0.0967\n",
      "Epoch 3: Train Loss(x1e3): 0.7218, Val Loss(x1e3): 0.6695, F2: 0.0115, Threshold: 0.150, Recall: 0.0274\n",
      "Epoch 4: Train Loss(x1e3): 0.6963, Val Loss(x1e3): 0.6472, F2: 0.0133, Threshold: 0.150, Recall: 0.0281\n",
      "Epoch 5: Train Loss(x1e3): 0.6780, Val Loss(x1e3): 0.6323, F2: 0.0144, Threshold: 0.100, Recall: 0.2305\n",
      "Epoch 6: Train Loss(x1e3): 0.6583, Val Loss(x1e3): 0.6105, F2: 0.0174, Threshold: 0.150, Recall: 0.0624\n",
      "Epoch 7: Train Loss(x1e3): 0.6379, Val Loss(x1e3): 0.5975, F2: 0.0198, Threshold: 0.100, Recall: 0.5048\n",
      "Epoch 8: Train Loss(x1e3): 0.6213, Val Loss(x1e3): 0.5852, F2: 0.0253, Threshold: 0.150, Recall: 0.1488\n",
      "Epoch 9: Train Loss(x1e3): 0.6141, Val Loss(x1e3): 0.5851, F2: 0.0348, Threshold: 0.200, Recall: 0.0528\n",
      "Epoch 10: Train Loss(x1e3): 0.6009, Val Loss(x1e3): 0.5821, F2: 0.0479, Threshold: 0.200, Recall: 0.0837\n",
      "Epoch 11: Train Loss(x1e3): 0.5898, Val Loss(x1e3): 0.5694, F2: 0.0659, Threshold: 0.200, Recall: 0.1173\n",
      "Epoch 12: Train Loss(x1e3): 0.5751, Val Loss(x1e3): 0.5549, F2: 0.0827, Threshold: 0.200, Recall: 0.1516\n",
      "Epoch 13: Train Loss(x1e3): 0.5620, Val Loss(x1e3): 0.5357, F2: 0.0982, Threshold: 0.200, Recall: 0.1742\n",
      "Epoch 14: Train Loss(x1e3): 0.5442, Val Loss(x1e3): 0.5033, F2: 0.1121, Threshold: 0.200, Recall: 0.1742\n",
      "Epoch 15: Train Loss(x1e3): 0.5270, Val Loss(x1e3): 0.4807, F2: 0.1521, Threshold: 0.200, Recall: 0.2215\n",
      "Epoch 16: Train Loss(x1e3): 0.5145, Val Loss(x1e3): 0.4584, F2: 0.1908, Threshold: 0.200, Recall: 0.2942\n",
      "Epoch 17: Train Loss(x1e3): 0.4842, Val Loss(x1e3): 0.4237, F2: 0.2771, Threshold: 0.200, Recall: 0.3944\n",
      "Epoch 18: Train Loss(x1e3): 0.4476, Val Loss(x1e3): 0.3966, F2: 0.3162, Threshold: 0.250, Recall: 0.3491\n",
      "Epoch 19: Train Loss(x1e3): 0.4255, Val Loss(x1e3): 0.3777, F2: 0.3294, Threshold: 0.250, Recall: 0.3711\n",
      "Epoch 20: Train Loss(x1e3): 0.4017, Val Loss(x1e3): 0.3618, F2: 0.3819, Threshold: 0.250, Recall: 0.4314\n",
      "Epoch 21: Train Loss(x1e3): 0.3820, Val Loss(x1e3): 0.3448, F2: 0.4124, Threshold: 0.250, Recall: 0.4808\n",
      "Epoch 22: Train Loss(x1e3): 0.3807, Val Loss(x1e3): 0.4059, F2: 0.3280, Threshold: 0.250, Recall: 0.3176\n",
      "Epoch 23: Train Loss(x1e3): 0.4092, Val Loss(x1e3): 0.3798, F2: 0.3749, Threshold: 0.250, Recall: 0.3793\n",
      "Epoch 24: Train Loss(x1e3): 0.3904, Val Loss(x1e3): 0.3659, F2: 0.3944, Threshold: 0.250, Recall: 0.4074\n",
      "Epoch 25: Train Loss(x1e3): 0.3783, Val Loss(x1e3): 0.3403, F2: 0.4414, Threshold: 0.250, Recall: 0.4465\n",
      "Epoch 26: Train Loss(x1e3): 0.3582, Val Loss(x1e3): 0.3316, F2: 0.4419, Threshold: 0.250, Recall: 0.4582\n",
      "Epoch 27: Train Loss(x1e3): 0.3419, Val Loss(x1e3): 0.3091, F2: 0.4751, Threshold: 0.250, Recall: 0.5158\n",
      "Epoch 28: Train Loss(x1e3): 0.3253, Val Loss(x1e3): 0.2984, F2: 0.4989, Threshold: 0.250, Recall: 0.5309\n",
      "Epoch 29: Train Loss(x1e3): 0.3155, Val Loss(x1e3): 0.2929, F2: 0.5337, Threshold: 0.250, Recall: 0.5706\n",
      "Epoch 30: Train Loss(x1e3): 0.3097, Val Loss(x1e3): 0.2840, F2: 0.5361, Threshold: 0.250, Recall: 0.5610\n",
      "Epoch 31: Train Loss(x1e3): 0.3003, Val Loss(x1e3): 0.2782, F2: 0.5398, Threshold: 0.250, Recall: 0.5700\n",
      "Epoch 32: Train Loss(x1e3): 0.2945, Val Loss(x1e3): 0.2721, F2: 0.5530, Threshold: 0.250, Recall: 0.5837\n",
      "Epoch 33: Train Loss(x1e3): 0.2944, Val Loss(x1e3): 0.2716, F2: 0.5575, Threshold: 0.300, Recall: 0.5466\n",
      "Epoch 34: Train Loss(x1e3): 0.2942, Val Loss(x1e3): 0.2644, F2: 0.5656, Threshold: 0.300, Recall: 0.5535\n",
      "Epoch 35: Train Loss(x1e3): 0.2838, Val Loss(x1e3): 0.2616, F2: 0.5658, Threshold: 0.300, Recall: 0.5610\n",
      "Epoch 36: Train Loss(x1e3): 0.2767, Val Loss(x1e3): 0.2594, F2: 0.5733, Threshold: 0.300, Recall: 0.5658\n",
      "Epoch 37: Train Loss(x1e3): 0.2683, Val Loss(x1e3): 0.2579, F2: 0.5725, Threshold: 0.300, Recall: 0.5727\n",
      "Epoch 38: Train Loss(x1e3): 0.2626, Val Loss(x1e3): 0.2578, F2: 0.5776, Threshold: 0.350, Recall: 0.5597\n",
      "Epoch 39: Train Loss(x1e3): 0.2592, Val Loss(x1e3): 0.2515, F2: 0.5822, Threshold: 0.300, Recall: 0.5844\n",
      "Epoch 40: Train Loss(x1e3): 0.2736, Val Loss(x1e3): 0.2874, F2: 0.5455, Threshold: 0.350, Recall: 0.5213\n",
      "Epoch 41: Train Loss(x1e3): 0.2783, Val Loss(x1e3): 0.2610, F2: 0.5588, Threshold: 0.300, Recall: 0.5562\n",
      "Epoch 42: Train Loss(x1e3): 0.2628, Val Loss(x1e3): 0.2522, F2: 0.5685, Threshold: 0.300, Recall: 0.5672\n",
      "Epoch 43: Train Loss(x1e3): 0.2599, Val Loss(x1e3): 0.2496, F2: 0.5771, Threshold: 0.300, Recall: 0.5761\n",
      "Epoch 44: Train Loss(x1e3): 0.2546, Val Loss(x1e3): 0.2444, F2: 0.5855, Threshold: 0.300, Recall: 0.5830\n",
      "Epoch 45: Train Loss(x1e3): 0.2494, Val Loss(x1e3): 0.2385, F2: 0.5991, Threshold: 0.350, Recall: 0.5789\n",
      "Epoch 46: Train Loss(x1e3): 0.2475, Val Loss(x1e3): 0.2401, F2: 0.5974, Threshold: 0.300, Recall: 0.5947\n",
      "Epoch 47: Train Loss(x1e3): 0.2433, Val Loss(x1e3): 0.2406, F2: 0.6034, Threshold: 0.350, Recall: 0.5823\n",
      "Epoch 48: Train Loss(x1e3): 0.2415, Val Loss(x1e3): 0.2398, F2: 0.6029, Threshold: 0.350, Recall: 0.5912\n",
      "Epoch 49: Train Loss(x1e3): 0.2405, Val Loss(x1e3): 0.2399, F2: 0.5950, Threshold: 0.350, Recall: 0.5789\n",
      "Epoch 50: Train Loss(x1e3): 0.2373, Val Loss(x1e3): 0.2359, F2: 0.6087, Threshold: 0.350, Recall: 0.5926\n",
      "Epoch 51: Train Loss(x1e3): 0.2345, Val Loss(x1e3): 0.2308, F2: 0.6081, Threshold: 0.400, Recall: 0.5816\n",
      "Epoch 52: Train Loss(x1e3): 0.2324, Val Loss(x1e3): 0.2291, F2: 0.6125, Threshold: 0.350, Recall: 0.5981\n",
      "Epoch 53: Train Loss(x1e3): 0.2310, Val Loss(x1e3): 0.2319, F2: 0.6136, Threshold: 0.350, Recall: 0.6022\n",
      "Epoch 54: Train Loss(x1e3): 0.2300, Val Loss(x1e3): 0.2355, F2: 0.6177, Threshold: 0.350, Recall: 0.6022\n",
      "Epoch 55: Train Loss(x1e3): 0.2291, Val Loss(x1e3): 0.2293, F2: 0.6162, Threshold: 0.350, Recall: 0.6036\n",
      "Epoch 56: Train Loss(x1e3): 0.2247, Val Loss(x1e3): 0.2297, F2: 0.6115, Threshold: 0.350, Recall: 0.6022\n",
      "Epoch 57: Train Loss(x1e3): 0.2251, Val Loss(x1e3): 0.2273, F2: 0.6208, Threshold: 0.350, Recall: 0.6111\n",
      "Epoch 58: Train Loss(x1e3): 0.2229, Val Loss(x1e3): 0.2238, F2: 0.6205, Threshold: 0.350, Recall: 0.6104\n",
      "Epoch 59: Train Loss(x1e3): 0.2203, Val Loss(x1e3): 0.2221, F2: 0.6210, Threshold: 0.350, Recall: 0.6091\n",
      "Epoch 60: Train Loss(x1e3): 0.2180, Val Loss(x1e3): 0.2187, F2: 0.6251, Threshold: 0.350, Recall: 0.6132\n",
      "Epoch 61: Train Loss(x1e3): 0.2192, Val Loss(x1e3): 0.2252, F2: 0.6206, Threshold: 0.350, Recall: 0.6111\n",
      "Epoch 62: Train Loss(x1e3): 0.2185, Val Loss(x1e3): 0.2226, F2: 0.6172, Threshold: 0.350, Recall: 0.6043\n",
      "Epoch 63: Train Loss(x1e3): 0.2190, Val Loss(x1e3): 0.2227, F2: 0.6295, Threshold: 0.350, Recall: 0.6132\n",
      "Epoch 64: Train Loss(x1e3): 0.2176, Val Loss(x1e3): 0.2235, F2: 0.6265, Threshold: 0.350, Recall: 0.6132\n",
      "Epoch 65: Train Loss(x1e3): 0.2177, Val Loss(x1e3): 0.2202, F2: 0.6367, Threshold: 0.350, Recall: 0.6276\n",
      "Epoch 66: Train Loss(x1e3): 0.2236, Val Loss(x1e3): 0.2259, F2: 0.6086, Threshold: 0.350, Recall: 0.6001\n",
      "Epoch 67: Train Loss(x1e3): 0.2222, Val Loss(x1e3): 0.2258, F2: 0.6237, Threshold: 0.350, Recall: 0.6166\n",
      "Epoch 68: Train Loss(x1e3): 0.2140, Val Loss(x1e3): 0.2248, F2: 0.6286, Threshold: 0.350, Recall: 0.6187\n",
      "Epoch 69: Train Loss(x1e3): 0.2149, Val Loss(x1e3): 0.2263, F2: 0.6318, Threshold: 0.350, Recall: 0.6262\n",
      "Epoch 70: Train Loss(x1e3): 0.2128, Val Loss(x1e3): 0.2183, F2: 0.6389, Threshold: 0.350, Recall: 0.6296\n",
      "Epoch 71: Train Loss(x1e3): 0.2110, Val Loss(x1e3): 0.2189, F2: 0.6452, Threshold: 0.350, Recall: 0.6385\n",
      "Epoch 72: Train Loss(x1e3): 0.2139, Val Loss(x1e3): 0.2162, F2: 0.6266, Threshold: 0.350, Recall: 0.6200\n",
      "Epoch 73: Train Loss(x1e3): 0.2112, Val Loss(x1e3): 0.2162, F2: 0.6389, Threshold: 0.400, Recall: 0.6166\n",
      "Epoch 74: Train Loss(x1e3): 0.2090, Val Loss(x1e3): 0.2129, F2: 0.6462, Threshold: 0.350, Recall: 0.6317\n",
      "Epoch 75: Train Loss(x1e3): 0.2071, Val Loss(x1e3): 0.2125, F2: 0.6533, Threshold: 0.350, Recall: 0.6379\n"
     ]
    }
   ],
   "source": [
    "trainer = ModelTrainer(config=Config())\n",
    "results = trainer.train_model(snapshots, global_num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb0d7038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_probs': array([0.02240904, 0.05746069, 0.00258313, ..., 0.02022282, 0.02206192,\n",
       "        0.02818465], shape=(1458820,), dtype=float32),\n",
       " 'val_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1458820,), dtype=float32),\n",
       " 'val_threshold': np.float64(0.35000000000000003),\n",
       " 'val_precision': 0.7231726283048211,\n",
       " 'val_recall': 0.6378600823045267,\n",
       " 'val_f1': 0.6778425655976676,\n",
       " 'val_f2': 0.6532733914020792,\n",
       " 'val_roc_auc': 0.9814942344789399,\n",
       " 'val_pr_auc': 0.6640282609880064,\n",
       " 'test_probs': array([0.00714832, 0.01883016, 0.01000949, ..., 0.07490002, 0.07445404,\n",
       "        0.09573593], shape=(1384809,), dtype=float32),\n",
       " 'test_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1384809,), dtype=float32),\n",
       " 'test_threshold': np.float64(0.3),\n",
       " 'test_precision': 0.6305949008498584,\n",
       " 'test_recall': 0.6782449725776966,\n",
       " 'test_f1': 0.6535525543159131,\n",
       " 'test_f2': 0.6681474366670669,\n",
       " 'test_roc_auc': 0.9805880442296231,\n",
       " 'test_pr_auc': 0.6796962250048807,\n",
       " 'train_loss_history': [0.0044092614225519355,\n",
       "  0.0007656569323444273,\n",
       "  0.0007217868105726666,\n",
       "  0.0006963221630940097,\n",
       "  0.000678003109896963,\n",
       "  0.0006582623173017055,\n",
       "  0.0006378760872394196,\n",
       "  0.0006213415772435837,\n",
       "  0.0006140974919617292,\n",
       "  0.0006009348780935397,\n",
       "  0.0005898430717934389,\n",
       "  0.0005750684949816787,\n",
       "  0.0005620125230052508,\n",
       "  0.0005442159363155952,\n",
       "  0.000527016388332413,\n",
       "  0.0005144582319189794,\n",
       "  0.00048419911672681337,\n",
       "  0.0004476079575397307,\n",
       "  0.0004254637569829356,\n",
       "  0.0004017077008029446,\n",
       "  0.0003819779922196176,\n",
       "  0.0003806691011050134,\n",
       "  0.00040916137731983326,\n",
       "  0.0003903631832145038,\n",
       "  0.000378286354134616,\n",
       "  0.00035822698919218965,\n",
       "  0.0003418949918341241,\n",
       "  0.00032534655474592,\n",
       "  0.0003154709165755776,\n",
       "  0.00030972368722359533,\n",
       "  0.00030031431197130587,\n",
       "  0.00029445143172779353,\n",
       "  0.000294387695248588,\n",
       "  0.0002941940251730557,\n",
       "  0.0002838456957761082,\n",
       "  0.0002766571333268075,\n",
       "  0.0002682829922378005,\n",
       "  0.00026258099842380034,\n",
       "  0.00025919807512764237,\n",
       "  0.00027361226830180385,\n",
       "  0.0002782566698442679,\n",
       "  0.00026277978486177744,\n",
       "  0.000259933666256984,\n",
       "  0.000254551333910058,\n",
       "  0.0002494148875484825,\n",
       "  0.00024747100042077363,\n",
       "  0.00024333529972864198,\n",
       "  0.00024148966622306034,\n",
       "  0.00024053401830315124,\n",
       "  0.00023734336036795867,\n",
       "  0.0002345302218600409,\n",
       "  0.00023240419477588148,\n",
       "  0.00023104987121769227,\n",
       "  0.0002299636512361758,\n",
       "  0.00022905313153387397,\n",
       "  0.00022468651695817243,\n",
       "  0.000225091767788399,\n",
       "  0.00022289009257292491,\n",
       "  0.0002203403901148704,\n",
       "  0.00021803525942232227,\n",
       "  0.00021922123505646596,\n",
       "  0.00021853301586816087,\n",
       "  0.00021903215565544087,\n",
       "  0.00021756669366368442,\n",
       "  0.00021770649209429394,\n",
       "  0.00022361820219884976,\n",
       "  0.00022219467246031854,\n",
       "  0.00021396099418780068,\n",
       "  0.00021491822872121702,\n",
       "  0.0002127999559888849,\n",
       "  0.0002110266727868293,\n",
       "  0.00021386361640907126,\n",
       "  0.00021119527491464396,\n",
       "  0.00020904088160023093,\n",
       "  0.0002071392163998098],\n",
       " 'val_loss_history': [0.0007008931050742311,\n",
       "  0.0007221084503856089,\n",
       "  0.0006694575256135847,\n",
       "  0.0006472126198267299,\n",
       "  0.0006323214620351791,\n",
       "  0.0006104831034982843,\n",
       "  0.0005974764436749476,\n",
       "  0.0005851768988317677,\n",
       "  0.0005850725574418902,\n",
       "  0.0005821418308187276,\n",
       "  0.0005694331692731274,\n",
       "  0.0005549240616216723,\n",
       "  0.0005357351993942368,\n",
       "  0.0005033091500601066,\n",
       "  0.0004807173474026578,\n",
       "  0.0004583827602410955,\n",
       "  0.0004237487113901547,\n",
       "  0.0003965650227785643,\n",
       "  0.00037767710663112145,\n",
       "  0.0003617970089960311,\n",
       "  0.0003448112027919186,\n",
       "  0.0004059060011059046,\n",
       "  0.00037979518778489104,\n",
       "  0.0003658591345551291,\n",
       "  0.00034034959805597154,\n",
       "  0.0003316461931847568,\n",
       "  0.00030911613222477693,\n",
       "  0.00029840556713419834,\n",
       "  0.0002929394748727126,\n",
       "  0.00028400151807415696,\n",
       "  0.0002781977423832619,\n",
       "  0.00027205456405811546,\n",
       "  0.00027156989173298437,\n",
       "  0.0002644445651510198,\n",
       "  0.00026159795691325726,\n",
       "  0.00025938008911907673,\n",
       "  0.00025788001325314065,\n",
       "  0.00025775289603708576,\n",
       "  0.0002515459907174643,\n",
       "  0.0002874070840854464,\n",
       "  0.00026104891730938107,\n",
       "  0.00025222972284869423,\n",
       "  0.00024962704420821477,\n",
       "  0.00024444045681905536,\n",
       "  0.00023852623209157691,\n",
       "  0.00024008255110987063,\n",
       "  0.00024063538252708634,\n",
       "  0.00023979662052754845,\n",
       "  0.00023990151696904962,\n",
       "  0.00023594231918520694,\n",
       "  0.00023084852728061378,\n",
       "  0.0002291428972966969,\n",
       "  0.00023193903949244747,\n",
       "  0.00023546600589595203,\n",
       "  0.00022926230199768076,\n",
       "  0.0002296800708531269,\n",
       "  0.00022728172396974905,\n",
       "  0.00022377384136364396,\n",
       "  0.00022213978809304535,\n",
       "  0.0002187199632836772,\n",
       "  0.0002251532402754362,\n",
       "  0.00022261306211086257,\n",
       "  0.00022268972367913063,\n",
       "  0.00022351902485492507,\n",
       "  0.00022024145541113934,\n",
       "  0.0002259177085111982,\n",
       "  0.0002258454728040046,\n",
       "  0.00022476266063417176,\n",
       "  0.00022627026191912591,\n",
       "  0.0002183118589787877,\n",
       "  0.00021885174334914024,\n",
       "  0.00021619997901975045,\n",
       "  0.00021620793683853532,\n",
       "  0.00021285771591854946,\n",
       "  0.00021254310143246715],\n",
       " 'f2_history': [0.009497172362921072,\n",
       "  0.010513443786629285,\n",
       "  0.011542679055808852,\n",
       "  0.013260025873221216,\n",
       "  0.014366587422394774,\n",
       "  0.017388313524668474,\n",
       "  0.019784733497489274,\n",
       "  0.025337443370230254,\n",
       "  0.03483217226092464,\n",
       "  0.04794466713825356,\n",
       "  0.06591627476678745,\n",
       "  0.08274674254904897,\n",
       "  0.09819840717544266,\n",
       "  0.11210168593874129,\n",
       "  0.15212886209495102,\n",
       "  0.19081932212436617,\n",
       "  0.27713514555619817,\n",
       "  0.31618834637843213,\n",
       "  0.32935589918422015,\n",
       "  0.381906496660595,\n",
       "  0.4124014589951759,\n",
       "  0.32795013457996885,\n",
       "  0.3749152542372881,\n",
       "  0.3944223107569721,\n",
       "  0.4414157851912124,\n",
       "  0.4419158507541678,\n",
       "  0.475107404599444,\n",
       "  0.4989042155472476,\n",
       "  0.5337439055683859,\n",
       "  0.536112203434264,\n",
       "  0.5397505845674201,\n",
       "  0.5530283337665713,\n",
       "  0.5574986010072748,\n",
       "  0.5656013456686291,\n",
       "  0.5657767326047862,\n",
       "  0.5733148019457956,\n",
       "  0.5724667489373372,\n",
       "  0.5775764439411099,\n",
       "  0.5822058220582206,\n",
       "  0.5455067470571346,\n",
       "  0.5588478500551268,\n",
       "  0.56846301897168,\n",
       "  0.5770816158285244,\n",
       "  0.585480093676815,\n",
       "  0.599091425326519,\n",
       "  0.597354278627532,\n",
       "  0.603411513859275,\n",
       "  0.6028815218911736,\n",
       "  0.5950366610265088,\n",
       "  0.6087079047484852,\n",
       "  0.6081468732071141,\n",
       "  0.6125316100028098,\n",
       "  0.6135569531795947,\n",
       "  0.6177008583087097,\n",
       "  0.6161602016524297,\n",
       "  0.611505780749408,\n",
       "  0.620819397993311,\n",
       "  0.620468488566648,\n",
       "  0.620979020979021,\n",
       "  0.6250874003635856,\n",
       "  0.6206464196154918,\n",
       "  0.6172061090093877,\n",
       "  0.6294888043937473,\n",
       "  0.626489138051857,\n",
       "  0.6366546061786807,\n",
       "  0.6085686465433301,\n",
       "  0.6236991813514638,\n",
       "  0.6285714285714286,\n",
       "  0.6318339100346021,\n",
       "  0.6389198218262806,\n",
       "  0.6451836451836452,\n",
       "  0.6266463330098433,\n",
       "  0.638857305287095,\n",
       "  0.646225091215268,\n",
       "  0.6532733914020792],\n",
       " 'model': TemporalEdgeClassifier(\n",
       "   (node_encoder): Sequential(\n",
       "     (0): Linear(in_features=15, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "   )\n",
       "   (gnn1): GATConv(256, 256, heads=4)\n",
       "   (gnn2): GATConv(256, 256, heads=2)\n",
       "   (gnn3): GATConv(256, 256, heads=2)\n",
       "   (dropout): Dropout(p=0.3, inplace=False)\n",
       "   (classifier): Sequential(\n",
       "     (0): Linear(in_features=265, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Dropout(p=0.3, inplace=False)\n",
       "     (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "     (4): ReLU()\n",
       "     (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82e25fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Function to compute and print confusion matrix\n",
    "def compute_confusion_matrix(labels, preds, threshold=0.5):\n",
    "\n",
    "    # Convert probabilities to binary predictions using the threshold\n",
    "    binary_preds = (preds >= threshold).astype(int)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(labels, binary_preds)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Optional: Extract and print TP, TN, FP, FN\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"False Negatives (FN): {fn}\")\n",
    "    print(f\"True Positives (TP): {tp}\")\n",
    "    print(f\"Precision: {tp / (tp + fp + 1e-8):.4f}\")\n",
    "    print(f\"Recall: {tp / (tp + fn + 1e-8):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51d19dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = results['test_probs']\n",
    "test_labels = results['test_labels']\n",
    "val_probs = results['val_probs']\n",
    "val_labels = results['val_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f1f36ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1454341    3021]\n",
      " [    424    1034]]\n",
      "True Negatives (TN): 1454341\n",
      "False Positives (FP): 3021\n",
      "False Negatives (FN): 424\n",
      "True Positives (TP): 1034\n",
      "Precision: 0.2550\n",
      "Recall: 0.7092\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(val_labels, val_probs, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c31c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1380272    2896]\n",
      " [    452    1189]]\n",
      "True Negatives (TN): 1380272\n",
      "False Positives (FP): 2896\n",
      "False Negatives (FN): 452\n",
      "True Positives (TP): 1189\n",
      "Precision: 0.2911\n",
      "Recall: 0.7246\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(test_labels, test_probs, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b1255f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC Score: 0.6797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate PR curve data\n",
    "precision, recall, thresholds = precision_recall_curve(test_labels, test_probs)\n",
    "pr_auc = average_precision_score(test_labels, test_probs)\n",
    "\n",
    "# Plot PR curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, linewidth=2, label=f'PR AUC = {pr_auc:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"PR AUC Score: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae20c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fastai-backup]",
   "language": "python",
   "name": "conda-env-.conda-fastai-backup-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
