{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83228cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Improved Temporal Graph Neural Network for Anti-Money Laundering Detection\n",
    "==========================================================================\n",
    "Optimized for F2 Score with structured code organization\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (precision_recall_curve, roc_auc_score, f1_score, \n",
    "                           precision_score, recall_score, fbeta_score, \n",
    "                           confusion_matrix, average_precision_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74ecce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent.parent))  # Adjust as needed\n",
    "from config import DATAPATH, SAMPLE_DATAPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ddba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f457192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration class for hyperparameters and settings\"\"\"\n",
    "    # Model architecture\n",
    "    HIDDEN_DIM = 128  # Increased from 128\n",
    "    NODE_DIM = 15\n",
    "    EDGE_DIM = 9\n",
    "    DROPOUT_RATE = 0.3\n",
    "    \n",
    "    # Training parameters\n",
    "    LEARNING_RATE = 0.0005  \n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    EPOCHS = 100\n",
    "    PATIENCE = 10  # Early stopping patience\n",
    "    \n",
    "    # F2 score optimization\n",
    "    BETA = 2  # For F2 score (emphasizes recall)\n",
    "    CLASS_WEIGHT_MULTIPLIER = 10  # Strong emphasis on minority class\n",
    "\n",
    "    # Criterion parameters\n",
    "    FOCAL_LOSS_ALPHA = 0.25\n",
    "    FOCAL_LOSS_GAMMA = 2.0\n",
    "    \n",
    "    # Data processing\n",
    "    TIME_WINDOW = '7D'\n",
    "    VALIDATION_SPLIT = 0.17\n",
    "    TEST_SPLIT = 0.13\n",
    "    \n",
    "    # Threshold optimization\n",
    "    THRESHOLD_SEARCH_RANGE = np.arange(0.05, 0.95, 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc23495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "\n",
    "def detailed_memory_profile():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "        \n",
    "        # Show memory summary\n",
    "        # print(torch.cuda.memory_summary())\n",
    "        return allocated, cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0671bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for addressing class imbalance - better than BCE for F2 optimization\"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08365f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGraphDataProcessor:\n",
    "    \"\"\"Enhanced data processor with better feature engineering for F2 optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, time_window='7D'):\n",
    "        self.time_window = time_window\n",
    "        self.scalers = {}\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_and_preprocess(self, df):\n",
    "        \"\"\"Load SAML-D dataset and perform initial preprocessing\"\"\"\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        \n",
    "        # Combine date and time into datetime\n",
    "        df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "        df = df.sort_values('datetime').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Loaded {len(df)} transactions\")\n",
    "        print(f\"Suspicious transactions: {df['Is_laundering'].sum()} ({df['Is_laundering'].mean()*100:.3f}%)\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def engineer_features(self, df):\n",
    "        \"\"\"Enhanced feature engineering for better detection\"\"\"\n",
    "        print(\"Engineering enhanced features...\")\n",
    "        \n",
    "        # Time-based features (more granular)\n",
    "        df['hour'] = df['datetime'].dt.hour.astype('int8')\n",
    "        df['month'] = df['datetime'].dt.month.astype('int8')\n",
    "        df['day_of_week'] = df['datetime'].dt.dayofweek.astype('int8')\n",
    "        df['day_of_month'] = df['datetime'].dt.day.astype('int8')\n",
    "        df['is_weekend'] = (df['day_of_week'] >= 5).astype('int8')\n",
    "        df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 5)).astype('int8')  # Night transactions\n",
    "        \n",
    "        # Amount-based features\n",
    "        df['log_amount'] = np.log1p(df['Amount']).astype('float32')\n",
    "        \n",
    "        # Calculate amount percentiles for anomaly detection\n",
    "        # amount_percentiles = df['Amount'].quantile([0.95, 0.99]).values\n",
    "        # df['high_amount'] = (df['Amount'] > amount_percentiles[0]).astype('int8')\n",
    "        # df['very_high_amount'] = (df['Amount'] > amount_percentiles[1]).astype('int8')\n",
    "        \n",
    "        # Geographic risk features\n",
    "        df['cross_border'] = (df['Payment_type'] == 'Cross-border').astype('int8')\n",
    "        risky_countries = {'Mexico', 'Turkey', 'Morocco', 'UAE'}\n",
    "        df['high_risk_sender'] = df['Sender_bank_location'].isin(risky_countries).astype('int8')\n",
    "        df['high_risk_receiver'] = df['Receiver_bank_location'].isin(risky_countries).astype('int8')\n",
    "        # df['both_high_risk'] = (df['high_risk_sender'] & df['high_risk_receiver']).astype('int8')\n",
    "        \n",
    "        # Currency features\n",
    "        df['currency_mismatch'] = (df['Payment_currency'] != df['Received_currency']).astype('int8')\n",
    "        \n",
    "        # Convert target\n",
    "        df['Is_laundering'] = df['Is_laundering'].astype('int8')\n",
    "        \n",
    "        # Clean up\n",
    "        columns_to_drop = ['Date', 'Time', 'Amount', 'Sender_bank_location', \n",
    "                          'Receiver_bank_location', 'Payment_currency', 'Received_currency', \n",
    "                          'Laundering_type']\n",
    "        df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_temporal_snapshots(self, df, account_features):\n",
    "        \"\"\"Create temporal graph snapshots with enhanced features\"\"\"\n",
    "        print(\"Creating temporal graph snapshots...\")\n",
    "        \n",
    "        # Global account mapping\n",
    "        all_accounts = list(set(df['Sender_account'].unique()) | set(df['Receiver_account'].unique()))\n",
    "        global_account_to_idx = {acc: idx for idx, acc in enumerate(all_accounts)}\n",
    "        global_num_nodes = len(all_accounts)\n",
    "        \n",
    "        # Time windows\n",
    "        start_date = df['datetime'].min().normalize().date()\n",
    "        end_date = df['datetime'].max().normalize().date()\n",
    "        \n",
    "        snapshots = []\n",
    "        print(f\"Processing time range: {start_date} to {end_date}\")\n",
    "\n",
    "        for window_start in pd.date_range(start=start_date, end=end_date, freq=self.time_window, inclusive='left'):\n",
    "            window_end = window_start + pd.Timedelta(days=7)\n",
    "            window_start_str = pd.to_datetime(window_start).strftime('%Y-%m-%d')\n",
    "            window_end_str = pd.to_datetime(window_end).strftime('%Y-%m-%d')\n",
    "            print(f\"Processing window: {window_start_str} to {window_end_str}\")\n",
    "            \n",
    "            # Get transactions in current window\n",
    "            window_mask = (df['datetime'] >= window_start_str) & (df['datetime'] < window_end_str)\n",
    "            window_trnx_data = df[window_mask].copy()\n",
    "            \n",
    "            # Account features for this window\n",
    "            window_accounts_features = account_features[account_features['window_start'] == window_start_str]\n",
    "            \n",
    "            if len(window_trnx_data) > 0:\n",
    "                graph_data = self._create_graph_snapshot(\n",
    "                    window_trnx_data, window_accounts_features,\n",
    "                    window_start_str, global_account_to_idx, global_num_nodes\n",
    "                )\n",
    "                if graph_data is not None:\n",
    "                    snapshots.append(graph_data)\n",
    "\n",
    "        print(f\"Created {len(snapshots)} temporal snapshots\")\n",
    "        return snapshots, global_num_nodes\n",
    "\n",
    "    def _create_graph_snapshot(self, window_trnx_data, window_accounts_features, \n",
    "                              timestamp, global_account_to_idx, global_num_nodes):\n",
    "        \"\"\"Create enhanced graph snapshot\"\"\"\n",
    "        if len(window_trnx_data) == 0:\n",
    "            return None\n",
    "\n",
    "        # Enhanced edge features\n",
    "        edge_feature_columns = [\n",
    "            'Payment_type_encoded', 'log_amount', 'month', 'day_of_week', 'hour', \n",
    "            'currency_mismatch', 'cross_border', 'high_risk_sender', 'high_risk_receiver',\n",
    "        ]\n",
    "        \n",
    "        # Filter available columns\n",
    "        edge_feature_columns = [col for col in edge_feature_columns if col in window_trnx_data.columns]\n",
    "\n",
    "        # Node features\n",
    "        node_feature_columns = ['sent_txns_count', 'fan_out', 'recv_txns_count', 'fan_in', \n",
    "                               'max_sent_txn_count', 'max_recv_txn_count', 'sent_recv_ratio', \n",
    "                               'fanout_fanin_ratio', 'log_med_sent_amt', 'log_std_sent_amt', \n",
    "                               'log_med_recv_amt', 'log_std_recv_amt', 'log_max_sent_txn_amt', \n",
    "                               'log_max_recv_txn_amt', 'log_total_txns_amt']\n",
    "\n",
    "        # Create mappings and features\n",
    "        sender_mapped = window_trnx_data['Sender_account'].map(global_account_to_idx)\n",
    "        receiver_mapped = window_trnx_data['Receiver_account'].map(global_account_to_idx)\n",
    "        edge_index = np.column_stack((sender_mapped, receiver_mapped))\n",
    "        edge_features = window_trnx_data[edge_feature_columns].values\n",
    "        transaction_labels = window_trnx_data['Is_laundering'].values\n",
    "\n",
    "        # Node features\n",
    "        node_features = np.zeros((global_num_nodes, len(node_feature_columns)))\n",
    "        try:\n",
    "            window_accounts_features['global_idx'] = window_accounts_features['account'].map(global_account_to_idx)\n",
    "            node_features[window_accounts_features['global_idx'].values] = window_accounts_features[node_feature_columns].values\n",
    "        except: \n",
    "            raise ValueError(\"Error in mapping account features to global indices.\")\n",
    "\n",
    "        # Convert to tensors\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "        edge_features = torch.tensor(edge_features, dtype=torch.float)\n",
    "        transaction_labels = torch.tensor(transaction_labels, dtype=torch.float)\n",
    "\n",
    "        return Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_features,\n",
    "            y=transaction_labels,\n",
    "            timestamp=timestamp,\n",
    "            num_nodes=global_num_nodes\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e55e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal GNN Model for Edge Classification\n",
    "class TemporalEdgeClassifier(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, dropout_rate):\n",
    "        super(TemporalEdgeClassifier, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.GRUCell(node_dim, hidden_dim)\n",
    "        self.gnn1 = SAGEConv(hidden_dim, hidden_dim, aggr='mean')\n",
    "        self.gnn2 = SAGEConv(hidden_dim, hidden_dim, aggr='mean')\n",
    "        self.gnn3 = SAGEConv(hidden_dim, hidden_dim, aggr='mean')\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        # Improved classifier architecture\n",
    "        # self.classifier = nn.Linear(hidden_dim * 2 + edge_dim, 1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 3, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(edge_dim, hidden_dim),  # Project to hidden_dim\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),  # Normalize\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim)  # Second layer for non-linearity\n",
    "        )\n",
    "\n",
    "    def forward(self, data, h):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        \n",
    "        # Update node hidden states with RNN (using current x)\n",
    "        h = self.rnn(x, h)\n",
    "        \n",
    "        # Apply GNN layers\n",
    "        h = F.relu(self.gnn1(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.gnn2(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.gnn3(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        # Process edge_attr\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "\n",
    "        # Edge features: concat sender h, receiver h, edge_attr\n",
    "        h_i = h[edge_index[0]]\n",
    "        h_j = h[edge_index[1]]\n",
    "        edge_input = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
    "        \n",
    "        # Prediction\n",
    "        out = self.classifier(edge_input)\n",
    "        \n",
    "        return out, h  # Return logits and updated h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59dd2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"Enhanced trainer class optimized for F2 score\"\"\"\n",
    "    \n",
    "    def __init__(self, config=Config(), mem_profile=False):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        self.mem_profile = mem_profile\n",
    "\n",
    "    def find_optimal_threshold(self, probs, labels):\n",
    "        \"\"\"Find optimal threshold for F2 score\"\"\"\n",
    "        best_f2 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in self.config.THRESHOLD_SEARCH_RANGE:\n",
    "            preds = (probs >= threshold).astype(int)\n",
    "            f2 = fbeta_score(labels, preds, beta=self.config.BETA, average='binary', zero_division=0)\n",
    "            if f2 > best_f2:\n",
    "                best_f2 = f2\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        return best_threshold, best_f2\n",
    "    \n",
    "    def compute_class_weights(self, snapshots):\n",
    "        \"\"\"Compute class weights for focal loss\"\"\"\n",
    "        all_labels = []\n",
    "        for snap in snapshots:\n",
    "            all_labels.extend(snap.y.cpu().numpy())\n",
    "        \n",
    "        all_labels = np.array(all_labels)\n",
    "        pos_weight = len(all_labels) / (2 * np.sum(all_labels))\n",
    "        return torch.tensor(pos_weight, dtype=torch.float).to(self.device)\n",
    "    \n",
    "    def train_model(self, snapshots, global_num_nodes):\n",
    "        \"\"\"Enhanced training with F2 optimization\"\"\"\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(len(snapshots) * (1 - self.config.VALIDATION_SPLIT - self.config.TEST_SPLIT))\n",
    "        val_size = int(len(snapshots) * self.config.VALIDATION_SPLIT)\n",
    "        \n",
    "        train_snaps = snapshots[:train_size]\n",
    "        val_snaps = snapshots[train_size:train_size + val_size]\n",
    "        test_snaps = snapshots[train_size + val_size:]\n",
    "        \n",
    "        print(f\"Data split - Train: {len(train_snaps)}, Val: {len(val_snaps)}, Test: {len(test_snaps)}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = TemporalEdgeClassifier(\n",
    "            self.config.NODE_DIM, \n",
    "            self.config.EDGE_DIM, \n",
    "            self.config.HIDDEN_DIM,\n",
    "            self.config.DROPOUT_RATE\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Compute class weights for focal loss\n",
    "        pos_weight = self.compute_class_weights(train_snaps)\n",
    "        criterion = FocalLoss(alpha=self.config.FOCAL_LOSS_ALPHA, gamma=self.config.FOCAL_LOSS_GAMMA)\n",
    "        \n",
    "        # Optimizer with different learning rates for different components\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': model.rnn.parameters(), 'lr': self.config.LEARNING_RATE * 0.5},\n",
    "            {'params': model.gnn1.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.gnn2.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.gnn3.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.edge_encoder.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.classifier.parameters(), 'lr': self.config.LEARNING_RATE * 1.5}\n",
    "        ], weight_decay=self.config.WEIGHT_DECAY)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    "        )\n",
    "        \n",
    "        # Training loop\n",
    "        best_f2_score = 0\n",
    "        patience_counter = 0\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "        f2_history = []\n",
    "        \n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "\n",
    "            if self.mem_profile:\n",
    "                print(f\"=== EPOCH {epoch} START ===\")\n",
    "                epoch_start_mem = detailed_memory_profile()\n",
    "                print(f\"Epoch Mem Allocated: {epoch_start_mem[0]:.3f} GB, Cached: {epoch_start_mem[0]:.3f} GB\")\n",
    "\n",
    "            for i, snap in enumerate(train_snaps):\n",
    "                if (i < 5) and self.mem_profile:\n",
    "                    print(f\"--- Snapshot {i} ---\")\n",
    "                    pre_snap = detailed_memory_profile()\n",
    "                    print(f\"Pre snap Allocated: {pre_snap[0]:.3f} GB, Cached: {pre_snap[0]:.3f} GB\")\n",
    "                \n",
    "                snap = snap.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                out, h = model(snap, h.detach())  # Detach to prevent gradient explosion\n",
    "                loss = criterion(out.squeeze(), snap.y)\n",
    "\n",
    "                if (i < 5) and self.mem_profile:\n",
    "                    post_forward = detailed_memory_profile()\n",
    "                    print(f\"Forward Mem Allocated: {post_forward[0]}, Cached: {post_forward[1]:.3f}GB cached\")\n",
    "                    print(f\"Forward pass added: {post_forward[1] - pre_snap[1]:.3f}GB cached\")\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "                optimizer.step()\n",
    "\n",
    "                if (i < 5) and self.mem_profile:\n",
    "                    post_backward = detailed_memory_profile()\n",
    "                    print(f\"Forward Mem Allocated: {post_backward[0]}, Cached: {post_backward[1]:.3f}GB cached\")\n",
    "                    print(f\"Backward pass added: {post_backward[1] - post_forward[1]:.3f}GB cached\")\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_snaps)\n",
    "            train_loss_history.append(avg_train_loss)\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_probs_list, val_labels_list = [], []\n",
    "            val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "                for snap in val_snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, h = model(snap, h)\n",
    "                    loss = criterion(out.squeeze(), snap.y)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    preds = torch.sigmoid(out).squeeze()\n",
    "                    val_probs_list.append(preds.cpu())\n",
    "                    val_labels_list.append(snap.y.cpu())\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_snaps)\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "            \n",
    "            # Calculate F2 score with optimal threshold\n",
    "            val_probs = torch.cat(val_probs_list).numpy()\n",
    "            val_labels = torch.cat(val_labels_list).numpy()\n",
    "            \n",
    "            optimal_threshold, f2_score = self.find_optimal_threshold(val_probs, val_labels)\n",
    "            f2_history.append(f2_score)\n",
    "            recall = recall_score(val_labels, (val_probs >= optimal_threshold).astype(int), zero_division=0)\n",
    "            \n",
    "            # Update scheduler with F2 score\n",
    "            # scheduler.step(f2_score)\n",
    "            scheduler.step(avg_val_loss)\n",
    "            \n",
    "            # Early stopping based on F2 score\n",
    "            if f2_score > best_f2_score:\n",
    "                best_f2_score = f2_score\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                # torch.save(model.state_dict(), './outputs/best_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # if (epoch + 1) % 10 == 0:\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"Epoch {epoch+1}: Train Loss(x1e3): {1000*avg_train_loss:.4f}, Val Loss(x1e3): {1000*avg_val_loss:.4f}, \"\n",
    "                        f\"F2: {f2_score:.4f}, Threshold: {optimal_threshold:.3f}, Recall: {recall:.4f}, \"\n",
    "                        f\"LR: {current_lr:.6f}\")\n",
    "\n",
    "            if patience_counter >= self.config.PATIENCE:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # Load best model and evaluate\n",
    "        # model.load_state_dict(torch.load('./outputs/best_model.pth'))\n",
    "        \n",
    "        # Final evaluation\n",
    "        results = self._evaluate_model(model, train_snaps, val_snaps, test_snaps, global_num_nodes)\n",
    "        results.update({\n",
    "            'train_loss_history': train_loss_history,\n",
    "            'val_loss_history': val_loss_history,\n",
    "            'f2_history': f2_history,\n",
    "            'model': model\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_model(self, model, train_snaps, val_snaps, test_snaps, global_num_nodes):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        model.eval()\n",
    "        results = {}\n",
    "        \n",
    "        for split_name, snaps in [('val', val_snaps), ('test', test_snaps)]:\n",
    "            probs_list, labels_list = [], []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "                for snap in snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, h = model(snap, h)\n",
    "                    preds = torch.sigmoid(out).squeeze().cpu().numpy()\n",
    "                    probs_list.extend(preds)\n",
    "                    labels_list.extend(snap.y.cpu().numpy())\n",
    "            \n",
    "            probs = np.array(probs_list)\n",
    "            labels = np.array(labels_list)\n",
    "            \n",
    "            # Find optimal threshold\n",
    "            optimal_threshold, best_f2 = self.find_optimal_threshold(probs, labels)\n",
    "            binary_preds = (probs >= optimal_threshold).astype(int)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            precision = precision_score(labels, binary_preds, zero_division=0)\n",
    "            recall = recall_score(labels, binary_preds, zero_division=0)\n",
    "            f1 = f1_score(labels, binary_preds, zero_division=0)\n",
    "            roc_auc = roc_auc_score(labels, probs)\n",
    "            pr_auc = average_precision_score(labels, probs)\n",
    "            \n",
    "            results[f'{split_name}_probs'] = probs\n",
    "            results[f'{split_name}_labels'] = labels\n",
    "            results[f'{split_name}_threshold'] = optimal_threshold\n",
    "            results[f'{split_name}_precision'] = precision\n",
    "            results[f'{split_name}_recall'] = recall\n",
    "            results[f'{split_name}_f1'] = f1\n",
    "            results[f'{split_name}_f2'] = best_f2\n",
    "            results[f'{split_name}_roc_auc'] = roc_auc\n",
    "            results[f'{split_name}_pr_auc'] = pr_auc\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2124555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset\n",
    "df = pd.read_csv(DATAPATH)\n",
    "\n",
    "# Filter by data range\n",
    "# df = df[df['Date'] < '2023-08-18']\n",
    "# df = df.head(300000).copy()\n",
    "\n",
    "# run feature engg.ipynb to get the account_stats_7D.csv\n",
    "account_stats = pd.read_csv('../account_stats_7D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9178de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Loaded 9504852 transactions\n",
      "Suspicious transactions: 9873 (0.104%)\n",
      "Engineering enhanced features...\n"
     ]
    }
   ],
   "source": [
    "graph_processor = TemporalGraphDataProcessor()\n",
    "df = graph_processor.load_and_preprocess(df)\n",
    "df = graph_processor.engineer_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8bfb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For each categorical column\n",
    "# categorical_cols = ['Payment_currency', 'Received_currency', 'Sender_bank_location', \n",
    "#                    'Receiver_bank_location', 'Payment_type']\n",
    "categorical_cols = ['Payment_type']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "# Drop original object columns\n",
    "df = df.drop(categorical_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43c740f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process accont_stats\n",
    "columns = ['med_sent_amt', 'std_sent_amt', 'med_recv_amt', 'std_recv_amt', \n",
    "           'max_sent_txn_amt', 'max_recv_txn_amt', 'total_txns_amt']\n",
    "\n",
    "for col in columns:\n",
    "    account_stats['log_' + col] = np.log1p(account_stats[col]).astype('float32')\n",
    "\n",
    "account_stats = account_stats.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "094d1677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data types to optimize memory\n",
    "account_stats = account_stats.astype({\n",
    "    'sent_txns_count': 'int32',\n",
    "    'recv_txns_count': 'int32',\n",
    "    'fan_out': 'int32',\n",
    "    'fan_in': 'int32',\n",
    "    'max_sent_txn_count': 'int32',\n",
    "    'max_recv_txn_count': 'int32',\n",
    "    'sent_recv_ratio': 'float32',\n",
    "    'fanout_fanin_ratio': 'float32'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79bf8e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporal graph snapshots...\n",
      "Processing time range: 2022-10-07 to 2023-08-23\n",
      "Processing window: 2022-10-07 to 2022-10-14\n",
      "Processing window: 2022-10-14 to 2022-10-21\n",
      "Processing window: 2022-10-21 to 2022-10-28\n",
      "Processing window: 2022-10-28 to 2022-11-04\n",
      "Processing window: 2022-11-04 to 2022-11-11\n",
      "Processing window: 2022-11-11 to 2022-11-18\n",
      "Processing window: 2022-11-18 to 2022-11-25\n",
      "Processing window: 2022-11-25 to 2022-12-02\n",
      "Processing window: 2022-12-02 to 2022-12-09\n",
      "Processing window: 2022-12-09 to 2022-12-16\n",
      "Processing window: 2022-12-16 to 2022-12-23\n",
      "Processing window: 2022-12-23 to 2022-12-30\n",
      "Processing window: 2022-12-30 to 2023-01-06\n",
      "Processing window: 2023-01-06 to 2023-01-13\n",
      "Processing window: 2023-01-13 to 2023-01-20\n",
      "Processing window: 2023-01-20 to 2023-01-27\n",
      "Processing window: 2023-01-27 to 2023-02-03\n",
      "Processing window: 2023-02-03 to 2023-02-10\n",
      "Processing window: 2023-02-10 to 2023-02-17\n",
      "Processing window: 2023-02-17 to 2023-02-24\n",
      "Processing window: 2023-02-24 to 2023-03-03\n",
      "Processing window: 2023-03-03 to 2023-03-10\n",
      "Processing window: 2023-03-10 to 2023-03-17\n",
      "Processing window: 2023-03-17 to 2023-03-24\n",
      "Processing window: 2023-03-24 to 2023-03-31\n",
      "Processing window: 2023-03-31 to 2023-04-07\n",
      "Processing window: 2023-04-07 to 2023-04-14\n",
      "Processing window: 2023-04-14 to 2023-04-21\n",
      "Processing window: 2023-04-21 to 2023-04-28\n",
      "Processing window: 2023-04-28 to 2023-05-05\n",
      "Processing window: 2023-05-05 to 2023-05-12\n",
      "Processing window: 2023-05-12 to 2023-05-19\n",
      "Processing window: 2023-05-19 to 2023-05-26\n",
      "Processing window: 2023-05-26 to 2023-06-02\n",
      "Processing window: 2023-06-02 to 2023-06-09\n",
      "Processing window: 2023-06-09 to 2023-06-16\n",
      "Processing window: 2023-06-16 to 2023-06-23\n",
      "Processing window: 2023-06-23 to 2023-06-30\n",
      "Processing window: 2023-06-30 to 2023-07-07\n",
      "Processing window: 2023-07-07 to 2023-07-14\n",
      "Processing window: 2023-07-14 to 2023-07-21\n",
      "Processing window: 2023-07-21 to 2023-07-28\n",
      "Processing window: 2023-07-28 to 2023-08-04\n",
      "Processing window: 2023-08-04 to 2023-08-11\n",
      "Processing window: 2023-08-11 to 2023-08-18\n",
      "Processing window: 2023-08-18 to 2023-08-25\n",
      "Created 46 temporal snapshots\n"
     ]
    }
   ],
   "source": [
    "snapshots, global_num_nodes = graph_processor.create_temporal_snapshots(df, account_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a083f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory - Allocated: 0.00GB, Cached: 0.00GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89fc6783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Data split - Train: 32, Val: 7, Test: 7\n",
      "Epoch 1: Train Loss(x1e3): 7.8602, Val Loss(x1e3): 1.3010, F2: 0.0000, Threshold: 0.500, Recall: 0.0000, LR: 0.000250\n",
      "Epoch 2: Train Loss(x1e3): 0.8320, Val Loss(x1e3): 0.6580, F2: 0.0160, Threshold: 0.150, Recall: 0.0741, LR: 0.000250\n",
      "Epoch 3: Train Loss(x1e3): 0.6736, Val Loss(x1e3): 0.6188, F2: 0.0200, Threshold: 0.100, Recall: 0.2538, LR: 0.000250\n",
      "Epoch 4: Train Loss(x1e3): 0.6421, Val Loss(x1e3): 0.5933, F2: 0.0234, Threshold: 0.100, Recall: 0.3038, LR: 0.000250\n",
      "Epoch 5: Train Loss(x1e3): 0.6199, Val Loss(x1e3): 0.5693, F2: 0.0285, Threshold: 0.100, Recall: 0.3855, LR: 0.000250\n",
      "Epoch 6: Train Loss(x1e3): 0.5979, Val Loss(x1e3): 0.5408, F2: 0.0369, Threshold: 0.150, Recall: 0.1022, LR: 0.000250\n",
      "Epoch 7: Train Loss(x1e3): 0.5641, Val Loss(x1e3): 0.5073, F2: 0.0555, Threshold: 0.150, Recall: 0.2126, LR: 0.000250\n",
      "Epoch 8: Train Loss(x1e3): 0.5281, Val Loss(x1e3): 0.4720, F2: 0.0909, Threshold: 0.150, Recall: 0.3882, LR: 0.000250\n",
      "Epoch 9: Train Loss(x1e3): 0.4959, Val Loss(x1e3): 0.4336, F2: 0.1571, Threshold: 0.200, Recall: 0.2003, LR: 0.000250\n",
      "Epoch 10: Train Loss(x1e3): 0.4644, Val Loss(x1e3): 0.3942, F2: 0.2727, Threshold: 0.200, Recall: 0.3635, LR: 0.000250\n",
      "Epoch 11: Train Loss(x1e3): 0.4331, Val Loss(x1e3): 0.3636, F2: 0.3324, Threshold: 0.200, Recall: 0.5130, LR: 0.000250\n",
      "Epoch 12: Train Loss(x1e3): 0.4059, Val Loss(x1e3): 0.3368, F2: 0.3847, Threshold: 0.250, Recall: 0.4232, LR: 0.000250\n",
      "Epoch 13: Train Loss(x1e3): 0.3838, Val Loss(x1e3): 0.3138, F2: 0.4475, Threshold: 0.250, Recall: 0.5165, LR: 0.000250\n",
      "Epoch 14: Train Loss(x1e3): 0.3580, Val Loss(x1e3): 0.2893, F2: 0.4975, Threshold: 0.250, Recall: 0.5933, LR: 0.000250\n",
      "Epoch 15: Train Loss(x1e3): 0.3369, Val Loss(x1e3): 0.2639, F2: 0.5437, Threshold: 0.250, Recall: 0.6502, LR: 0.000250\n",
      "Epoch 16: Train Loss(x1e3): 0.3162, Val Loss(x1e3): 0.2452, F2: 0.5771, Threshold: 0.300, Recall: 0.6145, LR: 0.000250\n",
      "Epoch 17: Train Loss(x1e3): 0.3013, Val Loss(x1e3): 0.2291, F2: 0.6081, Threshold: 0.300, Recall: 0.6372, LR: 0.000250\n",
      "Epoch 18: Train Loss(x1e3): 0.2847, Val Loss(x1e3): 0.2278, F2: 0.6117, Threshold: 0.300, Recall: 0.6680, LR: 0.000250\n",
      "Epoch 19: Train Loss(x1e3): 0.2897, Val Loss(x1e3): 0.2164, F2: 0.6355, Threshold: 0.300, Recall: 0.6337, LR: 0.000250\n",
      "Epoch 20: Train Loss(x1e3): 0.2663, Val Loss(x1e3): 0.2168, F2: 0.6381, Threshold: 0.300, Recall: 0.6317, LR: 0.000250\n",
      "Epoch 21: Train Loss(x1e3): 0.2754, Val Loss(x1e3): 0.2087, F2: 0.6442, Threshold: 0.350, Recall: 0.6399, LR: 0.000250\n",
      "Epoch 22: Train Loss(x1e3): 0.2640, Val Loss(x1e3): 0.2045, F2: 0.6569, Threshold: 0.350, Recall: 0.6859, LR: 0.000250\n",
      "Epoch 23: Train Loss(x1e3): 0.2597, Val Loss(x1e3): 0.1919, F2: 0.6738, Threshold: 0.350, Recall: 0.7003, LR: 0.000250\n",
      "Epoch 24: Train Loss(x1e3): 0.2277, Val Loss(x1e3): 0.1924, F2: 0.6812, Threshold: 0.400, Recall: 0.6742, LR: 0.000250\n",
      "Epoch 25: Train Loss(x1e3): 0.2479, Val Loss(x1e3): 0.1854, F2: 0.6839, Threshold: 0.400, Recall: 0.6776, LR: 0.000250\n",
      "Epoch 26: Train Loss(x1e3): 0.2155, Val Loss(x1e3): 0.1788, F2: 0.6894, Threshold: 0.400, Recall: 0.6831, LR: 0.000250\n",
      "Epoch 27: Train Loss(x1e3): 0.2177, Val Loss(x1e3): 0.1720, F2: 0.7018, Threshold: 0.350, Recall: 0.7305, LR: 0.000250\n",
      "Epoch 28: Train Loss(x1e3): 0.2144, Val Loss(x1e3): 0.1698, F2: 0.7067, Threshold: 0.400, Recall: 0.7044, LR: 0.000250\n",
      "Epoch 29: Train Loss(x1e3): 0.2061, Val Loss(x1e3): 0.1703, F2: 0.7140, Threshold: 0.400, Recall: 0.7167, LR: 0.000250\n",
      "Epoch 30: Train Loss(x1e3): 0.2045, Val Loss(x1e3): 0.1624, F2: 0.7252, Threshold: 0.400, Recall: 0.7277, LR: 0.000250\n",
      "Epoch 31: Train Loss(x1e3): 0.2018, Val Loss(x1e3): 0.1641, F2: 0.7180, Threshold: 0.400, Recall: 0.7270, LR: 0.000250\n",
      "Epoch 32: Train Loss(x1e3): 0.1875, Val Loss(x1e3): 0.1627, F2: 0.7362, Threshold: 0.450, Recall: 0.7277, LR: 0.000250\n",
      "Epoch 33: Train Loss(x1e3): 0.1997, Val Loss(x1e3): 0.1510, F2: 0.7359, Threshold: 0.400, Recall: 0.7373, LR: 0.000250\n",
      "Epoch 34: Train Loss(x1e3): 0.1806, Val Loss(x1e3): 0.1567, F2: 0.7382, Threshold: 0.400, Recall: 0.7476, LR: 0.000250\n",
      "Epoch 35: Train Loss(x1e3): 0.1885, Val Loss(x1e3): 0.1421, F2: 0.7505, Threshold: 0.400, Recall: 0.7517, LR: 0.000250\n",
      "Epoch 36: Train Loss(x1e3): 0.1822, Val Loss(x1e3): 0.1486, F2: 0.7531, Threshold: 0.400, Recall: 0.7613, LR: 0.000250\n",
      "Epoch 37: Train Loss(x1e3): 0.1748, Val Loss(x1e3): 0.1462, F2: 0.7521, Threshold: 0.400, Recall: 0.7606, LR: 0.000250\n",
      "Epoch 38: Train Loss(x1e3): 0.1778, Val Loss(x1e3): 0.1438, F2: 0.7569, Threshold: 0.400, Recall: 0.7695, LR: 0.000250\n",
      "Epoch 39: Train Loss(x1e3): 0.1786, Val Loss(x1e3): 0.1486, F2: 0.7534, Threshold: 0.450, Recall: 0.7462, LR: 0.000125\n",
      "Epoch 40: Train Loss(x1e3): 0.1660, Val Loss(x1e3): 0.1406, F2: 0.7490, Threshold: 0.350, Recall: 0.7449, LR: 0.000125\n",
      "Epoch 41: Train Loss(x1e3): 0.1609, Val Loss(x1e3): 0.1408, F2: 0.7501, Threshold: 0.350, Recall: 0.7524, LR: 0.000125\n",
      "Epoch 42: Train Loss(x1e3): 0.1632, Val Loss(x1e3): 0.1431, F2: 0.7477, Threshold: 0.400, Recall: 0.7407, LR: 0.000125\n",
      "Epoch 43: Train Loss(x1e3): 0.1631, Val Loss(x1e3): 0.1413, F2: 0.7502, Threshold: 0.400, Recall: 0.7407, LR: 0.000125\n",
      "Epoch 44: Train Loss(x1e3): 0.1641, Val Loss(x1e3): 0.1426, F2: 0.7498, Threshold: 0.400, Recall: 0.7435, LR: 0.000063\n",
      "Epoch 45: Train Loss(x1e3): 0.1629, Val Loss(x1e3): 0.1537, F2: 0.7491, Threshold: 0.450, Recall: 0.7421, LR: 0.000063\n",
      "Epoch 46: Train Loss(x1e3): 0.1655, Val Loss(x1e3): 0.1407, F2: 0.7619, Threshold: 0.350, Recall: 0.7833, LR: 0.000063\n",
      "Epoch 47: Train Loss(x1e3): 0.1600, Val Loss(x1e3): 0.1400, F2: 0.7631, Threshold: 0.400, Recall: 0.7654, LR: 0.000063\n",
      "Epoch 48: Train Loss(x1e3): 0.1643, Val Loss(x1e3): 0.1394, F2: 0.7617, Threshold: 0.350, Recall: 0.7819, LR: 0.000063\n",
      "Epoch 49: Train Loss(x1e3): 0.1600, Val Loss(x1e3): 0.1398, F2: 0.7651, Threshold: 0.400, Recall: 0.7702, LR: 0.000063\n",
      "Epoch 50: Train Loss(x1e3): 0.1627, Val Loss(x1e3): 0.1412, F2: 0.7644, Threshold: 0.400, Recall: 0.7675, LR: 0.000063\n",
      "Epoch 51: Train Loss(x1e3): 0.1630, Val Loss(x1e3): 0.1377, F2: 0.7651, Threshold: 0.400, Recall: 0.7634, LR: 0.000063\n",
      "Epoch 52: Train Loss(x1e3): 0.1592, Val Loss(x1e3): 0.1385, F2: 0.7661, Threshold: 0.400, Recall: 0.7675, LR: 0.000063\n",
      "Epoch 53: Train Loss(x1e3): 0.1577, Val Loss(x1e3): 0.1385, F2: 0.7687, Threshold: 0.400, Recall: 0.7716, LR: 0.000063\n",
      "Epoch 54: Train Loss(x1e3): 0.1567, Val Loss(x1e3): 0.1384, F2: 0.7668, Threshold: 0.400, Recall: 0.7682, LR: 0.000063\n",
      "Epoch 55: Train Loss(x1e3): 0.1581, Val Loss(x1e3): 0.1388, F2: 0.7682, Threshold: 0.400, Recall: 0.7695, LR: 0.000031\n",
      "Epoch 56: Train Loss(x1e3): 0.1545, Val Loss(x1e3): 0.1366, F2: 0.7702, Threshold: 0.400, Recall: 0.7723, LR: 0.000031\n",
      "Epoch 57: Train Loss(x1e3): 0.1517, Val Loss(x1e3): 0.1364, F2: 0.7681, Threshold: 0.400, Recall: 0.7682, LR: 0.000031\n",
      "Epoch 58: Train Loss(x1e3): 0.1535, Val Loss(x1e3): 0.1374, F2: 0.7705, Threshold: 0.400, Recall: 0.7730, LR: 0.000031\n",
      "Epoch 59: Train Loss(x1e3): 0.1531, Val Loss(x1e3): 0.1373, F2: 0.7704, Threshold: 0.400, Recall: 0.7702, LR: 0.000031\n",
      "Epoch 60: Train Loss(x1e3): 0.1532, Val Loss(x1e3): 0.1365, F2: 0.7721, Threshold: 0.400, Recall: 0.7716, LR: 0.000031\n",
      "Epoch 61: Train Loss(x1e3): 0.1506, Val Loss(x1e3): 0.1360, F2: 0.7703, Threshold: 0.400, Recall: 0.7709, LR: 0.000031\n",
      "Epoch 62: Train Loss(x1e3): 0.1517, Val Loss(x1e3): 0.1371, F2: 0.7685, Threshold: 0.400, Recall: 0.7695, LR: 0.000031\n",
      "Epoch 63: Train Loss(x1e3): 0.1513, Val Loss(x1e3): 0.1356, F2: 0.7713, Threshold: 0.400, Recall: 0.7723, LR: 0.000031\n",
      "Epoch 64: Train Loss(x1e3): 0.1479, Val Loss(x1e3): 0.1354, F2: 0.7664, Threshold: 0.350, Recall: 0.7826, LR: 0.000031\n",
      "Epoch 65: Train Loss(x1e3): 0.1516, Val Loss(x1e3): 0.1379, F2: 0.7691, Threshold: 0.400, Recall: 0.7702, LR: 0.000031\n",
      "Epoch 66: Train Loss(x1e3): 0.1505, Val Loss(x1e3): 0.1367, F2: 0.7696, Threshold: 0.400, Recall: 0.7716, LR: 0.000031\n",
      "Epoch 67: Train Loss(x1e3): 0.1507, Val Loss(x1e3): 0.1377, F2: 0.7708, Threshold: 0.400, Recall: 0.7743, LR: 0.000031\n",
      "Epoch 68: Train Loss(x1e3): 0.1510, Val Loss(x1e3): 0.1375, F2: 0.7697, Threshold: 0.400, Recall: 0.7709, LR: 0.000016\n",
      "Epoch 69: Train Loss(x1e3): 0.1501, Val Loss(x1e3): 0.1346, F2: 0.7692, Threshold: 0.350, Recall: 0.7853, LR: 0.000016\n",
      "Epoch 70: Train Loss(x1e3): 0.1483, Val Loss(x1e3): 0.1346, F2: 0.7691, Threshold: 0.350, Recall: 0.7860, LR: 0.000016\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "trainer = ModelTrainer(config=Config(), mem_profile=False)\n",
    "results = trainer.train_model(snapshots, global_num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb0d7038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_probs': array([0.07358936, 0.06273119, 0.0125565 , ..., 0.0151305 , 0.00894059,\n",
       "        0.01871899], shape=(1458820,), dtype=float32),\n",
       " 'val_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1458820,), dtype=float32),\n",
       " 'val_threshold': np.float64(0.35000000000000003),\n",
       " 'val_precision': 0.7082818294190358,\n",
       " 'val_recall': 0.7860082304526749,\n",
       " 'val_f1': 0.7451235370611183,\n",
       " 'val_f2': 0.7691275167785235,\n",
       " 'val_roc_auc': 0.9947758201037198,\n",
       " 'val_pr_auc': 0.804814046477607,\n",
       " 'test_probs': array([0.0013665 , 0.01294726, 0.00336071, ..., 0.008885  , 0.15391557,\n",
       "        0.0149585 ], shape=(1384809,), dtype=float32),\n",
       " 'test_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1384809,), dtype=float32),\n",
       " 'test_threshold': np.float64(0.4),\n",
       " 'test_precision': 0.7372434017595307,\n",
       " 'test_recall': 0.7659963436928702,\n",
       " 'test_f1': 0.7513448894202033,\n",
       " 'test_f2': 0.7600677228201718,\n",
       " 'test_roc_auc': 0.9940570835952796,\n",
       " 'test_pr_auc': 0.8094778857293173,\n",
       " 'train_loss_history': [0.007860231591621414,\n",
       "  0.0008320371689478634,\n",
       "  0.0006736092136634397,\n",
       "  0.0006421163470804458,\n",
       "  0.0006199184763318044,\n",
       "  0.0005979492161714006,\n",
       "  0.0005640630497509846,\n",
       "  0.0005281205612845952,\n",
       "  0.0004958965992045705,\n",
       "  0.0004643774091164232,\n",
       "  0.0004330811916588573,\n",
       "  0.0004059270531797665,\n",
       "  0.00038384926119761076,\n",
       "  0.000358006167516578,\n",
       "  0.0003369080714037409,\n",
       "  0.0003161698573421745,\n",
       "  0.000301267724353238,\n",
       "  0.00028466833509810385,\n",
       "  0.0002897436384046159,\n",
       "  0.0002663420800672611,\n",
       "  0.00027537476762518054,\n",
       "  0.000264034971678484,\n",
       "  0.00025974955951824086,\n",
       "  0.00022773537966713775,\n",
       "  0.000247874001161108,\n",
       "  0.0002155428878722887,\n",
       "  0.0002176606672037451,\n",
       "  0.00021441712169689708,\n",
       "  0.0002061068985312886,\n",
       "  0.000204459972337645,\n",
       "  0.00020177009400867973,\n",
       "  0.00018753571362140065,\n",
       "  0.00019968217770838237,\n",
       "  0.000180569277745235,\n",
       "  0.00018850220681088103,\n",
       "  0.00018224359450869088,\n",
       "  0.0001748195250002027,\n",
       "  0.00017781837505026488,\n",
       "  0.00017858340970633435,\n",
       "  0.00016603976973783574,\n",
       "  0.0001609262344572926,\n",
       "  0.0001632376483939879,\n",
       "  0.00016310366504512785,\n",
       "  0.00016414148922194727,\n",
       "  0.00016294496617774712,\n",
       "  0.00016548502435398404,\n",
       "  0.00016004670715119573,\n",
       "  0.00016425410512965755,\n",
       "  0.00015998220806068275,\n",
       "  0.00016267950286419364,\n",
       "  0.00016298851687679417,\n",
       "  0.00015923387695693236,\n",
       "  0.00015765417128932313,\n",
       "  0.0001567174483625422,\n",
       "  0.00015806523742867284,\n",
       "  0.00015449832494596194,\n",
       "  0.00015167650144576328,\n",
       "  0.0001534514130980824,\n",
       "  0.00015311011134144792,\n",
       "  0.00015322392096095427,\n",
       "  0.00015060468558658613,\n",
       "  0.00015172772600635653,\n",
       "  0.0001512818635092117,\n",
       "  0.00014793886793995625,\n",
       "  0.00015163260081862973,\n",
       "  0.00015048773843773233,\n",
       "  0.000150713585981066,\n",
       "  0.00015102162865332502,\n",
       "  0.00015010264269221807,\n",
       "  0.00014829829092377622],\n",
       " 'val_loss_history': [0.001301033014897257,\n",
       "  0.0006580477680212685,\n",
       "  0.000618772319285199,\n",
       "  0.0005932828020637057,\n",
       "  0.0005692710401490331,\n",
       "  0.0005408220292468156,\n",
       "  0.0005073347586273615,\n",
       "  0.00047202617029792497,\n",
       "  0.00043363741549131064,\n",
       "  0.0003941669419873506,\n",
       "  0.00036355967417226305,\n",
       "  0.00033684018749876747,\n",
       "  0.0003138298634439707,\n",
       "  0.0002892884783380266,\n",
       "  0.0002638863952597603,\n",
       "  0.00024516610886036815,\n",
       "  0.00022905193119575934,\n",
       "  0.0002277696434508211,\n",
       "  0.00021635940356645733,\n",
       "  0.0002168456807599536,\n",
       "  0.00020865033729933202,\n",
       "  0.00020446282412324633,\n",
       "  0.00019191865534854254,\n",
       "  0.00019237380807421038,\n",
       "  0.0001854053802422381,\n",
       "  0.00017884392790230258,\n",
       "  0.00017203702632936517,\n",
       "  0.0001698378743770133,\n",
       "  0.00017027157757963453,\n",
       "  0.0001624491820361332,\n",
       "  0.00016413171813058267,\n",
       "  0.00016270672183184485,\n",
       "  0.00015104612248251215,\n",
       "  0.00015673301407202546,\n",
       "  0.00014207393438222686,\n",
       "  0.00014859825543161214,\n",
       "  0.0001462325838344571,\n",
       "  0.00014382233868153499,\n",
       "  0.0001486471706552298,\n",
       "  0.0001406497706609246,\n",
       "  0.00014077355340954715,\n",
       "  0.0001431118559724252,\n",
       "  0.00014130226606669436,\n",
       "  0.00014260060457412953,\n",
       "  0.00015370072131710394,\n",
       "  0.00014067639131098986,\n",
       "  0.00013998652242922356,\n",
       "  0.00013944933639972338,\n",
       "  0.00013978175827235515,\n",
       "  0.00014124453342187086,\n",
       "  0.00013767805337140868,\n",
       "  0.00013852406326415285,\n",
       "  0.00013854923599865288,\n",
       "  0.00013836577168798873,\n",
       "  0.00013875152736935497,\n",
       "  0.00013660954781309037,\n",
       "  0.0001363988173709783,\n",
       "  0.00013744669039234786,\n",
       "  0.00013732259061985781,\n",
       "  0.00013649708645451547,\n",
       "  0.0001359992113845822,\n",
       "  0.00013714046924308474,\n",
       "  0.00013560870034520382,\n",
       "  0.00013535027911919833,\n",
       "  0.00013788847510503338,\n",
       "  0.0001366780634270981,\n",
       "  0.00013774596404151192,\n",
       "  0.00013752582370735972,\n",
       "  0.00013459156928417672,\n",
       "  0.00013457123714033514],\n",
       " 'f2_history': [0,\n",
       "  0.015951790145338533,\n",
       "  0.019985739904500574,\n",
       "  0.02337681526511314,\n",
       "  0.028493206246197524,\n",
       "  0.03693421248326806,\n",
       "  0.05553366056393537,\n",
       "  0.09085655579812509,\n",
       "  0.15705679862306368,\n",
       "  0.27274598600247013,\n",
       "  0.3324148964536486,\n",
       "  0.3846633416458853,\n",
       "  0.447468504872831,\n",
       "  0.4974695192086496,\n",
       "  0.5437026841018582,\n",
       "  0.5770964833183048,\n",
       "  0.6081434930610108,\n",
       "  0.6117321944479337,\n",
       "  0.6354883081155434,\n",
       "  0.6380767631980047,\n",
       "  0.644159072079536,\n",
       "  0.6569438969911969,\n",
       "  0.6738384371700106,\n",
       "  0.6812196812196812,\n",
       "  0.6839263463934653,\n",
       "  0.6893687707641196,\n",
       "  0.7017659462308908,\n",
       "  0.7067162124965594,\n",
       "  0.7139928942333971,\n",
       "  0.7252221462747779,\n",
       "  0.7179626117583311,\n",
       "  0.7361920621704136,\n",
       "  0.7358981380065718,\n",
       "  0.738182310713802,\n",
       "  0.7504793207340454,\n",
       "  0.7530529172320217,\n",
       "  0.7520683575206836,\n",
       "  0.7568807339449541,\n",
       "  0.7533582606287218,\n",
       "  0.7489655172413793,\n",
       "  0.750136761487965,\n",
       "  0.7477153143173636,\n",
       "  0.7502083912197832,\n",
       "  0.7497579194909393,\n",
       "  0.7490999723068402,\n",
       "  0.7619428876434481,\n",
       "  0.763129102844639,\n",
       "  0.7617265802485634,\n",
       "  0.7650906117999727,\n",
       "  0.7644486951769367,\n",
       "  0.7650536156172669,\n",
       "  0.7661235108859373,\n",
       "  0.7686526373326046,\n",
       "  0.7668081610297138,\n",
       "  0.7681774613172668,\n",
       "  0.7701778385772914,\n",
       "  0.7680702235632972,\n",
       "  0.7705456037194038,\n",
       "  0.7704445664105378,\n",
       "  0.7721345229924502,\n",
       "  0.7702850877192983,\n",
       "  0.7684931506849315,\n",
       "  0.7713385395259624,\n",
       "  0.7663890381515315,\n",
       "  0.7690727297630462,\n",
       "  0.7695991243672184,\n",
       "  0.7707536865101038,\n",
       "  0.7696521500958642,\n",
       "  0.7691790944511622,\n",
       "  0.7691275167785235],\n",
       " 'model': TemporalEdgeClassifier(\n",
       "   (rnn): GRUCell(15, 128)\n",
       "   (gnn1): SAGEConv(128, 128, aggr=mean)\n",
       "   (gnn2): SAGEConv(128, 128, aggr=mean)\n",
       "   (gnn3): SAGEConv(128, 128, aggr=mean)\n",
       "   (dropout): Dropout(p=0.3, inplace=False)\n",
       "   (classifier): Sequential(\n",
       "     (0): Linear(in_features=384, out_features=128, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Dropout(p=0.3, inplace=False)\n",
       "     (3): Linear(in_features=128, out_features=1, bias=True)\n",
       "   )\n",
       "   (edge_encoder): Sequential(\n",
       "     (0): Linear(in_features=9, out_features=128, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (3): Dropout(p=0.3, inplace=False)\n",
       "     (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82e25fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Function to compute and print confusion matrix\n",
    "def compute_confusion_matrix(labels, preds, threshold=0.5):\n",
    "\n",
    "    # Convert probabilities to binary predictions using the threshold\n",
    "    binary_preds = (preds >= threshold).astype(int)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(labels, binary_preds)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Optional: Extract and print TP, TN, FP, FN\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"False Negatives (FN): {fn}\")\n",
    "    print(f\"True Positives (TP): {tp}\")\n",
    "    print(f\"Precision: {tp / (tp + fp + 1e-8):.4f}\")\n",
    "    print(f\"Recall: {tp / (tp + fn + 1e-8):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51d19dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = results['test_probs']\n",
    "test_labels = results['test_labels']\n",
    "val_probs = results['val_probs']\n",
    "val_labels = results['val_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f1f36ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1456890     472]\n",
      " [    312    1146]]\n",
      "True Negatives (TN): 1456890\n",
      "False Positives (FP): 472\n",
      "False Negatives (FN): 312\n",
      "True Positives (TP): 1146\n",
      "Precision: 0.7083\n",
      "Recall: 0.7860\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(val_labels, val_probs, threshold=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c31c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1382519     649]\n",
      " [    350    1291]]\n",
      "True Negatives (TN): 1382519\n",
      "False Positives (FP): 649\n",
      "False Negatives (FN): 350\n",
      "True Positives (TP): 1291\n",
      "Precision: 0.6655\n",
      "Recall: 0.7867\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(test_labels, test_probs, threshold=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b1255f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC Score: 0.8095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate PR curve data\n",
    "precision, recall, thresholds = precision_recall_curve(test_labels, test_probs)\n",
    "pr_auc = average_precision_score(test_labels, test_probs)\n",
    "\n",
    "# Plot PR curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, linewidth=2, label=f'PR AUC = {pr_auc:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"PR AUC Score: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5373b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae20c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fastai-backup]",
   "language": "python",
   "name": "conda-env-.conda-fastai-backup-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
