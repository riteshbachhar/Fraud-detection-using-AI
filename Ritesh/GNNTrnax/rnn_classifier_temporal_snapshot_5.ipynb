{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83228cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Improved Temporal Graph Neural Network for Anti-Money Laundering Detection\n",
    "==========================================================================\n",
    "Optimized for F2 Score with structured code organization\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (precision_recall_curve, roc_auc_score, f1_score, \n",
    "                           precision_score, recall_score, fbeta_score, \n",
    "                           confusion_matrix, average_precision_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74ecce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent.parent))  # Adjust as needed\n",
    "from config import DATAPATH, SAMPLE_DATAPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ddba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f457192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration class for hyperparameters and settings\"\"\"\n",
    "    # Model architecture\n",
    "    HIDDEN_DIM = 128  # Increased from 128\n",
    "    NODE_DIM = 15\n",
    "    EDGE_DIM = 9\n",
    "    DROPOUT_RATE = 0.3\n",
    "    \n",
    "    # Training parameters\n",
    "    LEARNING_RATE = 0.0005  \n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    EPOCHS = 100\n",
    "    PATIENCE = 10  # Early stopping patience\n",
    "    \n",
    "    # F2 score optimization\n",
    "    BETA = 2  # For F2 score (emphasizes recall)\n",
    "    CLASS_WEIGHT_MULTIPLIER = 10  # Strong emphasis on minority class\n",
    "\n",
    "    # Criterion parameters\n",
    "    FOCAL_LOSS_ALPHA = 0.25\n",
    "    FOCAL_LOSS_GAMMA = 2.0\n",
    "    \n",
    "    # Data processing\n",
    "    TIME_WINDOW = '7D'\n",
    "    VALIDATION_SPLIT = 0.17\n",
    "    TEST_SPLIT = 0.13\n",
    "    \n",
    "    # Threshold optimization\n",
    "    THRESHOLD_SEARCH_RANGE = np.arange(0.05, 0.95, 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc23495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "\n",
    "def detailed_memory_profile():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        cached = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "        \n",
    "        # Show memory summary\n",
    "        # print(torch.cuda.memory_summary())\n",
    "        return allocated, cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0671bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for addressing class imbalance - better than BCE for F2 optimization\"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08365f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGraphDataProcessor:\n",
    "    \"\"\"Enhanced data processor with better feature engineering for F2 optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, time_window='7D'):\n",
    "        self.time_window = time_window\n",
    "        self.scalers = {}\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_and_preprocess(self, df):\n",
    "        \"\"\"Load SAML-D dataset and perform initial preprocessing\"\"\"\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        \n",
    "        # Combine date and time into datetime\n",
    "        df['datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "        df = df.sort_values('datetime').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Loaded {len(df)} transactions\")\n",
    "        print(f\"Suspicious transactions: {df['Is_laundering'].sum()} ({df['Is_laundering'].mean()*100:.3f}%)\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def engineer_features(self, df):\n",
    "        \"\"\"Enhanced feature engineering for better detection\"\"\"\n",
    "        print(\"Engineering enhanced features...\")\n",
    "        \n",
    "        # Time-based features (more granular)\n",
    "        df['hour'] = df['datetime'].dt.hour.astype('int8')\n",
    "        df['month'] = df['datetime'].dt.month.astype('int8')\n",
    "        df['day_of_week'] = df['datetime'].dt.dayofweek.astype('int8')\n",
    "        df['day_of_month'] = df['datetime'].dt.day.astype('int8')\n",
    "        df['is_weekend'] = (df['day_of_week'] >= 5).astype('int8')\n",
    "        df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 5)).astype('int8')  # Night transactions\n",
    "        \n",
    "        # Amount-based features\n",
    "        df['log_amount'] = np.log1p(df['Amount']).astype('float32')\n",
    "        \n",
    "        # Calculate amount percentiles for anomaly detection\n",
    "        # amount_percentiles = df['Amount'].quantile([0.95, 0.99]).values\n",
    "        # df['high_amount'] = (df['Amount'] > amount_percentiles[0]).astype('int8')\n",
    "        # df['very_high_amount'] = (df['Amount'] > amount_percentiles[1]).astype('int8')\n",
    "        \n",
    "        # Geographic risk features\n",
    "        df['cross_border'] = (df['Payment_type'] == 'Cross-border').astype('int8')\n",
    "        risky_countries = {'Mexico', 'Turkey', 'Morocco', 'UAE'}\n",
    "        df['high_risk_sender'] = df['Sender_bank_location'].isin(risky_countries).astype('int8')\n",
    "        df['high_risk_receiver'] = df['Receiver_bank_location'].isin(risky_countries).astype('int8')\n",
    "        # df['both_high_risk'] = (df['high_risk_sender'] & df['high_risk_receiver']).astype('int8')\n",
    "        \n",
    "        # Currency features\n",
    "        df['currency_mismatch'] = (df['Payment_currency'] != df['Received_currency']).astype('int8')\n",
    "        \n",
    "        # Convert target\n",
    "        df['Is_laundering'] = df['Is_laundering'].astype('int8')\n",
    "        \n",
    "        # Clean up\n",
    "        columns_to_drop = ['Date', 'Time', 'Amount', 'Sender_bank_location', \n",
    "                          'Receiver_bank_location', 'Payment_currency', 'Received_currency', \n",
    "                          'Laundering_type']\n",
    "        df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_temporal_snapshots(self, df, account_features):\n",
    "        \"\"\"Create temporal graph snapshots with enhanced features\"\"\"\n",
    "        print(\"Creating temporal graph snapshots...\")\n",
    "        \n",
    "        # Global account mapping\n",
    "        all_accounts = list(set(df['Sender_account'].unique()) | set(df['Receiver_account'].unique()))\n",
    "        global_account_to_idx = {acc: idx for idx, acc in enumerate(all_accounts)}\n",
    "        global_num_nodes = len(all_accounts)\n",
    "        \n",
    "        # Time windows\n",
    "        start_date = df['datetime'].min().normalize().date()\n",
    "        end_date = df['datetime'].max().normalize().date()\n",
    "        \n",
    "        snapshots = []\n",
    "        print(f\"Processing time range: {start_date} to {end_date}\")\n",
    "\n",
    "        for window_start in pd.date_range(start=start_date, end=end_date, freq=self.time_window, inclusive='left'):\n",
    "            window_end = window_start + pd.Timedelta(days=7)\n",
    "            window_start_str = pd.to_datetime(window_start).strftime('%Y-%m-%d')\n",
    "            window_end_str = pd.to_datetime(window_end).strftime('%Y-%m-%d')\n",
    "            print(f\"Processing window: {window_start_str} to {window_end_str}\")\n",
    "            \n",
    "            # Get transactions in current window\n",
    "            window_mask = (df['datetime'] >= window_start_str) & (df['datetime'] < window_end_str)\n",
    "            window_trnx_data = df[window_mask].copy()\n",
    "            \n",
    "            # Account features for this window\n",
    "            window_accounts_features = account_features[account_features['window_start'] == window_start_str]\n",
    "            \n",
    "            if len(window_trnx_data) > 0:\n",
    "                graph_data = self._create_graph_snapshot(\n",
    "                    window_trnx_data, window_accounts_features,\n",
    "                    window_start_str, global_account_to_idx, global_num_nodes\n",
    "                )\n",
    "                if graph_data is not None:\n",
    "                    snapshots.append(graph_data)\n",
    "\n",
    "        print(f\"Created {len(snapshots)} temporal snapshots\")\n",
    "        return snapshots, global_num_nodes\n",
    "\n",
    "    def _create_graph_snapshot(self, window_trnx_data, window_accounts_features, \n",
    "                              timestamp, global_account_to_idx, global_num_nodes):\n",
    "        \"\"\"Create enhanced graph snapshot\"\"\"\n",
    "        if len(window_trnx_data) == 0:\n",
    "            return None\n",
    "\n",
    "        # Enhanced edge features\n",
    "        edge_feature_columns = [\n",
    "            'Payment_type_encoded', 'log_amount', 'month', 'day_of_week', 'hour', \n",
    "            'currency_mismatch', 'cross_border', 'high_risk_sender', 'high_risk_receiver',\n",
    "        ]\n",
    "        \n",
    "        # Filter available columns\n",
    "        edge_feature_columns = [col for col in edge_feature_columns if col in window_trnx_data.columns]\n",
    "\n",
    "        # Node features\n",
    "        node_feature_columns = ['sent_txns_count', 'fan_out', 'recv_txns_count', 'fan_in', \n",
    "                               'max_sent_txn_count', 'max_recv_txn_count', 'sent_recv_ratio', \n",
    "                               'fanout_fanin_ratio', 'log_med_sent_amt', 'log_std_sent_amt', \n",
    "                               'log_med_recv_amt', 'log_std_recv_amt', 'log_max_sent_txn_amt', \n",
    "                               'log_max_recv_txn_amt', 'log_total_txns_amt']\n",
    "\n",
    "        # Create mappings and features\n",
    "        sender_mapped = window_trnx_data['Sender_account'].map(global_account_to_idx)\n",
    "        receiver_mapped = window_trnx_data['Receiver_account'].map(global_account_to_idx)\n",
    "        edge_index = np.column_stack((sender_mapped, receiver_mapped))\n",
    "        edge_features = window_trnx_data[edge_feature_columns].values\n",
    "        transaction_labels = window_trnx_data['Is_laundering'].values\n",
    "\n",
    "        # Node features\n",
    "        node_features = np.zeros((global_num_nodes, len(node_feature_columns)))\n",
    "        try:\n",
    "            window_accounts_features['global_idx'] = window_accounts_features['account'].map(global_account_to_idx)\n",
    "            node_features[window_accounts_features['global_idx'].values] = window_accounts_features[node_feature_columns].values\n",
    "        except: \n",
    "            raise ValueError(\"Error in mapping account features to global indices.\")\n",
    "\n",
    "        # Convert to tensors\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "        edge_features = torch.tensor(edge_features, dtype=torch.float)\n",
    "        transaction_labels = torch.tensor(transaction_labels, dtype=torch.float)\n",
    "\n",
    "        return Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_features,\n",
    "            y=transaction_labels,\n",
    "            timestamp=timestamp,\n",
    "            num_nodes=global_num_nodes\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e55e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal GNN Model for Edge Classification\n",
    "class TemporalEdgeClassifier(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, dropout_rate):\n",
    "        super(TemporalEdgeClassifier, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.GRUCell(node_dim, hidden_dim)\n",
    "        self.gnn1 = SAGEConv(hidden_dim, hidden_dim, aggr='mean')\n",
    "        self.gnn2 = SAGEConv(hidden_dim, hidden_dim, aggr='mean')\n",
    "        self.gnn3 = SAGEConv(hidden_dim, hidden_dim, aggr='mean')\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        # Improved classifier architecture\n",
    "        # self.classifier = nn.Linear(hidden_dim * 2 + edge_dim, 1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 3, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(edge_dim, hidden_dim),  # Project to hidden_dim\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),  # Normalize\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim)  # Second layer for non-linearity\n",
    "        )\n",
    "\n",
    "    def forward(self, data, h):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        \n",
    "        # Update node hidden states with RNN (using current x)\n",
    "        h = self.rnn(x, h)\n",
    "        \n",
    "        # Apply GNN layers\n",
    "        h = F.relu(self.gnn1(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.gnn2(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.gnn3(h, edge_index))\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        # Process edge_attr\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "\n",
    "        # Edge features: concat sender h, receiver h, edge_attr\n",
    "        h_i = h[edge_index[0]]\n",
    "        h_j = h[edge_index[1]]\n",
    "        edge_input = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
    "        \n",
    "        # Prediction\n",
    "        out = self.classifier(edge_input)\n",
    "        \n",
    "        return out, h  # Return logits and updated h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59dd2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"Enhanced trainer class optimized for F2 score\"\"\"\n",
    "    \n",
    "    def __init__(self, config=Config(), mem_profile=False):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        self.mem_profile = mem_profile\n",
    "\n",
    "    def find_optimal_threshold(self, probs, labels):\n",
    "        \"\"\"Find optimal threshold for F2 score\"\"\"\n",
    "        best_f2 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in self.config.THRESHOLD_SEARCH_RANGE:\n",
    "            preds = (probs >= threshold).astype(int)\n",
    "            f2 = fbeta_score(labels, preds, beta=self.config.BETA, average='binary', zero_division=0)\n",
    "            if f2 > best_f2:\n",
    "                best_f2 = f2\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        return best_threshold, best_f2\n",
    "    \n",
    "    def compute_class_weights(self, snapshots):\n",
    "        \"\"\"Compute class weights for focal loss\"\"\"\n",
    "        all_labels = []\n",
    "        for snap in snapshots:\n",
    "            all_labels.extend(snap.y.cpu().numpy())\n",
    "        \n",
    "        all_labels = np.array(all_labels)\n",
    "        pos_weight = len(all_labels) / (2 * np.sum(all_labels))\n",
    "        return torch.tensor(pos_weight, dtype=torch.float).to(self.device)\n",
    "    \n",
    "    def train_model(self, snapshots, global_num_nodes):\n",
    "        \"\"\"Enhanced training with F2 optimization\"\"\"\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(len(snapshots) * (1 - self.config.VALIDATION_SPLIT - self.config.TEST_SPLIT))\n",
    "        val_size = int(len(snapshots) * self.config.VALIDATION_SPLIT)\n",
    "        \n",
    "        train_snaps = snapshots[:train_size]\n",
    "        val_snaps = snapshots[train_size:train_size + val_size]\n",
    "        test_snaps = snapshots[train_size + val_size:]\n",
    "        \n",
    "        print(f\"Data split - Train: {len(train_snaps)}, Val: {len(val_snaps)}, Test: {len(test_snaps)}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = TemporalEdgeClassifier(\n",
    "            self.config.NODE_DIM, \n",
    "            self.config.EDGE_DIM, \n",
    "            self.config.HIDDEN_DIM,\n",
    "            self.config.DROPOUT_RATE\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Compute class weights for focal loss\n",
    "        pos_weight = self.compute_class_weights(train_snaps)\n",
    "        criterion = FocalLoss(alpha=self.config.FOCAL_LOSS_ALPHA, gamma=self.config.FOCAL_LOSS_GAMMA)\n",
    "        \n",
    "        # Optimizer with different learning rates for different components\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {'params': model.rnn.parameters(), 'lr': self.config.LEARNING_RATE * 0.5},\n",
    "            {'params': model.gnn1.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.gnn2.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.gnn3.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.edge_encoder.parameters(), 'lr': self.config.LEARNING_RATE},\n",
    "            {'params': model.classifier.parameters(), 'lr': self.config.LEARNING_RATE * 1.5}\n",
    "        ], weight_decay=self.config.WEIGHT_DECAY)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    "        )\n",
    "        \n",
    "        # Training loop\n",
    "        best_f2_score = 0\n",
    "        patience_counter = 0\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "        f2_history = []\n",
    "        \n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            # Training\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "\n",
    "            if self.mem_profile:\n",
    "                print(f\"=== EPOCH {epoch} START ===\")\n",
    "                epoch_start_mem = detailed_memory_profile()\n",
    "                print(f\"Epoch Mem Allocated: {epoch_start_mem[0]:.3f} GB, Cached: {epoch_start_mem[0]:.3f} GB\")\n",
    "\n",
    "            for i, snap in enumerate(train_snaps):\n",
    "                if (i < 5) and self.mem_profile:\n",
    "                    print(f\"--- Snapshot {i} ---\")\n",
    "                    pre_snap = detailed_memory_profile()\n",
    "                    print(f\"Pre snap Allocated: {pre_snap[0]:.3f} GB, Cached: {pre_snap[0]:.3f} GB\")\n",
    "                \n",
    "                snap = snap.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                out, h = model(snap, h.detach())  # Detach to prevent gradient explosion\n",
    "                loss = criterion(out.squeeze(), snap.y)\n",
    "\n",
    "                if (i < 5) and self.mem_profile:\n",
    "                    post_forward = detailed_memory_profile()\n",
    "                    print(f\"Forward Mem Allocated: {post_forward[0]}, Cached: {post_forward[1]:.3f}GB cached\")\n",
    "                    print(f\"Forward pass added: {post_forward[1] - pre_snap[1]:.3f}GB cached\")\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "                optimizer.step()\n",
    "\n",
    "                if (i < 5) and self.mem_profile:\n",
    "                    post_backward = detailed_memory_profile()\n",
    "                    print(f\"Forward Mem Allocated: {post_backward[0]}, Cached: {post_backward[1]:.3f}GB cached\")\n",
    "                    print(f\"Backward pass added: {post_backward[1] - post_forward[1]:.3f}GB cached\")\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_snaps)\n",
    "            train_loss_history.append(avg_train_loss)\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_probs_list, val_labels_list = [], []\n",
    "            val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "                for snap in val_snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, h = model(snap, h)\n",
    "                    loss = criterion(out.squeeze(), snap.y)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    preds = torch.sigmoid(out).squeeze()\n",
    "                    val_probs_list.append(preds.cpu())\n",
    "                    val_labels_list.append(snap.y.cpu())\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_snaps)\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "            \n",
    "            # Calculate F2 score with optimal threshold\n",
    "            val_probs = torch.cat(val_probs_list).numpy()\n",
    "            val_labels = torch.cat(val_labels_list).numpy()\n",
    "            \n",
    "            optimal_threshold, f2_score = self.find_optimal_threshold(val_probs, val_labels)\n",
    "            f2_history.append(f2_score)\n",
    "            recall = recall_score(val_labels, (val_probs >= optimal_threshold).astype(int), zero_division=0)\n",
    "            \n",
    "            # Update scheduler with F2 score\n",
    "            # scheduler.step(f2_score)\n",
    "            scheduler.step(avg_val_loss)\n",
    "            \n",
    "            # Early stopping based on F2 score\n",
    "            if f2_score > best_f2_score:\n",
    "                best_f2_score = f2_score\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                # torch.save(model.state_dict(), './outputs/best_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # if (epoch + 1) % 10 == 0:\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"Epoch {epoch+1}: Train Loss(x1e3): {1000*avg_train_loss:.4f}, Val Loss(x1e3): {1000*avg_val_loss:.4f}, \"\n",
    "                        f\"F2: {f2_score:.4f}, Threshold: {optimal_threshold:.3f}, Recall: {recall:.4f}, \"\n",
    "                        f\"LR: {current_lr:.6f}\")\n",
    "\n",
    "            if patience_counter >= self.config.PATIENCE:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # Load best model and evaluate\n",
    "        # model.load_state_dict(torch.load('./outputs/best_model.pth'))\n",
    "        \n",
    "        # Final evaluation\n",
    "        results = self._evaluate_model(model, train_snaps, val_snaps, test_snaps, global_num_nodes)\n",
    "        results.update({\n",
    "            'train_loss_history': train_loss_history,\n",
    "            'val_loss_history': val_loss_history,\n",
    "            'f2_history': f2_history,\n",
    "            'model': model\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_model(self, model, train_snaps, val_snaps, test_snaps, global_num_nodes):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        model.eval()\n",
    "        results = {}\n",
    "        \n",
    "        for split_name, snaps in [('val', val_snaps), ('test', test_snaps)]:\n",
    "            probs_list, labels_list = [], []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                h = torch.zeros(global_num_nodes, self.config.HIDDEN_DIM).to(self.device)\n",
    "                for snap in snaps:\n",
    "                    snap = snap.to(self.device)\n",
    "                    out, h = model(snap, h)\n",
    "                    preds = torch.sigmoid(out).squeeze().cpu().numpy()\n",
    "                    probs_list.extend(preds)\n",
    "                    labels_list.extend(snap.y.cpu().numpy())\n",
    "            \n",
    "            probs = np.array(probs_list)\n",
    "            labels = np.array(labels_list)\n",
    "            \n",
    "            # Find optimal threshold\n",
    "            optimal_threshold, best_f2 = self.find_optimal_threshold(probs, labels)\n",
    "            binary_preds = (probs >= optimal_threshold).astype(int)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            precision = precision_score(labels, binary_preds, zero_division=0)\n",
    "            recall = recall_score(labels, binary_preds, zero_division=0)\n",
    "            f1 = f1_score(labels, binary_preds, zero_division=0)\n",
    "            roc_auc = roc_auc_score(labels, probs)\n",
    "            pr_auc = average_precision_score(labels, probs)\n",
    "            \n",
    "            results[f'{split_name}_probs'] = probs\n",
    "            results[f'{split_name}_labels'] = labels\n",
    "            results[f'{split_name}_threshold'] = optimal_threshold\n",
    "            results[f'{split_name}_precision'] = precision\n",
    "            results[f'{split_name}_recall'] = recall\n",
    "            results[f'{split_name}_f1'] = f1\n",
    "            results[f'{split_name}_f2'] = best_f2\n",
    "            results[f'{split_name}_roc_auc'] = roc_auc\n",
    "            results[f'{split_name}_pr_auc'] = pr_auc\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2124555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset\n",
    "df = pd.read_csv(DATAPATH)\n",
    "\n",
    "# Filter by data range\n",
    "# df = df[df['Date'] < '2023-08-18']\n",
    "# df = df.head(300000).copy()\n",
    "\n",
    "# run feature engg.ipynb to get the account_stats_7D.csv\n",
    "account_stats = pd.read_csv('../account_stats_7D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9178de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Loaded 9504852 transactions\n",
      "Suspicious transactions: 9873 (0.104%)\n",
      "Engineering enhanced features...\n"
     ]
    }
   ],
   "source": [
    "graph_processor = TemporalGraphDataProcessor()\n",
    "df = graph_processor.load_and_preprocess(df)\n",
    "df = graph_processor.engineer_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8bfb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For each categorical column\n",
    "# categorical_cols = ['Payment_currency', 'Received_currency', 'Sender_bank_location', \n",
    "#                    'Receiver_bank_location', 'Payment_type']\n",
    "categorical_cols = ['Payment_type']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "# Drop original object columns\n",
    "df = df.drop(categorical_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43c740f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process accont_stats\n",
    "columns = ['med_sent_amt', 'std_sent_amt', 'med_recv_amt', 'std_recv_amt', \n",
    "           'max_sent_txn_amt', 'max_recv_txn_amt', 'total_txns_amt']\n",
    "\n",
    "for col in columns:\n",
    "    account_stats['log_' + col] = np.log1p(account_stats[col]).astype('float32')\n",
    "\n",
    "account_stats = account_stats.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "094d1677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data types to optimize memory\n",
    "account_stats = account_stats.astype({\n",
    "    'sent_txns_count': 'int32',\n",
    "    'recv_txns_count': 'int32',\n",
    "    'fan_out': 'int32',\n",
    "    'fan_in': 'int32',\n",
    "    'max_sent_txn_count': 'int32',\n",
    "    'max_recv_txn_count': 'int32',\n",
    "    'sent_recv_ratio': 'float32',\n",
    "    'fanout_fanin_ratio': 'float32'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79bf8e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporal graph snapshots...\n",
      "Processing time range: 2022-10-07 to 2023-08-23\n",
      "Processing window: 2022-10-07 to 2022-10-14\n",
      "Processing window: 2022-10-14 to 2022-10-21\n",
      "Processing window: 2022-10-21 to 2022-10-28\n",
      "Processing window: 2022-10-28 to 2022-11-04\n",
      "Processing window: 2022-11-04 to 2022-11-11\n",
      "Processing window: 2022-11-11 to 2022-11-18\n",
      "Processing window: 2022-11-18 to 2022-11-25\n",
      "Processing window: 2022-11-25 to 2022-12-02\n",
      "Processing window: 2022-12-02 to 2022-12-09\n",
      "Processing window: 2022-12-09 to 2022-12-16\n",
      "Processing window: 2022-12-16 to 2022-12-23\n",
      "Processing window: 2022-12-23 to 2022-12-30\n",
      "Processing window: 2022-12-30 to 2023-01-06\n",
      "Processing window: 2023-01-06 to 2023-01-13\n",
      "Processing window: 2023-01-13 to 2023-01-20\n",
      "Processing window: 2023-01-20 to 2023-01-27\n",
      "Processing window: 2023-01-27 to 2023-02-03\n",
      "Processing window: 2023-02-03 to 2023-02-10\n",
      "Processing window: 2023-02-10 to 2023-02-17\n",
      "Processing window: 2023-02-17 to 2023-02-24\n",
      "Processing window: 2023-02-24 to 2023-03-03\n",
      "Processing window: 2023-03-03 to 2023-03-10\n",
      "Processing window: 2023-03-10 to 2023-03-17\n",
      "Processing window: 2023-03-17 to 2023-03-24\n",
      "Processing window: 2023-03-24 to 2023-03-31\n",
      "Processing window: 2023-03-31 to 2023-04-07\n",
      "Processing window: 2023-04-07 to 2023-04-14\n",
      "Processing window: 2023-04-14 to 2023-04-21\n",
      "Processing window: 2023-04-21 to 2023-04-28\n",
      "Processing window: 2023-04-28 to 2023-05-05\n",
      "Processing window: 2023-05-05 to 2023-05-12\n",
      "Processing window: 2023-05-12 to 2023-05-19\n",
      "Processing window: 2023-05-19 to 2023-05-26\n",
      "Processing window: 2023-05-26 to 2023-06-02\n",
      "Processing window: 2023-06-02 to 2023-06-09\n",
      "Processing window: 2023-06-09 to 2023-06-16\n",
      "Processing window: 2023-06-16 to 2023-06-23\n",
      "Processing window: 2023-06-23 to 2023-06-30\n",
      "Processing window: 2023-06-30 to 2023-07-07\n",
      "Processing window: 2023-07-07 to 2023-07-14\n",
      "Processing window: 2023-07-14 to 2023-07-21\n",
      "Processing window: 2023-07-21 to 2023-07-28\n",
      "Processing window: 2023-07-28 to 2023-08-04\n",
      "Processing window: 2023-08-04 to 2023-08-11\n",
      "Processing window: 2023-08-11 to 2023-08-18\n",
      "Processing window: 2023-08-18 to 2023-08-25\n",
      "Created 46 temporal snapshots\n"
     ]
    }
   ],
   "source": [
    "snapshots, global_num_nodes = graph_processor.create_temporal_snapshots(df, account_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a083f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory - Allocated: 2.71GB, Cached: 2.85GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89fc6783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Data split - Train: 32, Val: 7, Test: 7\n",
      "Epoch 1: Train Loss(x1e3): 7.6154, Val Loss(x1e3): 1.2564, F2: 0.0007, Threshold: 0.050, Recall: 0.0007, LR: 0.000250\n",
      "Epoch 2: Train Loss(x1e3): 0.8394, Val Loss(x1e3): 0.6776, F2: 0.0143, Threshold: 0.150, Recall: 0.1084, LR: 0.000250\n",
      "Epoch 3: Train Loss(x1e3): 0.6819, Val Loss(x1e3): 0.6209, F2: 0.0190, Threshold: 0.100, Recall: 0.2791, LR: 0.000250\n",
      "Epoch 4: Train Loss(x1e3): 0.6473, Val Loss(x1e3): 0.5932, F2: 0.0238, Threshold: 0.100, Recall: 0.3457, LR: 0.000250\n",
      "Epoch 5: Train Loss(x1e3): 0.6227, Val Loss(x1e3): 0.5711, F2: 0.0291, Threshold: 0.100, Recall: 0.4328, LR: 0.000250\n",
      "Epoch 6: Train Loss(x1e3): 0.5996, Val Loss(x1e3): 0.5445, F2: 0.0401, Threshold: 0.150, Recall: 0.1310, LR: 0.000250\n",
      "Epoch 7: Train Loss(x1e3): 0.5671, Val Loss(x1e3): 0.5099, F2: 0.0676, Threshold: 0.150, Recall: 0.1996, LR: 0.000250\n",
      "Epoch 8: Train Loss(x1e3): 0.5311, Val Loss(x1e3): 0.4684, F2: 0.1106, Threshold: 0.150, Recall: 0.3697, LR: 0.000250\n",
      "Epoch 9: Train Loss(x1e3): 0.4938, Val Loss(x1e3): 0.4273, F2: 0.1651, Threshold: 0.200, Recall: 0.1948, LR: 0.000250\n",
      "Epoch 10: Train Loss(x1e3): 0.4592, Val Loss(x1e3): 0.3914, F2: 0.2758, Threshold: 0.200, Recall: 0.3553, LR: 0.000250\n",
      "Epoch 11: Train Loss(x1e3): 0.4276, Val Loss(x1e3): 0.3597, F2: 0.3496, Threshold: 0.200, Recall: 0.5117, LR: 0.000250\n",
      "Epoch 12: Train Loss(x1e3): 0.3962, Val Loss(x1e3): 0.3332, F2: 0.3874, Threshold: 0.250, Recall: 0.4143, LR: 0.000250\n",
      "Epoch 13: Train Loss(x1e3): 0.3705, Val Loss(x1e3): 0.3115, F2: 0.4679, Threshold: 0.250, Recall: 0.5295, LR: 0.000250\n",
      "Epoch 14: Train Loss(x1e3): 0.3456, Val Loss(x1e3): 0.2847, F2: 0.5052, Threshold: 0.250, Recall: 0.6159, LR: 0.000250\n",
      "Epoch 15: Train Loss(x1e3): 0.3287, Val Loss(x1e3): 0.2631, F2: 0.5646, Threshold: 0.250, Recall: 0.6495, LR: 0.000250\n",
      "Epoch 16: Train Loss(x1e3): 0.3037, Val Loss(x1e3): 0.2395, F2: 0.6077, Threshold: 0.300, Recall: 0.6241, LR: 0.000250\n",
      "Epoch 17: Train Loss(x1e3): 0.2872, Val Loss(x1e3): 0.2512, F2: 0.5855, Threshold: 0.350, Recall: 0.5857, LR: 0.000250\n",
      "Epoch 18: Train Loss(x1e3): 0.3138, Val Loss(x1e3): 0.2374, F2: 0.6280, Threshold: 0.250, Recall: 0.6372, LR: 0.000250\n",
      "Epoch 19: Train Loss(x1e3): 0.2686, Val Loss(x1e3): 0.2203, F2: 0.6432, Threshold: 0.250, Recall: 0.6797, LR: 0.000250\n",
      "Epoch 20: Train Loss(x1e3): 0.2525, Val Loss(x1e3): 0.2100, F2: 0.6570, Threshold: 0.300, Recall: 0.6578, LR: 0.000250\n",
      "Epoch 21: Train Loss(x1e3): 0.2692, Val Loss(x1e3): 0.2021, F2: 0.6644, Threshold: 0.350, Recall: 0.6564, LR: 0.000250\n",
      "Epoch 22: Train Loss(x1e3): 0.2676, Val Loss(x1e3): 0.2105, F2: 0.6625, Threshold: 0.350, Recall: 0.6989, LR: 0.000250\n",
      "Epoch 23: Train Loss(x1e3): 0.2448, Val Loss(x1e3): 0.1870, F2: 0.6851, Threshold: 0.350, Recall: 0.6934, LR: 0.000250\n",
      "Epoch 24: Train Loss(x1e3): 0.2251, Val Loss(x1e3): 0.1881, F2: 0.6920, Threshold: 0.350, Recall: 0.7318, LR: 0.000250\n",
      "Epoch 25: Train Loss(x1e3): 0.2338, Val Loss(x1e3): 0.1866, F2: 0.6915, Threshold: 0.350, Recall: 0.7318, LR: 0.000250\n",
      "Epoch 26: Train Loss(x1e3): 0.2203, Val Loss(x1e3): 0.1782, F2: 0.7094, Threshold: 0.350, Recall: 0.7469, LR: 0.000250\n",
      "Epoch 27: Train Loss(x1e3): 0.2221, Val Loss(x1e3): 0.1709, F2: 0.7136, Threshold: 0.400, Recall: 0.7126, LR: 0.000250\n",
      "Epoch 28: Train Loss(x1e3): 0.2091, Val Loss(x1e3): 0.1718, F2: 0.7163, Threshold: 0.350, Recall: 0.7503, LR: 0.000250\n",
      "Epoch 29: Train Loss(x1e3): 0.2105, Val Loss(x1e3): 0.1640, F2: 0.7195, Threshold: 0.400, Recall: 0.7188, LR: 0.000250\n",
      "Epoch 30: Train Loss(x1e3): 0.1946, Val Loss(x1e3): 0.1703, F2: 0.7290, Threshold: 0.400, Recall: 0.7298, LR: 0.000250\n",
      "Epoch 31: Train Loss(x1e3): 0.2164, Val Loss(x1e3): 0.1633, F2: 0.7213, Threshold: 0.400, Recall: 0.7215, LR: 0.000250\n",
      "Epoch 32: Train Loss(x1e3): 0.1911, Val Loss(x1e3): 0.1561, F2: 0.7387, Threshold: 0.400, Recall: 0.7339, LR: 0.000250\n",
      "Epoch 33: Train Loss(x1e3): 0.1996, Val Loss(x1e3): 0.1577, F2: 0.7274, Threshold: 0.400, Recall: 0.7257, LR: 0.000250\n",
      "Epoch 34: Train Loss(x1e3): 0.1790, Val Loss(x1e3): 0.1686, F2: 0.7480, Threshold: 0.400, Recall: 0.7572, LR: 0.000250\n",
      "Epoch 35: Train Loss(x1e3): 0.2177, Val Loss(x1e3): 0.1543, F2: 0.7251, Threshold: 0.400, Recall: 0.7154, LR: 0.000250\n",
      "Epoch 36: Train Loss(x1e3): 0.1714, Val Loss(x1e3): 0.1525, F2: 0.7524, Threshold: 0.400, Recall: 0.7551, LR: 0.000250\n",
      "Epoch 37: Train Loss(x1e3): 0.1969, Val Loss(x1e3): 0.1508, F2: 0.7450, Threshold: 0.400, Recall: 0.7462, LR: 0.000250\n",
      "Epoch 38: Train Loss(x1e3): 0.1722, Val Loss(x1e3): 0.1564, F2: 0.7531, Threshold: 0.400, Recall: 0.7606, LR: 0.000250\n",
      "Epoch 39: Train Loss(x1e3): 0.1995, Val Loss(x1e3): 0.1484, F2: 0.7359, Threshold: 0.400, Recall: 0.7277, LR: 0.000250\n",
      "Epoch 40: Train Loss(x1e3): 0.1611, Val Loss(x1e3): 0.1593, F2: 0.7535, Threshold: 0.400, Recall: 0.7627, LR: 0.000250\n",
      "Epoch 41: Train Loss(x1e3): 0.2017, Val Loss(x1e3): 0.1516, F2: 0.7311, Threshold: 0.400, Recall: 0.7222, LR: 0.000250\n",
      "Epoch 42: Train Loss(x1e3): 0.1589, Val Loss(x1e3): 0.1538, F2: 0.7553, Threshold: 0.400, Recall: 0.7565, LR: 0.000250\n",
      "Epoch 43: Train Loss(x1e3): 0.1940, Val Loss(x1e3): 0.1425, F2: 0.7489, Threshold: 0.350, Recall: 0.7517, LR: 0.000250\n",
      "Epoch 44: Train Loss(x1e3): 0.1580, Val Loss(x1e3): 0.1557, F2: 0.7615, Threshold: 0.400, Recall: 0.7689, LR: 0.000250\n",
      "Epoch 45: Train Loss(x1e3): 0.1913, Val Loss(x1e3): 0.1447, F2: 0.7474, Threshold: 0.350, Recall: 0.7483, LR: 0.000250\n",
      "Epoch 46: Train Loss(x1e3): 0.1564, Val Loss(x1e3): 0.1612, F2: 0.7542, Threshold: 0.450, Recall: 0.7421, LR: 0.000250\n",
      "Epoch 47: Train Loss(x1e3): 0.2071, Val Loss(x1e3): 0.1504, F2: 0.7406, Threshold: 0.300, Recall: 0.7497, LR: 0.000125\n",
      "Epoch 48: Train Loss(x1e3): 0.1567, Val Loss(x1e3): 0.1434, F2: 0.7470, Threshold: 0.300, Recall: 0.7778, LR: 0.000125\n",
      "Epoch 49: Train Loss(x1e3): 0.1552, Val Loss(x1e3): 0.1431, F2: 0.7507, Threshold: 0.350, Recall: 0.7558, LR: 0.000125\n",
      "Epoch 50: Train Loss(x1e3): 0.1661, Val Loss(x1e3): 0.1421, F2: 0.7491, Threshold: 0.350, Recall: 0.7449, LR: 0.000125\n",
      "Epoch 51: Train Loss(x1e3): 0.1617, Val Loss(x1e3): 0.1406, F2: 0.7530, Threshold: 0.300, Recall: 0.7764, LR: 0.000125\n",
      "Epoch 52: Train Loss(x1e3): 0.1585, Val Loss(x1e3): 0.1418, F2: 0.7529, Threshold: 0.350, Recall: 0.7469, LR: 0.000125\n",
      "Epoch 53: Train Loss(x1e3): 0.1572, Val Loss(x1e3): 0.1413, F2: 0.7528, Threshold: 0.350, Recall: 0.7510, LR: 0.000125\n",
      "Epoch 54: Train Loss(x1e3): 0.1596, Val Loss(x1e3): 0.1391, F2: 0.7556, Threshold: 0.350, Recall: 0.7510, LR: 0.000125\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "trainer = ModelTrainer(config=Config(), mem_profile=False)\n",
    "results = trainer.train_model(snapshots, global_num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb0d7038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_probs': array([0.09969815, 0.06114856, 0.00705266, ..., 0.00987016, 0.00627424,\n",
       "        0.01236532], shape=(1458820,), dtype=float32),\n",
       " 'val_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1458820,), dtype=float32),\n",
       " 'val_threshold': np.float64(0.35000000000000003),\n",
       " 'val_precision': 0.7743988684582744,\n",
       " 'val_recall': 0.7510288065843621,\n",
       " 'val_f1': 0.7625348189415042,\n",
       " 'val_f2': 0.7555892906431134,\n",
       " 'val_roc_auc': 0.9943030059467296,\n",
       " 'val_pr_auc': 0.7904635965618241,\n",
       " 'test_probs': array([0.00065623, 0.00420685, 0.00258708, ..., 0.00647344, 0.32142994,\n",
       "        0.02155951], shape=(1384809,), dtype=float32),\n",
       " 'test_labels': array([0., 0., 0., ..., 0., 0., 0.], shape=(1384809,), dtype=float32),\n",
       " 'test_threshold': np.float64(0.45),\n",
       " 'test_precision': 0.829817158931083,\n",
       " 'test_recall': 0.7190737355271176,\n",
       " 'test_f1': 0.7704864511916422,\n",
       " 'test_f2': 0.7387928875532181,\n",
       " 'test_roc_auc': 0.9934699604951088,\n",
       " 'test_pr_auc': 0.7852232601718753,\n",
       " 'train_loss_history': [0.007615412814629963,\n",
       "  0.000839387251289736,\n",
       "  0.0006819442596679437,\n",
       "  0.0006472637915067025,\n",
       "  0.0006226891491678543,\n",
       "  0.0005996150375722209,\n",
       "  0.0005670691143677686,\n",
       "  0.0005311445756888133,\n",
       "  0.0004938352531098644,\n",
       "  0.0004592413797581685,\n",
       "  0.0004275503051758278,\n",
       "  0.0003962388682339224,\n",
       "  0.00037048883586976444,\n",
       "  0.000345605350958067,\n",
       "  0.0003287320173512853,\n",
       "  0.00030366800501724356,\n",
       "  0.00028715667849610327,\n",
       "  0.0003137576368317241,\n",
       "  0.0002685696649677993,\n",
       "  0.00025249455984521774,\n",
       "  0.00026917098966805497,\n",
       "  0.00026764329504658235,\n",
       "  0.00024480777801727527,\n",
       "  0.00022512898340210086,\n",
       "  0.00023378895730274962,\n",
       "  0.00022030384297977434,\n",
       "  0.00022205282311915653,\n",
       "  0.00020908909755235072,\n",
       "  0.00021045739413239062,\n",
       "  0.00019460293879092205,\n",
       "  0.00021641604871547315,\n",
       "  0.0001910971377583337,\n",
       "  0.00019963960085078725,\n",
       "  0.0001790237101886305,\n",
       "  0.00021773493017462897,\n",
       "  0.00017144395792456635,\n",
       "  0.00019686022142195725,\n",
       "  0.00017222619203494105,\n",
       "  0.00019952092134190025,\n",
       "  0.0001611053935448581,\n",
       "  0.0002016516464209417,\n",
       "  0.0001588690142853011,\n",
       "  0.00019403692704145215,\n",
       "  0.00015796008142388018,\n",
       "  0.0001913174007768248,\n",
       "  0.0001564022277307231,\n",
       "  0.000207069937914639,\n",
       "  0.00015667703860344773,\n",
       "  0.00015523377282988804,\n",
       "  0.0001660614966567664,\n",
       "  0.00016166045338650292,\n",
       "  0.00015848581097088754,\n",
       "  0.00015716091274953214,\n",
       "  0.000159638438390175],\n",
       " 'val_loss_history': [0.0012563873647845217,\n",
       "  0.0006775905910347189,\n",
       "  0.0006209354199069951,\n",
       "  0.000593174818537331,\n",
       "  0.0005710925865319691,\n",
       "  0.0005444839022987123,\n",
       "  0.0005098927441784846,\n",
       "  0.00046843368493552717,\n",
       "  0.0004273382156887757,\n",
       "  0.0003913798302944217,\n",
       "  0.00035972804679269236,\n",
       "  0.00033316435708132176,\n",
       "  0.0003114807020340647,\n",
       "  0.0002847303860887353,\n",
       "  0.0002630929375300184,\n",
       "  0.00023950781698139117,\n",
       "  0.00025118905302536277,\n",
       "  0.00023740195527872338,\n",
       "  0.0002203414457783635,\n",
       "  0.0002099802784089531,\n",
       "  0.0002021288507551487,\n",
       "  0.00021053994298979108,\n",
       "  0.00018698142749989138,\n",
       "  0.00018808300124614367,\n",
       "  0.00018662736485046999,\n",
       "  0.000178244141612335,\n",
       "  0.00017088477449890758,\n",
       "  0.0001718292000337637,\n",
       "  0.0001640397053311712,\n",
       "  0.00017033967950348078,\n",
       "  0.00016326395000630458,\n",
       "  0.00015609828135763695,\n",
       "  0.00015768930877259533,\n",
       "  0.00016858932732637704,\n",
       "  0.00015425696619786322,\n",
       "  0.00015253339682073732,\n",
       "  0.0001507656800510761,\n",
       "  0.00015640935037351613,\n",
       "  0.0001483513551647775,\n",
       "  0.0001592517104914545,\n",
       "  0.00015155215701919848,\n",
       "  0.00015378262573254427,\n",
       "  0.00014247390208765864,\n",
       "  0.00015569591154676994,\n",
       "  0.00014469983580056578,\n",
       "  0.00016119981072344153,\n",
       "  0.00015038092429417053,\n",
       "  0.00014336196493656774,\n",
       "  0.00014309481879796034,\n",
       "  0.0001421126050575237,\n",
       "  0.00014058303141999722,\n",
       "  0.00014175024573757713,\n",
       "  0.00014126446330919862,\n",
       "  0.00013914781863734658],\n",
       " 'f2_history': [0.0007072135785007072,\n",
       "  0.014335746819823253,\n",
       "  0.01902064698240006,\n",
       "  0.02378907024383797,\n",
       "  0.02913284763197503,\n",
       "  0.04011593715869949,\n",
       "  0.06764610163187502,\n",
       "  0.11055956678700361,\n",
       "  0.1651354808698686,\n",
       "  0.2757666098807496,\n",
       "  0.34957825679475163,\n",
       "  0.38737814263724984,\n",
       "  0.4678787878787879,\n",
       "  0.5051755175517552,\n",
       "  0.5646315287383735,\n",
       "  0.6077200480833445,\n",
       "  0.5854929384341149,\n",
       "  0.6280421849648459,\n",
       "  0.6431723779854621,\n",
       "  0.6570293231022197,\n",
       "  0.6643987781171896,\n",
       "  0.6624626186451696,\n",
       "  0.6850521750914758,\n",
       "  0.691958495460441,\n",
       "  0.6915100453661698,\n",
       "  0.7093538301198541,\n",
       "  0.7135989010989011,\n",
       "  0.71634363541121,\n",
       "  0.7194837292324592,\n",
       "  0.7289668402302001,\n",
       "  0.7213384530992869,\n",
       "  0.7387462027064347,\n",
       "  0.7274477447744775,\n",
       "  0.7479674796747967,\n",
       "  0.725111234705228,\n",
       "  0.7523575235752358,\n",
       "  0.7450013694878116,\n",
       "  0.7530897731902757,\n",
       "  0.735885698432515,\n",
       "  0.7534896327415639,\n",
       "  0.7311484516039439,\n",
       "  0.7552725280745002,\n",
       "  0.7489408227415607,\n",
       "  0.7615489130434783,\n",
       "  0.7473626524181395,\n",
       "  0.7542172034016451,\n",
       "  0.7406152595202602,\n",
       "  0.7470355731225297,\n",
       "  0.7506811989100818,\n",
       "  0.7490688370809767,\n",
       "  0.7529599574298257,\n",
       "  0.7529037610619469,\n",
       "  0.7527842705898529,\n",
       "  0.7555892906431134],\n",
       " 'model': TemporalEdgeClassifier(\n",
       "   (rnn): GRUCell(15, 128)\n",
       "   (gnn1): SAGEConv(128, 128, aggr=mean)\n",
       "   (gnn2): SAGEConv(128, 128, aggr=mean)\n",
       "   (gnn3): SAGEConv(128, 128, aggr=mean)\n",
       "   (dropout): Dropout(p=0.3, inplace=False)\n",
       "   (classifier): Sequential(\n",
       "     (0): Linear(in_features=384, out_features=128, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Dropout(p=0.3, inplace=False)\n",
       "     (3): Linear(in_features=128, out_features=1, bias=True)\n",
       "   )\n",
       "   (edge_encoder): Sequential(\n",
       "     (0): Linear(in_features=9, out_features=128, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (3): Dropout(p=0.3, inplace=False)\n",
       "     (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "   )\n",
       " )}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82e25fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Function to compute and print confusion matrix\n",
    "def compute_confusion_matrix(labels, preds, threshold=0.5):\n",
    "\n",
    "    # Convert probabilities to binary predictions using the threshold\n",
    "    binary_preds = (preds >= threshold).astype(int)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(labels, binary_preds)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Optional: Extract and print TP, TN, FP, FN\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"True Negatives (TN): {tn}\")\n",
    "    print(f\"False Positives (FP): {fp}\")\n",
    "    print(f\"False Negatives (FN): {fn}\")\n",
    "    print(f\"True Positives (TP): {tp}\")\n",
    "    print(f\"Precision: {tp / (tp + fp + 1e-8):.4f}\")\n",
    "    print(f\"Recall: {tp / (tp + fn + 1e-8):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51d19dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = results['test_probs']\n",
    "test_labels = results['test_labels']\n",
    "val_probs = results['val_probs']\n",
    "val_labels = results['val_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f1f36ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1449146    8216]\n",
      " [    196    1262]]\n",
      "True Negatives (TN): 1449146\n",
      "False Positives (FP): 8216\n",
      "False Negatives (FN): 196\n",
      "True Positives (TP): 1262\n",
      "Precision: 0.1332\n",
      "Recall: 0.8656\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(val_labels, val_probs, threshold=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c31c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1373370    9798]\n",
      " [    181    1460]]\n",
      "True Negatives (TN): 1373370\n",
      "False Positives (FP): 9798\n",
      "False Negatives (FN): 181\n",
      "True Positives (TP): 1460\n",
      "Precision: 0.1297\n",
      "Recall: 0.8897\n"
     ]
    }
   ],
   "source": [
    "compute_confusion_matrix(test_labels, test_probs, threshold=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b1255f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC Score: 0.7852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate PR curve data\n",
    "precision, recall, thresholds = precision_recall_curve(test_labels, test_probs)\n",
    "pr_auc = average_precision_score(test_labels, test_probs)\n",
    "\n",
    "# Plot PR curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, linewidth=2, label=f'PR AUC = {pr_auc:.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"PR AUC Score: {pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5373b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae20c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-backup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
