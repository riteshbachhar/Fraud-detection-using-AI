{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b998b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool, SAGEConv, global_mean_pool\n",
    "from torch_geometric.data import NeighborSampler\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.data import Data, DataLoader as PyGDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "274e5e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent.parent))  # Adjust as needed\n",
    "from config import DATAPATH, SAMPLE_DATAPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc6e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE_AccountRiskDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    GraphSAGE model for scalable account risk detection\n",
    "    Uses sampling and aggregation for handling large transaction graphs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, hidden_dim=256, num_layers=3, dropout=0.3, aggregator='mean'):\n",
    "        super(GraphSAGE_AccountRiskDetector, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # GraphSAGE layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(num_features, hidden_dim, aggr=aggregator))\n",
    "        \n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_dim, hidden_dim, aggr=aggregator))\n",
    "        \n",
    "        self.convs.append(SAGEConv(hidden_dim, hidden_dim, aggr=aggregator))\n",
    "        \n",
    "        # Batch normalization layers\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 4, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # GraphSAGE layers with residual connections\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x_new = conv(x, edge_index)\n",
    "            x_new = self.batch_norms[i](x_new)\n",
    "            x_new = F.relu(x_new)\n",
    "            x_new = F.dropout(x_new, p=self.dropout, training=self.training)\n",
    "            \n",
    "            # Residual connection (if dimensions match)\n",
    "            if i > 0 and x.size(-1) == x_new.size(-1):\n",
    "                x = x + x_new\n",
    "            else:\n",
    "                x = x_new\n",
    "        \n",
    "        # Final layer\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        x = self.batch_norms[-1](x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Classification\n",
    "        out = self.classifier(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "888be030",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_graphsage(model, loader, device):\n",
    "    \"\"\"\n",
    "    Evaluation function for GraphSAGE\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    probabilities = []\n",
    "    \n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        \n",
    "        # Get predictions for target nodes only\n",
    "        pred = out[:batch.batch_size].argmax(dim=1)\n",
    "        probs = F.softmax(out[:batch.batch_size], dim=1)[:, 1]\n",
    "        \n",
    "        predictions.append(pred.cpu())\n",
    "        labels.append(batch.y[:batch.batch_size].cpu())\n",
    "        probabilities.append(probs.cpu())\n",
    "    \n",
    "    predictions = torch.cat(predictions)\n",
    "    labels = torch.cat(labels)\n",
    "    probabilities = torch.cat(probabilities)\n",
    "    \n",
    "    accuracy = (predictions == labels).float().mean().item()\n",
    "    \n",
    "    return accuracy, predictions.numpy(), probabilities.numpy(), labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45dcdffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inductive_dataset(df, cutoff_date, gap_days=7):\n",
    "    \"\"\"\n",
    "    Create proper inductive test setup:\n",
    "    - Training: transactions before cutoff_date\n",
    "    - Gap: gap_days with no data (prevents leakage)\n",
    "    - Test: new accounts appearing after cutoff_date + gap\n",
    "    \"\"\"\n",
    "    print(\"Creating inductive dataset...\")\n",
    "    \n",
    "    # Define time periods\n",
    "    train_end = cutoff_date\n",
    "    test_start = cutoff_date + pd.Timedelta(days=gap_days)\n",
    "    \n",
    "    # Split data\n",
    "    train_data = df[df['DateTime'] <= train_end].copy()\n",
    "    test_data = df[df['DateTime'] >= test_start].copy()\n",
    "\n",
    "    print(f\"Training period: {train_data['DateTime'].min()} to {train_data['DateTime'].max()}\")\n",
    "    print(f\"Gap period: {gap_days} days\")\n",
    "    print(f\"Test period: {test_data['DateTime'].min()} to {test_data['DateTime'].max()}\")\n",
    "    \n",
    "    # Get account sets\n",
    "    train_accounts = set(train_data['Sender_account']) | set(train_data['Receiver_account'])\n",
    "    test_accounts = set(test_data['Sender_account']) | set(test_data['Receiver_account'])\n",
    "    \n",
    "    # Find completely new accounts (never seen in training)\n",
    "    new_accounts = test_accounts - train_accounts\n",
    "    # Find accounts that appeared in training and also appear in test\n",
    "    existing_accounts_in_test = test_accounts & train_accounts\n",
    "    \n",
    "    print(f\"\\nAccount Statistics:\")\n",
    "    print(f\"Training accounts: {len(train_accounts):,}\")\n",
    "    print(f\"Test period accounts: {len(test_accounts):,}\")\n",
    "    print(f\"Completely new accounts: {len(new_accounts):,}\")\n",
    "    print(f\"Existing accounts in test: {len(existing_accounts_in_test):,}\")\n",
    "    \n",
    "    return {\n",
    "        'train_data': train_data,\n",
    "        'test_data': test_data,\n",
    "        'train_accounts': train_accounts,\n",
    "        'new_accounts': new_accounts,\n",
    "        'existing_accounts_in_test': existing_accounts_in_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feb4cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_account_features(account, sent_txns, recv_txns):\n",
    "    \"\"\"\n",
    "    Extract comprehensive behavioral features for an account\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # === YOUR EXISTING FEATURES (keep all) ===\n",
    "    features['total_txns'] = len(sent_txns) + len(recv_txns)\n",
    "    features['sent_count'] = len(sent_txns)\n",
    "    features['recv_count'] = len(recv_txns)\n",
    "    features['sent_recv_ratio'] = len(sent_txns) / (len(recv_txns) + 1)\n",
    "    \n",
    "    features['total_sent_amount'] = sent_txns['Amount'].sum()\n",
    "    features['total_recv_amount'] = recv_txns['Amount'].sum()\n",
    "    features['avg_sent_amount'] = sent_txns['Amount'].mean() if len(sent_txns) > 0 else 0\n",
    "    features['avg_recv_amount'] = recv_txns['Amount'].mean() if len(recv_txns) > 0 else 0\n",
    "    features['std_sent_amount'] = sent_txns['Amount'].std() if len(sent_txns) > 1 else 0\n",
    "    features['std_recv_amount'] = recv_txns['Amount'].std() if len(recv_txns) > 1 else 0\n",
    "    features['median_sent_amount'] = sent_txns['Amount'].median() if len(sent_txns) > 0 else 0\n",
    "    features['median_recv_amount'] = recv_txns['Amount'].median() if len(recv_txns) > 0 else 0\n",
    "    \n",
    "    features['unique_senders'] = recv_txns['Sender_account'].nunique()\n",
    "    features['unique_receivers'] = sent_txns['Receiver_account'].nunique()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "611160e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_accounts(data, accounts, feature_extraction_function):\n",
    "    \"\"\"\n",
    "    Extract features for accounts using only their test period transactions\n",
    "    data: DataFrame with transaction data\n",
    "    accounts: List of accounts to extract features for\n",
    "    feature_extraction_function: Function to extract features for a single account\n",
    "    \"\"\"\n",
    "    print(f\"Extracting features for {len(accounts):,} accounts...\")\n",
    "\n",
    "    account_features = []\n",
    "    account_labels = []\n",
    "    account_ids = []\n",
    "\n",
    "    for i, account in enumerate(accounts):\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print(f\"  Processed {i+1:,} / {len(accounts):,} accounts...\")\n",
    "        \n",
    "        # Get transactions for this account in test period only\n",
    "        sent_txns = data[data['Sender_account'] == account]\n",
    "        recv_txns = data[data['Receiver_account'] == account]\n",
    "\n",
    "        # Skip accounts with very few transactions\n",
    "        if len(sent_txns) + len(recv_txns) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Extract features using only test period data\n",
    "        features = feature_extraction_function(account, sent_txns, recv_txns)\n",
    "        \n",
    "        # Label: suspicious if involved in any suspicious transaction\n",
    "        is_suspicious = (sent_txns['Is_laundering'].sum() > 0) or (recv_txns['Is_laundering'].sum() > 0)\n",
    "\n",
    "        account_features.append(features)\n",
    "        account_labels.append(1 if is_suspicious else 0)\n",
    "        account_ids.append(account)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    features_df = pd.DataFrame(account_features, index=account_ids)\n",
    "    labels_series = pd.Series(account_labels, index=account_ids, name='high_risk')\n",
    "\n",
    "    print(f\"Features extracted for {len(features_df)} accounts\")\n",
    "    print(f\"Suspicious accounts: {labels_series.sum()} ({labels_series.mean()*100:.2f}%)\")\n",
    "\n",
    "    return features_df, labels_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5116bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transaction_graph(df, account_features_df, account_labels):\n",
    "    \"\"\"\n",
    "    Create graph where nodes are accounts and edges are transactions\n",
    "    \"\"\"\n",
    "    print(\"Building transaction network graph...\")\n",
    "    \n",
    "    # Create mapping of account to index\n",
    "    accounts = list(account_features_df.index)\n",
    "    account_to_idx = {acc: idx for idx, acc in enumerate(accounts)}\n",
    "    \n",
    "    # Build edges\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        sender = row['Sender_account']\n",
    "        receiver = row['Receiver_account']\n",
    "        \n",
    "        if sender in account_to_idx and receiver in account_to_idx:\n",
    "            sender_idx = account_to_idx[sender]\n",
    "            receiver_idx = account_to_idx[receiver]\n",
    "            \n",
    "            edge_index.append([sender_idx, receiver_idx])\n",
    "            \n",
    "            # Edge features: amount, payment type encoded\n",
    "            edge_features = [\n",
    "                row['Amount'],\n",
    "                row['Payment_currency_encoded'],\n",
    "                row['Received_currency_encoded'],\n",
    "                row['Sender_bank_location_encoded'],\n",
    "                row['Receiver_bank_location_encoded'],\n",
    "                row['Payment_type_encoded'],\n",
    "                1 if row['Payment_type'] == 'Cross-border' else 0\n",
    "            ]\n",
    "            edge_attr.append(edge_features)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    \n",
    "    # Node features\n",
    "    x = torch.tensor(account_features_df.values, dtype=torch.float)\n",
    "    \n",
    "    # Labels\n",
    "    y = torch.tensor(account_labels.values, dtype=torch.long)\n",
    "    \n",
    "    # Create PyG data object\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    \n",
    "    return data, account_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d09dc142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Date range:\n",
      "From: 2022-10-07 10:35:19\n",
      "To: 2023-08-23 10:57:12\n"
     ]
    }
   ],
   "source": [
    "# Load the entire dataset\n",
    "df = pd.read_csv(DATAPATH)\n",
    "\n",
    "# Add and delete columns\n",
    "df['DateTime'] = pd.to_datetime(df[\"Date\"] + ' ' + df[\"Time\"], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# df.drop(columns=['Laundering_type'], inplace=True)\n",
    "df.drop(columns=['Time', 'Date'], inplace=True)\n",
    "\n",
    "print(\"\\nDate range:\")\n",
    "print(f\"From: {df['DateTime'].min()}\")\n",
    "print(f\"To: {df['DateTime'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab9a83ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating inductive dataset...\n",
      "Training period: 2022-10-07 10:35:19 to 2023-05-30 23:59:58\n",
      "Gap period: 7 days\n",
      "Test period: 2023-06-07 00:00:14 to 2023-08-23 10:57:12\n",
      "\n",
      "Account Statistics:\n",
      "Training accounts: 735,533\n",
      "Test period accounts: 474,075\n",
      "Completely new accounts: 110,905\n",
      "Existing accounts in test: 363,170\n"
     ]
    }
   ],
   "source": [
    "cutoff_date = pd.to_datetime('2023-05-31')\n",
    "\n",
    "# Spliting dataset\n",
    "dataset_split = create_inductive_dataset(df, cutoff_date, gap_days=7)\n",
    "\n",
    "# Delete full transaction table \n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf1b6d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train_data', 'test_data', 'train_accounts', 'new_accounts', 'existing_accounts_in_test'])\n"
     ]
    }
   ],
   "source": [
    "print(dataset_split.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8972e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accounts = dataset_split['train_accounts']\n",
    "new_accounts = dataset_split['new_accounts']\n",
    "existing_accounts_in_test = dataset_split['existing_accounts_in_test']\n",
    "test_accounts = new_accounts | existing_accounts_in_test\n",
    "\n",
    "train_transaction_df = dataset_split['train_data']\n",
    "test_transaction_df = dataset_split['test_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15e76ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading batch 0...\n",
      "Loading batch 1...\n",
      "Loading batch 2...\n",
      "Loading batch 3...\n",
      "Loading batch 4...\n",
      "Loading batch 5...\n",
      "Loading batch 6...\n",
      "Loading batch 7...\n"
     ]
    }
   ],
   "source": [
    "# Load temporary file (other notebooks)\n",
    "batch_size = 100000\n",
    "\n",
    "for batch in range(len(train_accounts)//batch_size + 1):\n",
    "    print(f\"Loading batch {batch}...\")\n",
    "    features = np.load(f\"tmp/features_temp_{batch}.npy\", allow_pickle=True)\n",
    "    labels = np.load(f\"tmp/labels_temp_{batch}.npy\", allow_pickle=True)\n",
    "    ids = np.load(f\"tmp/ids_temp_{batch}.npy\", allow_pickle=True)\n",
    "    \n",
    "    if batch == 0:\n",
    "        train_features = features\n",
    "        train_labels = labels\n",
    "        train_ids = ids\n",
    "    else:\n",
    "        train_features = np.concatenate((train_features, features), axis=0)\n",
    "        train_labels = np.concatenate((train_labels, labels), axis=0)\n",
    "        train_ids = np.concatenate((train_ids, ids), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "824985a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (735533, 14)\n",
      "Number of features: 14\n"
     ]
    }
   ],
   "source": [
    "train_features_df = pd.DataFrame(train_features.tolist(), index=train_ids)\n",
    "train_labels_series = pd.Series(train_labels, index=train_ids, name='Acc_label')\n",
    "\n",
    "print(f\"Feature matrix shape: {train_features_df.shape}\")\n",
    "print(f\"Number of features: {train_features_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2a043ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Amount to log\n",
    "for feat in ['total_sent_amount', 'total_recv_amount', 'avg_sent_amount', 'avg_recv_amount',\n",
    "             'std_sent_amount', 'std_recv_amount', 'median_sent_amount', 'median_recv_amount']:\n",
    "            #  'max_txn_amount_7d']:\n",
    "    train_features_df[feat] = np.log1p(train_features_df[feat])\n",
    "\n",
    "# Convert Amount to log in transaction table\n",
    "train_transaction_df['Amount'] = np.log1p(train_transaction_df['Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f097925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for 474,075 accounts...\n",
      "  Processed 10,000 / 474,075 accounts...\n",
      "  Processed 20,000 / 474,075 accounts...\n",
      "  Processed 30,000 / 474,075 accounts...\n",
      "  Processed 40,000 / 474,075 accounts...\n",
      "  Processed 50,000 / 474,075 accounts...\n",
      "  Processed 60,000 / 474,075 accounts...\n",
      "  Processed 70,000 / 474,075 accounts...\n",
      "  Processed 80,000 / 474,075 accounts...\n",
      "  Processed 90,000 / 474,075 accounts...\n",
      "  Processed 100,000 / 474,075 accounts...\n",
      "  Processed 110,000 / 474,075 accounts...\n",
      "  Processed 120,000 / 474,075 accounts...\n",
      "  Processed 130,000 / 474,075 accounts...\n",
      "  Processed 140,000 / 474,075 accounts...\n",
      "  Processed 150,000 / 474,075 accounts...\n",
      "  Processed 160,000 / 474,075 accounts...\n",
      "  Processed 170,000 / 474,075 accounts...\n",
      "  Processed 180,000 / 474,075 accounts...\n",
      "  Processed 190,000 / 474,075 accounts...\n",
      "  Processed 200,000 / 474,075 accounts...\n",
      "  Processed 210,000 / 474,075 accounts...\n",
      "  Processed 220,000 / 474,075 accounts...\n",
      "  Processed 230,000 / 474,075 accounts...\n",
      "  Processed 240,000 / 474,075 accounts...\n",
      "  Processed 250,000 / 474,075 accounts...\n",
      "  Processed 260,000 / 474,075 accounts...\n",
      "  Processed 270,000 / 474,075 accounts...\n",
      "  Processed 280,000 / 474,075 accounts...\n",
      "  Processed 290,000 / 474,075 accounts...\n",
      "  Processed 300,000 / 474,075 accounts...\n",
      "  Processed 310,000 / 474,075 accounts...\n",
      "  Processed 320,000 / 474,075 accounts...\n",
      "  Processed 330,000 / 474,075 accounts...\n",
      "  Processed 340,000 / 474,075 accounts...\n",
      "  Processed 350,000 / 474,075 accounts...\n",
      "  Processed 360,000 / 474,075 accounts...\n",
      "  Processed 370,000 / 474,075 accounts...\n",
      "  Processed 380,000 / 474,075 accounts...\n",
      "  Processed 390,000 / 474,075 accounts...\n",
      "  Processed 400,000 / 474,075 accounts...\n",
      "  Processed 410,000 / 474,075 accounts...\n",
      "  Processed 420,000 / 474,075 accounts...\n",
      "  Processed 430,000 / 474,075 accounts...\n",
      "  Processed 440,000 / 474,075 accounts...\n",
      "  Processed 450,000 / 474,075 accounts...\n",
      "  Processed 460,000 / 474,075 accounts...\n",
      "  Processed 470,000 / 474,075 accounts...\n",
      "Features extracted for 393119 accounts\n",
      "Suspicious accounts: 2078 (0.53%)\n"
     ]
    }
   ],
   "source": [
    "test_features_df, test_labels_series = extract_features_for_accounts(\n",
    "        test_transaction_df, \n",
    "        test_accounts,\n",
    "        extract_account_features\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f170b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Payment_currency encoding:\n",
      "  Albanian lek → 0\n",
      "  Dirham → 1\n",
      "  Euro → 2\n",
      "  Indian rupee → 3\n",
      "  Mexican Peso → 4\n",
      "  Moroccan dirham → 5\n",
      "  Naira → 6\n",
      "  Pakistani rupee → 7\n",
      "  Swiss franc → 8\n",
      "  Turkish lira → 9\n",
      "  UK pounds → 10\n",
      "  US dollar → 11\n",
      "  Yen → 12\n",
      "\n",
      "Received_currency encoding:\n",
      "  Albanian lek → 0\n",
      "  Dirham → 1\n",
      "  Euro → 2\n",
      "  Indian rupee → 3\n",
      "  Mexican Peso → 4\n",
      "  Moroccan dirham → 5\n",
      "  Naira → 6\n",
      "  Pakistani rupee → 7\n",
      "  Swiss franc → 8\n",
      "  Turkish lira → 9\n",
      "  UK pounds → 10\n",
      "  US dollar → 11\n",
      "  Yen → 12\n",
      "\n",
      "Sender_bank_location encoding:\n",
      "  Albania → 0\n",
      "  Austria → 1\n",
      "  France → 2\n",
      "  Germany → 3\n",
      "  India → 4\n",
      "  Italy → 5\n",
      "  Japan → 6\n",
      "  Mexico → 7\n",
      "  Morocco → 8\n",
      "  Netherlands → 9\n",
      "  Nigeria → 10\n",
      "  Pakistan → 11\n",
      "  Spain → 12\n",
      "  Switzerland → 13\n",
      "  Turkey → 14\n",
      "  UAE → 15\n",
      "  UK → 16\n",
      "  USA → 17\n",
      "\n",
      "Receiver_bank_location encoding:\n",
      "  Albania → 0\n",
      "  Austria → 1\n",
      "  France → 2\n",
      "  Germany → 3\n",
      "  India → 4\n",
      "  Italy → 5\n",
      "  Japan → 6\n",
      "  Mexico → 7\n",
      "  Morocco → 8\n",
      "  Netherlands → 9\n",
      "  Nigeria → 10\n",
      "  Pakistan → 11\n",
      "  Spain → 12\n",
      "  Switzerland → 13\n",
      "  Turkey → 14\n",
      "  UAE → 15\n",
      "  UK → 16\n",
      "  USA → 17\n",
      "\n",
      "Payment_type encoding:\n",
      "  ACH → 0\n",
      "  Cash Deposit → 1\n",
      "  Cash Withdrawal → 2\n",
      "  Cheque → 3\n",
      "  Credit card → 4\n",
      "  Cross-border → 5\n",
      "  Debit card → 6\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical features in transaction table\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize label encoders for each categorical column\n",
    "labelEncoders = {}\n",
    "categorical_cols = ['Payment_currency', 'Received_currency', 'Sender_bank_location', \n",
    "                   'Receiver_bank_location', 'Payment_type']\n",
    "\n",
    "# Fit encoders and transform data\n",
    "for col in categorical_cols:\n",
    "    labelEncoders[col] = LabelEncoder()\n",
    "    train_transaction_df[f'{col}_encoded'] = labelEncoders[col].fit_transform(train_transaction_df[col])\n",
    "    test_transaction_df[f'{col}_encoded'] = labelEncoders[col].transform(test_transaction_df[col])\n",
    "\n",
    "# Print encoding mappings\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col} encoding:\")\n",
    "    for i, class_name in enumerate(labelEncoders[col].classes_):\n",
    "        print(f\"  {class_name} → {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb5ad395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features normalized!\n",
      "Scaled features shape: (735533, 14)\n"
     ]
    }
   ],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features_df)\n",
    "train_features_df_scaled = pd.DataFrame(train_features_scaled, columns=train_features_df.columns, index=train_features_df.index)\n",
    "\n",
    "print(\"Features normalized!\")\n",
    "print(f\"Scaled features shape: {train_features_df_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66bcef13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features normalized!\n",
      "Scaled features shape: (393119, 14)\n"
     ]
    }
   ],
   "source": [
    "# Rescale test features\n",
    "test_features_df_scaled = scaler.transform(test_features_df)\n",
    "test_features_df_scaled = pd.DataFrame(test_features_df_scaled, columns=test_features_df.columns, index=test_features_df.index)\n",
    "\n",
    "print(\"Features normalized!\")\n",
    "print(f\"Scaled features shape: {test_features_df_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "39447a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building transaction network graph...\n",
      "\n",
      "======================================================================\n",
      "GRAPH STATISTICS\n",
      "======================================================================\n",
      "Number of nodes (accounts): 393,119\n",
      "Number of edges (transactions): 2,200,629\n",
      "Number of features per node: 14\n",
      "Average degree: 5.60\n"
     ]
    }
   ],
   "source": [
    "test_graph_data, test_account_to_idx = build_transaction_graph(test_transaction_df, test_features_df_scaled, test_labels_series)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GRAPH STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Number of nodes (accounts): {test_graph_data.num_nodes:,}\")\n",
    "print(f\"Number of edges (transactions): {test_graph_data.num_edges:,}\")\n",
    "print(f\"Number of features per node: {test_graph_data.num_node_features}\")\n",
    "print(f\"Average degree: {test_graph_data.num_edges / test_graph_data.num_nodes:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4cd08602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f4087533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_100669/3762515983.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_graphsage_model.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Initialize the model architecture\n",
    "model = GraphSAGE_AccountRiskDetector(\n",
    "    num_features=test_graph_data.num_node_features,\n",
    "    hidden_dim=256,  # Must match your training config\n",
    "    num_layers=3,    # Must match your training config / Number of neighbourhood\n",
    "    dropout=0.3,\n",
    "    aggregator='mean'\n",
    ").to(device)\n",
    "\n",
    "# 2. Load the saved parameters\n",
    "model.load_state_dict(torch.load('best_graphsage_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8307658b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphSAGE_AccountRiskDetector(\n",
       "  (convs): ModuleList(\n",
       "    (0): SAGEConv(14, 256, aggr=mean)\n",
       "    (1-2): 2 x SAGEConv(256, 256, aggr=mean)\n",
       "  )\n",
       "  (batch_norms): ModuleList(\n",
       "    (0-2): 3 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Set to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7162f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Then create your test loader and evaluate\n",
    "test_loader = NeighborLoader(\n",
    "    test_graph_data,\n",
    "    num_neighbors=[15, 10, 5],\n",
    "    batch_size=1024,\n",
    "    input_nodes=torch.ones(test_graph_data.num_nodes, dtype=torch.bool),\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4f5e3927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Use your evaluation function\n",
    "test_acc, test_pred, test_probs, test_labels = evaluate_graphsage(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "891cf513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   Normal Account     0.9949    0.9769    0.9858    391041\n",
      "High-Risk Account     0.0125    0.0549    0.0203      2078\n",
      "\n",
      "         accuracy                         0.9720    393119\n",
      "        macro avg     0.5037    0.5159    0.5031    393119\n",
      "     weighted avg     0.9897    0.9720    0.9807    393119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, test_pred, \n",
    "                           target_names=['Normal Account', 'High-Risk Account'],\n",
    "                           digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c4693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6aeb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_inductive_evaluation_pipeline(df, features_df_scaled, labels_series, model, \n",
    "                                     feature_extraction_function, scaler, device,\n",
    "                                     cutoff_date=None, gap_days=7):\n",
    "    \"\"\"\n",
    "    Complete pipeline for evaluating GraphSAGE on new nodes with new transactions\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"INDUCTIVE EVALUATION: NEW NODES WITH NEW TRANSACTIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Set cutoff date if not provided (use 80% of data for training)\n",
    "    if cutoff_date is None:\n",
    "        cutoff_date = df['DateTime'].quantile(0.8)\n",
    "    \n",
    "    # 1. Create inductive dataset split\n",
    "    dataset_split = create_inductive_dataset(df, cutoff_date, gap_days)\n",
    "    \n",
    "    if len(dataset_split['new_accounts']) == 0:\n",
    "        print(\"No new accounts found for evaluation\")\n",
    "        return None\n",
    "    \n",
    "    # 2. Extract features for new accounts using only test period data\n",
    "    new_features_df, new_labels_series = extract_features_for_new_accounts(\n",
    "        dataset_split['test_data'], \n",
    "        dataset_split['new_accounts'],\n",
    "        feature_extraction_function\n",
    "    )\n",
    "    \n",
    "    if len(new_features_df) == 0:\n",
    "        print(\"No valid new accounts with sufficient transactions\")\n",
    "        return None\n",
    "    \n",
    "    # Add labels to features dataframe for convenience\n",
    "    new_features_df['high_risk'] = new_labels_series\n",
    "    \n",
    "    # 3. Build test period graph\n",
    "    test_graph, account_to_idx, new_account_indices = build_test_period_graph(\n",
    "        dataset_split['test_data'],\n",
    "        dataset_split['new_accounts'],\n",
    "        dataset_split['existing_accounts_in_test'],\n",
    "        new_features_df,\n",
    "        features_df_scaled,\n",
    "        scaler\n",
    "    )\n",
    "    \n",
    "    # 4. Evaluate model on new nodes\n",
    "    results = evaluate_model_on_new_nodes(\n",
    "        model, test_graph, new_account_indices, device\n",
    "    )\n",
    "    \n",
    "    # 5. Print results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"INDUCTIVE EVALUATION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"New accounts evaluated: {len(new_account_indices)}\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    \n",
    "    if results['auc'] is not None:\n",
    "        print(f\"AUC: {results['auc']:.4f}\")\n",
    "        \n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(\n",
    "            results['true_labels'], \n",
    "            results['predictions'],\n",
    "            target_names=['Normal', 'High-Risk'],\n",
    "            digits=4\n",
    "        ))\n",
    "    else:\n",
    "        print(\"AUC: Not available (single class)\")\n",
    "    \n",
    "    # 6. Performance comparison\n",
    "    suspicious_ratio = results['true_labels'].mean()\n",
    "    print(f\"\\nDataset characteristics:\")\n",
    "    print(f\"Suspicious account ratio: {suspicious_ratio:.2%}\")\n",
    "    \n",
    "    return {\n",
    "        **results,\n",
    "        'dataset_split': dataset_split,\n",
    "        'new_features_df': new_features_df,\n",
    "        'test_graph': test_graph,\n",
    "        'account_mapping': account_to_idx\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with your existing code\n",
    "def run_inductive_test(df, features_df_scaled, labels_series, model, device):\n",
    "    \"\"\"\n",
    "    Run inductive test using your existing feature extraction function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use your existing feature extraction function\n",
    "    def extract_account_features_wrapper(account, sent_txns, recv_txns):\n",
    "        # This should be your existing extract_account_features function\n",
    "        # but make sure it only uses data from sent_txns and recv_txns\n",
    "        # (which will be from test period only)\n",
    "        \n",
    "        # Import your feature extraction function here\n",
    "        from your_module import extract_account_features  # Adjust import\n",
    "        return extract_account_features(account, sent_txns, recv_txns)\n",
    "    \n",
    "    # Get the scaler used for training\n",
    "    # You should save this during training\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(features_df_scaled)  # Refit on training data\n",
    "    \n",
    "    # Run evaluation\n",
    "    results = full_inductive_evaluation_pipeline(\n",
    "        df=df,\n",
    "        features_df_scaled=features_df_scaled,\n",
    "        labels_series=labels_series,\n",
    "        model=model,\n",
    "        feature_extraction_function=extract_account_features_wrapper,\n",
    "        scaler=scaler,\n",
    "        device=device,\n",
    "        cutoff_date=None,  # Will use 80% split\n",
    "        gap_days=7\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Usage:\n",
    "# results = run_inductive_test(df, features_df_scaled, labels_series, model, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-backup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
